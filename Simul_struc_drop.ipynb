{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In odrer to compare structured dropout and iid dropout in a linear model regime, we use the simulations embedded in sklearn (which make use of the Madelon synthetic dataset, see references in http://archive.ics.uci.edu/ml/datasets/madelon )\n",
    "we vary: \n",
    "- the number of variables of redundant variables\n",
    "- the number of overall variables \n",
    "\n",
    "we assess classification accuracy on a test set drawn from the same simulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "\n",
    "x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "x_train=x_all[range(100),]\n",
    "y_train=y_all[range(100),]\n",
    "x_test=x_all[101:,]\n",
    "y_test=y_all[101:]\n",
    "\n",
    "\n",
    "dim = 1000 \n",
    "nb_train = x_train.shape[0]\n",
    "nb_test = x_test.shape[0]\n",
    "nb_classes=1\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(nb_train, 'train samples')\n",
    "print(nb_test, 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = to_categorical(y_train, nb_classes)\n",
    "#y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "y_train=y_train.reshape(nb_train,1)\n",
    "y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.distributions import MultivariateNormalFullCovariance as mvnfc\n",
    "\n",
    "\n",
    "def dropout_layer(x, mode, l, dim):\n",
    "\n",
    "    if mode == 'struc':\n",
    "        xm = tf.reduce_mean(x, 0)\n",
    "        cov = tf.matmul(tf.transpose(x-xm), x-xm) / batch_size\n",
    "        cov += 1e-2 * tf.eye(dim, dtype='float32')\n",
    "       # dia=tf.sqrt(tf.diag(1/tf.diag_part(cov)))\n",
    "       # corr= tf.matmul(tf.matmul(dia,cov),dia)\n",
    "        sample = mvnfc(tf.zeros(shape=[dim]), cov).sample()\n",
    "        return tf.multiply(x, np.sqrt(l)* sample + tf.ones(shape=[dim]))\n",
    "\n",
    "    elif mode == 'iid':\n",
    "      # mu = tf.Variable(lambda : tf.ones(shape=[dim]))\n",
    "        cov =  tf.eye(dim, dtype='float32')\n",
    "        sample = mvnfc(tf.zeros(shape=[dim]), cov).sample()\n",
    "        return tf.multiply(x, np.sqrt(l)* sample + tf.ones(shape=[dim]))\n",
    "\n",
    "    else:  # no dropout\n",
    "        return x\n",
    "\n",
    "\n",
    "class Linear_Model:\n",
    "\n",
    "    def __init__(self, dim, nb_classes, batch_size, l, mode=None):\n",
    "\n",
    "        self.X = tf.placeholder(tf.float32, [None, dim])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "        self.train = tf.placeholder(tf.bool)\n",
    "\n",
    "        W = tf.Variable(tf.random_uniform([dim, nb_classes], -0.01, 0.01))  # model weights\n",
    "        b = tf.Variable(tf.zeros(shape=[nb_classes]))                       # model biases\n",
    "\n",
    "        self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n",
    "        x = tf.matmul(self.dl, W) + b\n",
    "\n",
    "        # Minimize error using cross entropy\n",
    "        self.probs = tf.nn.sigmoid(x)\n",
    "        log_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=x, labels=self.Y)\n",
    "        self.mean_log_loss = tf.reduce_mean(log_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred, dl = sess.run([model.probs, model.dl],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    cor_norms.append(np.linalg.norm(np.corrcoef((dl + 1e-10 * np.random.rand(*dl.shape)).T)))\n",
    "                    print(cor_norms[-1])\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "\n",
    "            all_accuracies.append(accs)\n",
    "            all_cor_norms.append(cor_norms)\n",
    "\n",
    "    return all_accuracies, all_cor_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5525, 0.512]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.max(accs) for accs in acc_struc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[np.max(accs) for accs in acc_iid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training of the linear model, we simulate on 10 runs a set of 100 points with parameters listed in the paper, the model is either regularised using iid Gaussian dropout, Structured dropout (ASNI), or without regularisation. We test the model on each run, and for all regularisation parameters on one test dataset with 10,000 points, then average the accuracy on the 10 runs (and compute the standard deviation).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n",
      "WARNING:tensorflow:From <ipython-input-4-5317bbadfddf>:18: MultivariateNormalFullCovariance.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_full_covariance) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py:194: MultivariateNormalTriL.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_tril) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_tril.py:221: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.315\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.345\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.219\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.187\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.146\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.109\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.214\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.115\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.089\n",
      "Accuracy: 0.657\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.689\n",
      "Accuracy: 0.547\n",
      "Iteration: 200, 0.341\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.291\n",
      "Accuracy: 0.681\n",
      "Iteration: 600, 0.225\n",
      "Accuracy: 0.676\n",
      "Iteration: 800, 0.161\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.185\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.265\n",
      "Accuracy: 0.665\n",
      "Iteration: 1400, 0.129\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.087\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.114\n",
      "Accuracy: 0.658\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.364\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.260\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.189\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.202\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.160\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.198\n",
      "Accuracy: 0.662\n",
      "Iteration: 1400, 0.146\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.125\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.102\n",
      "Accuracy: 0.657\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.311\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.310\n",
      "Accuracy: 0.679\n",
      "Iteration: 600, 0.224\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.188\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.159\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.204\n",
      "Accuracy: 0.665\n",
      "Iteration: 1400, 0.158\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.095\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.095\n",
      "Accuracy: 0.657\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.481\n",
      "Iteration: 200, 0.366\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.310\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.271\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.175\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.233\n",
      "Accuracy: 0.666\n",
      "Iteration: 1200, 0.133\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.088\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.122\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.095\n",
      "Accuracy: 0.655\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.458\n",
      "Iteration: 200, 0.362\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.364\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.236\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.258\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.117\n",
      "Accuracy: 0.665\n",
      "Iteration: 1200, 0.174\n",
      "Accuracy: 0.662\n",
      "Iteration: 1400, 0.189\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.209\n",
      "Accuracy: 0.658\n",
      "Iteration: 1800, 0.167\n",
      "Accuracy: 0.654\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.579\n",
      "Iteration: 200, 0.469\n",
      "Accuracy: 0.670\n",
      "Iteration: 400, 0.384\n",
      "Accuracy: 0.663\n",
      "Iteration: 600, 0.446\n",
      "Accuracy: 0.657\n",
      "Iteration: 800, 0.646\n",
      "Accuracy: 0.656\n",
      "Iteration: 1000, 0.479\n",
      "Accuracy: 0.654\n",
      "Iteration: 1200, 0.400\n",
      "Accuracy: 0.655\n",
      "Iteration: 1400, 0.263\n",
      "Accuracy: 0.656\n",
      "Iteration: 1600, 0.191\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 0.256\n",
      "Accuracy: 0.653\n",
      "#### struc #### iteration  0\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.688\n",
      "Accuracy: 0.568\n",
      "Iteration: 200, 0.439\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.310\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.298\n",
      "Accuracy: 0.675\n",
      "Iteration: 800, 0.170\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.159\n",
      "Accuracy: 0.668\n",
      "Iteration: 1200, 0.145\n",
      "Accuracy: 0.664\n",
      "Iteration: 1400, 0.158\n",
      "Accuracy: 0.663\n",
      "Iteration: 1600, 0.094\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.092\n",
      "Accuracy: 0.658\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.297\n",
      "Accuracy: 0.678\n",
      "Iteration: 400, 0.253\n",
      "Accuracy: 0.679\n",
      "Iteration: 600, 0.221\n",
      "Accuracy: 0.675\n",
      "Iteration: 800, 0.143\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.156\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.145\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.138\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.137\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.101\n",
      "Accuracy: 0.658\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.435\n",
      "Iteration: 200, 0.411\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.336\n",
      "Accuracy: 0.675\n",
      "Iteration: 600, 0.243\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.217\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.190\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.223\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.111\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.116\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.085\n",
      "Accuracy: 0.658\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.689\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.350\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.277\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.230\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.141\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.172\n",
      "Accuracy: 0.665\n",
      "Iteration: 1200, 0.175\n",
      "Accuracy: 0.664\n",
      "Iteration: 1400, 0.174\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.100\n",
      "Accuracy: 0.661\n",
      "Iteration: 1800, 0.123\n",
      "Accuracy: 0.657\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.324\n",
      "Accuracy: 0.679\n",
      "Iteration: 400, 0.243\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.248\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.186\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.140\n",
      "Accuracy: 0.661\n",
      "Iteration: 1200, 0.129\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.145\n",
      "Accuracy: 0.654\n",
      "Iteration: 1600, 0.162\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.102\n",
      "Accuracy: 0.651\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.389\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 0.219\n",
      "Accuracy: 0.649\n",
      "Iteration: 600, 0.323\n",
      "Accuracy: 0.645\n",
      "Iteration: 800, 0.256\n",
      "Accuracy: 0.637\n",
      "Iteration: 1000, 0.288\n",
      "Accuracy: 0.634\n",
      "Iteration: 1200, 0.237\n",
      "Accuracy: 0.625\n",
      "Iteration: 1400, 0.381\n",
      "Accuracy: 0.617\n",
      "Iteration: 1600, 0.302\n",
      "Accuracy: 0.615\n",
      "Iteration: 1800, 0.215\n",
      "Accuracy: 0.611\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.528\n",
      "Accuracy: 0.605\n",
      "Iteration: 400, 0.526\n",
      "Accuracy: 0.588\n",
      "Iteration: 600, 0.687\n",
      "Accuracy: 0.565\n",
      "Iteration: 800, 0.327\n",
      "Accuracy: 0.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, 0.534\n",
      "Accuracy: 0.564\n",
      "Iteration: 1200, 0.293\n",
      "Accuracy: 0.569\n",
      "Iteration: 1400, 0.354\n",
      "Accuracy: 0.558\n",
      "Iteration: 1600, 0.532\n",
      "Accuracy: 0.551\n",
      "Iteration: 1800, 0.415\n",
      "Accuracy: 0.556\n",
      "#### no noise ####   iteration  0\n",
      "Lamb None\n",
      "Iteration: 0, 0.671\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.384\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.283\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.247\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.174\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.134\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.138\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.104\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.148\n",
      "Accuracy: 0.658\n",
      "Iteration: 1800, 0.124\n",
      "Accuracy: 0.658\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.547\n",
      "Iteration: 200, 0.379\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.322\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.270\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.181\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.139\n",
      "Accuracy: 0.661\n",
      "Iteration: 1200, 0.110\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.076\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.073\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.068\n",
      "Accuracy: 0.657\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.408\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.247\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.201\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.163\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.102\n",
      "Accuracy: 0.662\n",
      "Iteration: 1200, 0.128\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.097\n",
      "Accuracy: 0.659\n",
      "Iteration: 1600, 0.067\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.067\n",
      "Accuracy: 0.654\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.672\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.318\n",
      "Accuracy: 0.676\n",
      "Iteration: 400, 0.225\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.161\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.172\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.125\n",
      "Accuracy: 0.658\n",
      "Iteration: 1200, 0.168\n",
      "Accuracy: 0.658\n",
      "Iteration: 1400, 0.118\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.083\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.055\n",
      "Accuracy: 0.655\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.311\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.261\n",
      "Accuracy: 0.671\n",
      "Iteration: 600, 0.180\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.168\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.119\n",
      "Accuracy: 0.663\n",
      "Iteration: 1200, 0.108\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.087\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.086\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.067\n",
      "Accuracy: 0.655\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.311\n",
      "Accuracy: 0.686\n",
      "Iteration: 400, 0.294\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.205\n",
      "Accuracy: 0.663\n",
      "Iteration: 800, 0.149\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.109\n",
      "Accuracy: 0.659\n",
      "Iteration: 1200, 0.128\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.073\n",
      "Accuracy: 0.656\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.688\n",
      "Accuracy: 0.571\n",
      "Iteration: 200, 0.382\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.301\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.216\n",
      "Accuracy: 0.668\n",
      "Iteration: 800, 0.202\n",
      "Accuracy: 0.663\n",
      "Iteration: 1000, 0.229\n",
      "Accuracy: 0.657\n",
      "Iteration: 1200, 0.154\n",
      "Accuracy: 0.658\n",
      "Iteration: 1400, 0.121\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.145\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 0.069\n",
      "Accuracy: 0.654\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.699\n",
      "Accuracy: 0.569\n",
      "Iteration: 200, 0.527\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.415\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.275\n",
      "Accuracy: 0.663\n",
      "Iteration: 800, 0.246\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.287\n",
      "Accuracy: 0.655\n",
      "Iteration: 1200, 0.234\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.314\n",
      "Accuracy: 0.653\n",
      "Iteration: 1600, 0.749\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 0.238\n",
      "Accuracy: 0.646\n",
      "#### struc #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.329\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.260\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.172\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.145\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.169\n",
      "Accuracy: 0.660\n",
      "Iteration: 1200, 0.110\n",
      "Accuracy: 0.659\n",
      "Iteration: 1400, 0.115\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.078\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.060\n",
      "Accuracy: 0.655\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.580\n",
      "Iteration: 200, 0.370\n",
      "Accuracy: 0.684\n",
      "Iteration: 400, 0.254\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.217\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.165\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.162\n",
      "Accuracy: 0.661\n",
      "Iteration: 1200, 0.104\n",
      "Accuracy: 0.659\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.101\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.056\n",
      "Accuracy: 0.655\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.592\n",
      "Iteration: 200, 0.293\n",
      "Accuracy: 0.681\n",
      "Iteration: 400, 0.260\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.227\n",
      "Accuracy: 0.665\n",
      "Iteration: 800, 0.182\n",
      "Accuracy: 0.659\n",
      "Iteration: 1000, 0.154\n",
      "Accuracy: 0.657\n",
      "Iteration: 1200, 0.111\n",
      "Accuracy: 0.657\n",
      "Iteration: 1400, 0.090\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.088\n",
      "Accuracy: 0.655\n",
      "Iteration: 1800, 0.067\n",
      "Accuracy: 0.654\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.330\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.241\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.231\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.221\n",
      "Accuracy: 0.663\n",
      "Iteration: 1000, 0.147\n",
      "Accuracy: 0.662\n",
      "Iteration: 1200, 0.110\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.655\n",
      "Iteration: 1600, 0.080\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.060\n",
      "Accuracy: 0.653\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.554\n",
      "Iteration: 200, 0.329\n",
      "Accuracy: 0.684\n",
      "Iteration: 400, 0.221\n",
      "Accuracy: 0.668\n",
      "Iteration: 600, 0.235\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.146\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.123\n",
      "Accuracy: 0.659\n",
      "Iteration: 1200, 0.120\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.110\n",
      "Accuracy: 0.654\n",
      "Iteration: 1600, 0.089\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.075\n",
      "Accuracy: 0.650\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.485\n",
      "Accuracy: 0.670\n",
      "Iteration: 400, 0.356\n",
      "Accuracy: 0.655\n",
      "Iteration: 600, 0.313\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.265\n",
      "Accuracy: 0.644\n",
      "Iteration: 1000, 0.235\n",
      "Accuracy: 0.641\n",
      "Iteration: 1200, 0.171\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.151\n",
      "Accuracy: 0.631\n",
      "Iteration: 1600, 0.121\n",
      "Accuracy: 0.628\n",
      "Iteration: 1800, 0.161\n",
      "Accuracy: 0.626\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.660\n",
      "Accuracy: 0.583\n",
      "Iteration: 200, 0.541\n",
      "Accuracy: 0.614\n",
      "Iteration: 400, 0.380\n",
      "Accuracy: 0.598\n",
      "Iteration: 600, 0.516\n",
      "Accuracy: 0.594\n",
      "Iteration: 800, 0.312\n",
      "Accuracy: 0.583\n",
      "Iteration: 1000, 0.459\n",
      "Accuracy: 0.577\n",
      "Iteration: 1200, 0.659\n",
      "Accuracy: 0.576\n",
      "Iteration: 1400, 0.373\n",
      "Accuracy: 0.578\n",
      "Iteration: 1600, 0.466\n",
      "Accuracy: 0.577\n",
      "Iteration: 1800, 0.407\n",
      "Accuracy: 0.573\n",
      "#### no noise ####   iteration  1\n",
      "Lamb None\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.523\n",
      "Iteration: 200, 0.333\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.251\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.196\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.199\n",
      "Accuracy: 0.660\n",
      "Iteration: 1000, 0.137\n",
      "Accuracy: 0.659\n",
      "Iteration: 1200, 0.116\n",
      "Accuracy: 0.659\n",
      "Iteration: 1400, 0.074\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.094\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.050\n",
      "Accuracy: 0.655\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.334\n",
      "Accuracy: 0.641\n",
      "Iteration: 400, 0.272\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.157\n",
      "Accuracy: 0.642\n",
      "Iteration: 800, 0.138\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.131\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.090\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.057\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.052\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.034\n",
      "Accuracy: 0.632\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.676\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.351\n",
      "Accuracy: 0.641\n",
      "Iteration: 400, 0.236\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.172\n",
      "Accuracy: 0.641\n",
      "Iteration: 800, 0.124\n",
      "Accuracy: 0.640\n",
      "Iteration: 1000, 0.119\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.075\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.063\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.063\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.047\n",
      "Accuracy: 0.632\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.687\n",
      "Accuracy: 0.584\n",
      "Iteration: 200, 0.406\n",
      "Accuracy: 0.638\n",
      "Iteration: 400, 0.285\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.155\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.135\n",
      "Accuracy: 0.640\n",
      "Iteration: 1000, 0.107\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.093\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.057\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.076\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.047\n",
      "Accuracy: 0.632\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.699\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.369\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.256\n",
      "Accuracy: 0.644\n",
      "Iteration: 600, 0.186\n",
      "Accuracy: 0.643\n",
      "Iteration: 800, 0.123\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.122\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.069\n",
      "Accuracy: 0.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1400, 0.075\n",
      "Accuracy: 0.637\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.635\n",
      "Iteration: 1800, 0.040\n",
      "Accuracy: 0.632\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.670\n",
      "Accuracy: 0.565\n",
      "Iteration: 200, 0.367\n",
      "Accuracy: 0.645\n",
      "Iteration: 400, 0.235\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.155\n",
      "Accuracy: 0.642\n",
      "Iteration: 800, 0.159\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.113\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.096\n",
      "Accuracy: 0.635\n",
      "Iteration: 1400, 0.098\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.059\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.064\n",
      "Accuracy: 0.631\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.489\n",
      "Iteration: 200, 0.373\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.281\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.214\n",
      "Accuracy: 0.642\n",
      "Iteration: 800, 0.286\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.143\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.104\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.229\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.634\n",
      "Iteration: 1800, 0.110\n",
      "Accuracy: 0.634\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.432\n",
      "Iteration: 200, 0.625\n",
      "Accuracy: 0.634\n",
      "Iteration: 400, 0.441\n",
      "Accuracy: 0.633\n",
      "Iteration: 600, 0.462\n",
      "Accuracy: 0.634\n",
      "Iteration: 800, 0.446\n",
      "Accuracy: 0.633\n",
      "Iteration: 1000, 0.356\n",
      "Accuracy: 0.632\n",
      "Iteration: 1200, 0.319\n",
      "Accuracy: 0.634\n",
      "Iteration: 1400, 0.326\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.330\n",
      "Accuracy: 0.634\n",
      "Iteration: 1800, 0.432\n",
      "Accuracy: 0.637\n",
      "#### struc #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.520\n",
      "Iteration: 200, 0.401\n",
      "Accuracy: 0.642\n",
      "Iteration: 400, 0.238\n",
      "Accuracy: 0.642\n",
      "Iteration: 600, 0.155\n",
      "Accuracy: 0.638\n",
      "Iteration: 800, 0.165\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.128\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.105\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.086\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.059\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.052\n",
      "Accuracy: 0.631\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.687\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.377\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.194\n",
      "Accuracy: 0.639\n",
      "Iteration: 600, 0.145\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.141\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.117\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.103\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.078\n",
      "Accuracy: 0.631\n",
      "Iteration: 1800, 0.047\n",
      "Accuracy: 0.630\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.583\n",
      "Iteration: 200, 0.370\n",
      "Accuracy: 0.635\n",
      "Iteration: 400, 0.242\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.177\n",
      "Accuracy: 0.639\n",
      "Iteration: 800, 0.140\n",
      "Accuracy: 0.636\n",
      "Iteration: 1000, 0.118\n",
      "Accuracy: 0.635\n",
      "Iteration: 1200, 0.103\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.066\n",
      "Accuracy: 0.633\n",
      "Iteration: 1600, 0.066\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.044\n",
      "Accuracy: 0.632\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.317\n",
      "Accuracy: 0.638\n",
      "Iteration: 400, 0.188\n",
      "Accuracy: 0.642\n",
      "Iteration: 600, 0.209\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.152\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.087\n",
      "Accuracy: 0.636\n",
      "Iteration: 1200, 0.085\n",
      "Accuracy: 0.635\n",
      "Iteration: 1400, 0.080\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.066\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.048\n",
      "Accuracy: 0.631\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.402\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.256\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.197\n",
      "Accuracy: 0.637\n",
      "Iteration: 800, 0.178\n",
      "Accuracy: 0.635\n",
      "Iteration: 1000, 0.136\n",
      "Accuracy: 0.634\n",
      "Iteration: 1200, 0.103\n",
      "Accuracy: 0.628\n",
      "Iteration: 1400, 0.051\n",
      "Accuracy: 0.626\n",
      "Iteration: 1600, 0.079\n",
      "Accuracy: 0.625\n",
      "Iteration: 1800, 0.085\n",
      "Accuracy: 0.624\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.482\n",
      "Iteration: 200, 0.427\n",
      "Accuracy: 0.624\n",
      "Iteration: 400, 0.297\n",
      "Accuracy: 0.614\n",
      "Iteration: 600, 0.179\n",
      "Accuracy: 0.610\n",
      "Iteration: 800, 0.200\n",
      "Accuracy: 0.607\n",
      "Iteration: 1000, 0.196\n",
      "Accuracy: 0.605\n",
      "Iteration: 1200, 0.157\n",
      "Accuracy: 0.600\n",
      "Iteration: 1400, 0.139\n",
      "Accuracy: 0.598\n",
      "Iteration: 1600, 0.107\n",
      "Accuracy: 0.592\n",
      "Iteration: 1800, 0.117\n",
      "Accuracy: 0.592\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.709\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.377\n",
      "Accuracy: 0.584\n",
      "Iteration: 400, 0.376\n",
      "Accuracy: 0.564\n",
      "Iteration: 600, 0.360\n",
      "Accuracy: 0.559\n",
      "Iteration: 800, 0.569\n",
      "Accuracy: 0.559\n",
      "Iteration: 1000, 0.336\n",
      "Accuracy: 0.555\n",
      "Iteration: 1200, 0.496\n",
      "Accuracy: 0.553\n",
      "Iteration: 1400, 0.342\n",
      "Accuracy: 0.546\n",
      "Iteration: 1600, 0.361\n",
      "Accuracy: 0.545\n",
      "Iteration: 1800, 0.337\n",
      "Accuracy: 0.538\n",
      "#### no noise ####   iteration  2\n",
      "Lamb None\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.375\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.265\n",
      "Accuracy: 0.642\n",
      "Iteration: 600, 0.168\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.144\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.139\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.090\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.083\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.049\n",
      "Accuracy: 0.631\n",
      "Iteration: 1800, 0.046\n",
      "Accuracy: 0.631\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.625\n",
      "Iteration: 200, 0.339\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.207\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.192\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.132\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.100\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.079\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 0.077\n",
      "Accuracy: 0.688\n",
      "Iteration: 1600, 0.041\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.045\n",
      "Accuracy: 0.686\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.497\n",
      "Iteration: 200, 0.329\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.247\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.181\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.126\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.120\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.084\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.046\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.058\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.049\n",
      "Accuracy: 0.684\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.686\n",
      "Accuracy: 0.542\n",
      "Iteration: 200, 0.343\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.244\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.226\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.101\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.074\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.059\n",
      "Accuracy: 0.690\n",
      "Iteration: 1400, 0.078\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.058\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.042\n",
      "Accuracy: 0.685\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.703\n",
      "Accuracy: 0.466\n",
      "Iteration: 200, 0.297\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.250\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.166\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.094\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.099\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.068\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.069\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.054\n",
      "Accuracy: 0.685\n",
      "Iteration: 1800, 0.040\n",
      "Accuracy: 0.685\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.572\n",
      "Iteration: 200, 0.310\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.167\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.198\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.149\n",
      "Accuracy: 0.690\n",
      "Iteration: 1000, 0.081\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.075\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.050\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.049\n",
      "Accuracy: 0.684\n",
      "Iteration: 1800, 0.052\n",
      "Accuracy: 0.685\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.281\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.227\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.210\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.098\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.163\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.094\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.086\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.684\n",
      "Iteration: 1800, 0.087\n",
      "Accuracy: 0.684\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.437\n",
      "Iteration: 200, 0.519\n",
      "Accuracy: 0.678\n",
      "Iteration: 400, 0.295\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.297\n",
      "Accuracy: 0.676\n",
      "Iteration: 800, 0.251\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.357\n",
      "Accuracy: 0.675\n",
      "Iteration: 1200, 0.458\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.435\n",
      "Accuracy: 0.670\n",
      "Iteration: 1600, 0.303\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.284\n",
      "Accuracy: 0.666\n",
      "#### struc #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.543\n",
      "Iteration: 200, 0.326\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.169\n",
      "Accuracy: 0.690\n",
      "Iteration: 600, 0.173\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.153\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.087\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.109\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.039\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.049\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.054\n",
      "Accuracy: 0.685\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.712\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.327\n",
      "Accuracy: 0.690\n",
      "Iteration: 400, 0.222\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.176\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.126\n",
      "Accuracy: 0.694\n",
      "Iteration: 1000, 0.089\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.092\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 0.089\n",
      "Accuracy: 0.689\n",
      "Iteration: 1600, 0.054\n",
      "Accuracy: 0.688\n",
      "Iteration: 1800, 0.037\n",
      "Accuracy: 0.687\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.538\n",
      "Iteration: 200, 0.342\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.214\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.148\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.187\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.096\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.042\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 0.066\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.064\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.030\n",
      "Accuracy: 0.686\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.575\n",
      "Iteration: 200, 0.371\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.203\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.124\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.145\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.137\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.077\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.058\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.059\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.042\n",
      "Accuracy: 0.684\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.604\n",
      "Iteration: 200, 0.369\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.185\n",
      "Accuracy: 0.689\n",
      "Iteration: 600, 0.139\n",
      "Accuracy: 0.689\n",
      "Iteration: 800, 0.148\n",
      "Accuracy: 0.688\n",
      "Iteration: 1000, 0.096\n",
      "Accuracy: 0.686\n",
      "Iteration: 1200, 0.127\n",
      "Accuracy: 0.683\n",
      "Iteration: 1400, 0.053\n",
      "Accuracy: 0.681\n",
      "Iteration: 1600, 0.062\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.063\n",
      "Accuracy: 0.679\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.503\n",
      "Iteration: 200, 0.422\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.175\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.259\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.133\n",
      "Accuracy: 0.659\n",
      "Iteration: 1000, 0.176\n",
      "Accuracy: 0.653\n",
      "Iteration: 1200, 0.106\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.195\n",
      "Accuracy: 0.644\n",
      "Iteration: 1600, 0.097\n",
      "Accuracy: 0.642\n",
      "Iteration: 1800, 0.061\n",
      "Accuracy: 0.637\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.712\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.599\n",
      "Accuracy: 0.612\n",
      "Iteration: 400, 0.540\n",
      "Accuracy: 0.591\n",
      "Iteration: 600, 0.469\n",
      "Accuracy: 0.586\n",
      "Iteration: 800, 0.220\n",
      "Accuracy: 0.571\n",
      "Iteration: 1000, 0.241\n",
      "Accuracy: 0.575\n",
      "Iteration: 1200, 0.609\n",
      "Accuracy: 0.576\n",
      "Iteration: 1400, 0.384\n",
      "Accuracy: 0.570\n",
      "Iteration: 1600, 0.683\n",
      "Accuracy: 0.568\n",
      "Iteration: 1800, 0.379\n",
      "Accuracy: 0.565\n",
      "#### no noise ####   iteration  3\n",
      "Lamb None\n",
      "Iteration: 0, 0.688\n",
      "Accuracy: 0.457\n",
      "Iteration: 200, 0.352\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.217\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.192\n",
      "Accuracy: 0.691\n",
      "Iteration: 800, 0.132\n",
      "Accuracy: 0.689\n",
      "Iteration: 1000, 0.109\n",
      "Accuracy: 0.688\n",
      "Iteration: 1200, 0.059\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.057\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.032\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.082\n",
      "Accuracy: 0.685\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.516\n",
      "Iteration: 200, 0.326\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.185\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.107\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.119\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.062\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.058\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.036\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.031\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.033\n",
      "Accuracy: 0.697\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.451\n",
      "Iteration: 200, 0.278\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.180\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.124\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.094\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.088\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.051\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.033\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.037\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.027\n",
      "Accuracy: 0.695\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.320\n",
      "Accuracy: 0.695\n",
      "Iteration: 400, 0.186\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.143\n",
      "Accuracy: 0.700\n",
      "Iteration: 800, 0.094\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.052\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.073\n",
      "Accuracy: 0.699\n",
      "Iteration: 1400, 0.042\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.035\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.028\n",
      "Accuracy: 0.697\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.439\n",
      "Iteration: 200, 0.309\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.167\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.099\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.081\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.062\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.052\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.046\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.026\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.034\n",
      "Accuracy: 0.697\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.294\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.205\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.142\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.080\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.086\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.055\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.047\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.035\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.030\n",
      "Accuracy: 0.698\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.450\n",
      "Iteration: 200, 0.257\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.172\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.195\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.182\n",
      "Accuracy: 0.699\n",
      "Iteration: 1000, 0.107\n",
      "Accuracy: 0.701\n",
      "Iteration: 1200, 0.045\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.090\n",
      "Accuracy: 0.700\n",
      "Iteration: 1600, 0.045\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.075\n",
      "Accuracy: 0.702\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.577\n",
      "Iteration: 200, 0.424\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.346\n",
      "Accuracy: 0.704\n",
      "Iteration: 600, 0.368\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.226\n",
      "Accuracy: 0.704\n",
      "Iteration: 1000, 0.493\n",
      "Accuracy: 0.699\n",
      "Iteration: 1200, 0.478\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.436\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.201\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.184\n",
      "Accuracy: 0.704\n",
      "#### struc #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.689\n",
      "Accuracy: 0.469\n",
      "Iteration: 200, 0.262\n",
      "Accuracy: 0.686\n",
      "Iteration: 400, 0.168\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.119\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.077\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.075\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.053\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.041\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.034\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.029\n",
      "Accuracy: 0.696\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.558\n",
      "Iteration: 200, 0.353\n",
      "Accuracy: 0.694\n",
      "Iteration: 400, 0.216\n",
      "Accuracy: 0.699\n",
      "Iteration: 600, 0.134\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.097\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.062\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.069\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.053\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.037\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.020\n",
      "Accuracy: 0.696\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.503\n",
      "Iteration: 200, 0.266\n",
      "Accuracy: 0.696\n",
      "Iteration: 400, 0.168\n",
      "Accuracy: 0.697\n",
      "Iteration: 600, 0.115\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.053\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.080\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.066\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.049\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.033\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.030\n",
      "Accuracy: 0.697\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.534\n",
      "Iteration: 200, 0.318\n",
      "Accuracy: 0.690\n",
      "Iteration: 400, 0.176\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.117\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.083\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.057\n",
      "Accuracy: 0.694\n",
      "Iteration: 1200, 0.054\n",
      "Accuracy: 0.694\n",
      "Iteration: 1400, 0.044\n",
      "Accuracy: 0.695\n",
      "Iteration: 1600, 0.040\n",
      "Accuracy: 0.695\n",
      "Iteration: 1800, 0.027\n",
      "Accuracy: 0.696\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.432\n",
      "Iteration: 200, 0.290\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.222\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.134\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.118\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.061\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.090\n",
      "Accuracy: 0.695\n",
      "Iteration: 1400, 0.068\n",
      "Accuracy: 0.694\n",
      "Iteration: 1600, 0.048\n",
      "Accuracy: 0.693\n",
      "Iteration: 1800, 0.048\n",
      "Accuracy: 0.693\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.509\n",
      "Iteration: 200, 0.465\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.193\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.193\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.108\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.122\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.202\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 0.109\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.042\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.089\n",
      "Accuracy: 0.655\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.713\n",
      "Accuracy: 0.456\n",
      "Iteration: 200, 0.410\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.449\n",
      "Accuracy: 0.612\n",
      "Iteration: 600, 0.699\n",
      "Accuracy: 0.593\n",
      "Iteration: 800, 0.282\n",
      "Accuracy: 0.595\n",
      "Iteration: 1000, 0.369\n",
      "Accuracy: 0.600\n",
      "Iteration: 1200, 0.385\n",
      "Accuracy: 0.594\n",
      "Iteration: 1400, 0.486\n",
      "Accuracy: 0.584\n",
      "Iteration: 1600, 0.519\n",
      "Accuracy: 0.584\n",
      "Iteration: 1800, 0.281\n",
      "Accuracy: 0.579\n",
      "#### no noise ####   iteration  4\n",
      "Lamb None\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.477\n",
      "Iteration: 200, 0.292\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.190\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.102\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.101\n",
      "Accuracy: 0.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, 0.072\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.060\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.048\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.034\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.029\n",
      "Accuracy: 0.698\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000 \n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=100, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 100\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n",
      "WARNING:tensorflow:From <ipython-input-2-5317bbadfddf>:18: MultivariateNormalFullCovariance.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_full_covariance) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py:194: MultivariateNormalTriL.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_tril) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_tril.py:221: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.571\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.479\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.480\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.699\n",
      "Accuracy: 0.500\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.487\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.490\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.537\n",
      "#### struc #### iteration  0\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.704\n",
      "Accuracy: 0.491\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.680\n",
      "Accuracy: 0.589\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.514\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.495\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.574\n",
      "Lamb 0.1\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "                 \n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 200 \n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=100, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 100\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6655, 0.0235405182610749)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6834800000000001, 0.02014580849705467)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6803999999999999, 0.01981706335459418)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 0)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.558\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.712\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.712\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.711\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.712\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.711\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.521\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.709\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.709\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.708\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.708\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.715\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.712\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.711\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.710\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.708\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.710\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.708\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.485\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.713\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.713\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.713\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.712\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.712\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.712\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.738\n",
      "Accuracy: 0.471\n",
      "Iteration: 200, 0.009\n",
      "Accuracy: 0.708\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.709\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.708\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.707\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.706\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.782\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.027\n",
      "Accuracy: 0.694\n",
      "Iteration: 400, 0.018\n",
      "Accuracy: 0.677\n",
      "Iteration: 600, 0.007\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.044\n",
      "Accuracy: 0.657\n",
      "Iteration: 1000, 0.007\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.007\n",
      "Accuracy: 0.642\n",
      "Iteration: 1400, 0.009\n",
      "Accuracy: 0.641\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.643\n",
      "Iteration: 1800, 0.039\n",
      "Accuracy: 0.635\n",
      "('#### struc #### iteration ', 0)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.740\n",
      "Accuracy: 0.490\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.704\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.703\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.703\n",
      "Accuracy: 0.549\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.715\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.716\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.716\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.715\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.715\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.671\n",
      "Accuracy: 0.565\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.716\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.715\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.714\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.715\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.714\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.714\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.714\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.779\n",
      "Accuracy: 0.478\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.707\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.708\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.708\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.708\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.707\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.707\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.766\n",
      "Accuracy: 0.552\n",
      "Iteration: 200, 0.029\n",
      "Accuracy: 0.703\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.690\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.688\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.685\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.682\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.681\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.839\n",
      "Accuracy: 0.523\n",
      "Iteration: 200, 0.034\n",
      "Accuracy: 0.596\n",
      "Iteration: 400, 0.017\n",
      "Accuracy: 0.574\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.566\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.556\n",
      "Iteration: 1000, 0.004\n",
      "Accuracy: 0.554\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.552\n",
      "Iteration: 1400, 0.004\n",
      "Accuracy: 0.551\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.550\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.546\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.789\n",
      "Accuracy: 0.551\n",
      "Iteration: 200, 0.093\n",
      "Accuracy: 0.516\n",
      "Iteration: 400, 0.040\n",
      "Accuracy: 0.516\n",
      "Iteration: 600, 0.052\n",
      "Accuracy: 0.516\n",
      "Iteration: 800, 0.022\n",
      "Accuracy: 0.512\n",
      "Iteration: 1000, 0.006\n",
      "Accuracy: 0.506\n",
      "Iteration: 1200, 0.023\n",
      "Accuracy: 0.508\n",
      "Iteration: 1400, 0.026\n",
      "Accuracy: 0.503\n",
      "Iteration: 1600, 0.074\n",
      "Accuracy: 0.512\n",
      "Iteration: 1800, 0.018\n",
      "Accuracy: 0.505\n",
      "('#### no noise ####   iteration ', 0)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.707\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.708\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.709\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 1)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.747\n",
      "Accuracy: 0.468\n",
      "Iteration: 200, 0.016\n",
      "Accuracy: 0.673\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.671\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.750\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.018\n",
      "Accuracy: 0.672\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.706\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.707\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.679\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.678\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.711\n",
      "Accuracy: 0.483\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.666\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.668\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.740\n",
      "Accuracy: 0.538\n",
      "Iteration: 200, 0.020\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.007\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.670\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.721\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.056\n",
      "Accuracy: 0.652\n",
      "Iteration: 400, 0.025\n",
      "Accuracy: 0.635\n",
      "Iteration: 600, 0.048\n",
      "Accuracy: 0.630\n",
      "Iteration: 800, 0.018\n",
      "Accuracy: 0.633\n",
      "Iteration: 1000, 0.005\n",
      "Accuracy: 0.626\n",
      "Iteration: 1200, 0.035\n",
      "Accuracy: 0.616\n",
      "Iteration: 1400, 0.034\n",
      "Accuracy: 0.606\n",
      "Iteration: 1600, 0.028\n",
      "Accuracy: 0.603\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.605\n",
      "('#### struc #### iteration ', 1)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.781\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.680\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.680\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.680\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.680\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.681\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.770\n",
      "Accuracy: 0.471\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.674\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.674\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.674\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.727\n",
      "Accuracy: 0.442\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.673\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.673\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.674\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.746\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.664\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.669\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.707\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.030\n",
      "Accuracy: 0.662\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.657\n",
      "Iteration: 600, 0.008\n",
      "Accuracy: 0.653\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.649\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.644\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.630\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.040\n",
      "Accuracy: 0.574\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.557\n",
      "Iteration: 600, 0.009\n",
      "Accuracy: 0.551\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.546\n",
      "Iteration: 1000, 0.004\n",
      "Accuracy: 0.543\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.539\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.538\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.536\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.536\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.908\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.093\n",
      "Accuracy: 0.514\n",
      "Iteration: 400, 0.062\n",
      "Accuracy: 0.511\n",
      "Iteration: 600, 0.026\n",
      "Accuracy: 0.517\n",
      "Iteration: 800, 0.026\n",
      "Accuracy: 0.510\n",
      "Iteration: 1000, 0.025\n",
      "Accuracy: 0.510\n",
      "Iteration: 1200, 0.021\n",
      "Accuracy: 0.509\n",
      "Iteration: 1400, 0.022\n",
      "Accuracy: 0.510\n",
      "Iteration: 1600, 0.072\n",
      "Accuracy: 0.505\n",
      "Iteration: 1800, 0.062\n",
      "Accuracy: 0.510\n",
      "('#### no noise ####   iteration ', 1)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.659\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.016\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.671\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 2)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.697\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.747\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.696\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.699\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.700\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.747\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.700\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.701\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.700\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.712\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.704\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.705\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.657\n",
      "Accuracy: 0.504\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.699\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.702\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.717\n",
      "Accuracy: 0.538\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.702\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.702\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.701\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.701\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.819\n",
      "Accuracy: 0.487\n",
      "Iteration: 200, 0.111\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.061\n",
      "Accuracy: 0.659\n",
      "Iteration: 600, 0.013\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.009\n",
      "Accuracy: 0.649\n",
      "Iteration: 1000, 0.009\n",
      "Accuracy: 0.633\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.633\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.004\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.626\n",
      "('#### struc #### iteration ', 2)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.674\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.700\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.703\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.749\n",
      "Accuracy: 0.518\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.692\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.692\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.694\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.695\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.694\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.677\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.704\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.704\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.705\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.768\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.699\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.699\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.699\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.738\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.679\n",
      "Iteration: 400, 0.007\n",
      "Accuracy: 0.675\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.668\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.666\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.666\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.664\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.662\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.869\n",
      "Accuracy: 0.479\n",
      "Iteration: 200, 0.032\n",
      "Accuracy: 0.567\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.550\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.542\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.537\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.532\n",
      "Iteration: 1200, 0.004\n",
      "Accuracy: 0.529\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.529\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.527\n",
      "Iteration: 1800, 0.002\n",
      "Accuracy: 0.524\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 1.134\n",
      "Accuracy: 0.537\n",
      "Iteration: 200, 0.193\n",
      "Accuracy: 0.508\n",
      "Iteration: 400, 0.062\n",
      "Accuracy: 0.500\n",
      "Iteration: 600, 0.045\n",
      "Accuracy: 0.494\n",
      "Iteration: 800, 0.046\n",
      "Accuracy: 0.493\n",
      "Iteration: 1000, 0.047\n",
      "Accuracy: 0.493\n",
      "Iteration: 1200, 0.012\n",
      "Accuracy: 0.491\n",
      "Iteration: 1400, 0.006\n",
      "Accuracy: 0.494\n",
      "Iteration: 1600, 0.024\n",
      "Accuracy: 0.493\n",
      "Iteration: 1800, 0.006\n",
      "Accuracy: 0.486\n",
      "('#### no noise ####   iteration ', 2)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.681\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.702\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 3)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.652\n",
      "Accuracy: 0.489\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.668\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.669\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.670\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.715\n",
      "Accuracy: 0.549\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.676\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.678\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.678\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.640\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.666\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.572\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.677\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.679\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.710\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.679\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.679\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.680\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.529\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.676\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.677\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.675\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.676\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.675\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.675\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.675\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.596\n",
      "Accuracy: 0.563\n",
      "Iteration: 200, 0.066\n",
      "Accuracy: 0.653\n",
      "Iteration: 400, 0.024\n",
      "Accuracy: 0.632\n",
      "Iteration: 600, 0.023\n",
      "Accuracy: 0.623\n",
      "Iteration: 800, 0.020\n",
      "Accuracy: 0.616\n",
      "Iteration: 1000, 0.037\n",
      "Accuracy: 0.617\n",
      "Iteration: 1200, 0.011\n",
      "Accuracy: 0.614\n",
      "Iteration: 1400, 0.005\n",
      "Accuracy: 0.603\n",
      "Iteration: 1600, 0.011\n",
      "Accuracy: 0.605\n",
      "Iteration: 1800, 0.010\n",
      "Accuracy: 0.600\n",
      "('#### struc #### iteration ', 3)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.755\n",
      "Accuracy: 0.512\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.667\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.670\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.795\n",
      "Accuracy: 0.494\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.667\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.672\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.714\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.683\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.684\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.684\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.683\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.683\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.682\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.681\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.723\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.672\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.673\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.674\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.752\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 0.016\n",
      "Accuracy: 0.659\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.657\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.655\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.654\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.652\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.647\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.704\n",
      "Accuracy: 0.499\n",
      "Iteration: 200, 0.044\n",
      "Accuracy: 0.577\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.555\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.544\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.544\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.539\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.535\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.533\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.531\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.531\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.750\n",
      "Accuracy: 0.550\n",
      "Iteration: 200, 0.051\n",
      "Accuracy: 0.511\n",
      "Iteration: 400, 0.098\n",
      "Accuracy: 0.507\n",
      "Iteration: 600, 0.022\n",
      "Accuracy: 0.505\n",
      "Iteration: 800, 0.049\n",
      "Accuracy: 0.502\n",
      "Iteration: 1000, 0.028\n",
      "Accuracy: 0.509\n",
      "Iteration: 1200, 0.039\n",
      "Accuracy: 0.504\n",
      "Iteration: 1400, 0.003\n",
      "Accuracy: 0.504\n",
      "Iteration: 1600, 0.005\n",
      "Accuracy: 0.504\n",
      "Iteration: 1800, 0.004\n",
      "Accuracy: 0.506\n",
      "('#### no noise ####   iteration ', 3)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.679\n",
      "Accuracy: 0.494\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.668\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.672\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 4)\n",
      "('Lamb', 1e-06)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, 0.744\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.645\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.647\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.649\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.717\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.654\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.652\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.650\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.687\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.648\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.541\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.645\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.645\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.743\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.652\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.651\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.651\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.474\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.641\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.641\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.641\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.056\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.020\n",
      "Accuracy: 0.624\n",
      "Iteration: 600, 0.033\n",
      "Accuracy: 0.616\n",
      "Iteration: 800, 0.021\n",
      "Accuracy: 0.617\n",
      "Iteration: 1000, 0.026\n",
      "Accuracy: 0.607\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.609\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.610\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.607\n",
      "Iteration: 1800, 0.007\n",
      "Accuracy: 0.595\n",
      "('#### struc #### iteration ', 4)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.746\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.649\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.650\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.649\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.649\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.746\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.728\n",
      "Accuracy: 0.510\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.647\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.646\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.706\n",
      "Accuracy: 0.535\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.648\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.649\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.648\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.648\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.674\n",
      "Accuracy: 0.511\n",
      "Iteration: 200, 0.021\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.007\n",
      "Accuracy: 0.635\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.633\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.633\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.633\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.633\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.631\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.630\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.770\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.053\n",
      "Accuracy: 0.566\n",
      "Iteration: 400, 0.018\n",
      "Accuracy: 0.551\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.542\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.538\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.538\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.537\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.535\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.534\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.533\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 1.135\n",
      "Accuracy: 0.551\n",
      "Iteration: 200, 0.118\n",
      "Accuracy: 0.516\n",
      "Iteration: 400, 0.046\n",
      "Accuracy: 0.514\n",
      "Iteration: 600, 0.024\n",
      "Accuracy: 0.509\n",
      "Iteration: 800, 0.016\n",
      "Accuracy: 0.503\n",
      "Iteration: 1000, 0.015\n",
      "Accuracy: 0.511\n",
      "Iteration: 1200, 0.009\n",
      "Accuracy: 0.512\n",
      "Iteration: 1400, 0.039\n",
      "Accuracy: 0.506\n",
      "Iteration: 1600, 0.046\n",
      "Accuracy: 0.502\n",
      "Iteration: 1800, 0.036\n",
      "Accuracy: 0.509\n",
      "('#### no noise ####   iteration ', 4)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.648\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.648\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.648\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 1000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68056, 0.02296654958847756)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6864600000000001, 0.020661229392269956)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68758, 0.022539955634384)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 10000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond_75/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond_75/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'cond_75/eye/MatrixDiag', defined at:\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-5d11152b021e>\", line 88, in <module>\n    acc_iid_i=training(lambdas, 'iid', max_iters)\n  File \"<ipython-input-9-5d11152b021e>\", line 11, in training\n    model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n  File \"<ipython-input-4-5317bbadfddf>\", line 36, in __init__\n    self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2048, in cond\n    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1895, in BuildCondBranch\n    original_result = fn()\n  File \"<ipython-input-4-5317bbadfddf>\", line 36, in <lambda>\n    self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n  File \"<ipython-input-4-5317bbadfddf>\", line 17, in dropout_layer\n    cov =  tf.eye(dim, dtype='float32')\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/linalg_ops.py\", line 167, in eye\n    name=name)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/linalg_ops_impl.py\", line 68, in eye\n    return array_ops.matrix_diag(diag_ones)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3950, in matrix_diag\n    \"MatrixDiag\", diagonal=diagonal, name=name)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond_75/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond_75/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond_75/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond_75/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5d11152b021e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#### iid  #### iteration '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0macc_iid_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0macc_iid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macc_iid_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5d11152b021e>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(seqlambda, mode, max_iters, learning_rate)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n\u001b[0;32m---> 26\u001b[0;31m                     model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                \u001b[0;31m# print(\"train_accuracy\",acc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond_75/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond_75/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'cond_75/eye/MatrixDiag', defined at:\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-5d11152b021e>\", line 88, in <module>\n    acc_iid_i=training(lambdas, 'iid', max_iters)\n  File \"<ipython-input-9-5d11152b021e>\", line 11, in training\n    model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n  File \"<ipython-input-4-5317bbadfddf>\", line 36, in __init__\n    self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2048, in cond\n    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1895, in BuildCondBranch\n    original_result = fn()\n  File \"<ipython-input-4-5317bbadfddf>\", line 36, in <lambda>\n    self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n  File \"<ipython-input-4-5317bbadfddf>\", line 17, in dropout_layer\n    cov =  tf.eye(dim, dtype='float32')\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/linalg_ops.py\", line 167, in eye\n    name=name)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/linalg_ops_impl.py\", line 68, in eye\n    return array_ops.matrix_diag(diag_ones)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3950, in matrix_diag\n    \"MatrixDiag\", diagonal=diagonal, name=name)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond_75/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond_75/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=10000, n_informative=1000, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 10000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n",
      "WARNING:tensorflow:From <ipython-input-3-5317bbadfddf>:18: MultivariateNormalFullCovariance.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_full_covariance) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py:194: MultivariateNormalTriL.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_tril) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_tril.py:221: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "Iteration: 0, 1.130\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.701\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.214\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.006\n",
      "Accuracy: 0.695\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.697\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.702\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.076\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.700\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.700\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.701\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.210\n",
      "Accuracy: 0.566\n",
      "Iteration: 200, 0.006\n",
      "Accuracy: 0.699\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.824\n",
      "Accuracy: 0.530\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "Lamb 0.1\n",
      "Iteration: 0, 1.266\n",
      "Accuracy: 0.472\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.705\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.705\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.705\n",
      "Lamb 1.0\n",
      "Iteration: 0, 1.197\n",
      "Accuracy: 0.395\n",
      "Iteration: 200, 0.096\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.027\n",
      "Accuracy: 0.681\n",
      "Iteration: 600, 0.025\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 0.025\n",
      "Accuracy: 0.679\n",
      "Iteration: 1000, 0.087\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.067\n",
      "Accuracy: 0.664\n",
      "Iteration: 1400, 0.004\n",
      "Accuracy: 0.688\n",
      "Iteration: 1600, 0.023\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.056\n",
      "Accuracy: 0.670\n",
      "#### struc #### iteration  0\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.981\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.702\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.704\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.706\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.706\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.707\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.707\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.707\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.194\n",
      "Accuracy: 0.581\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.708\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.708\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.891\n",
      "Accuracy: 0.550\n",
      "Iteration: 200, 0.066\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.703\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.608\n",
      "Accuracy: 0.472\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.702\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.708\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.709\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.704\n",
      "Lamb 0.01\n",
      "Iteration: 0, 4.496\n",
      "Accuracy: 0.567\n",
      "Iteration: 200, 0.041\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.684\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 0.017\n",
      "Accuracy: 0.683\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.682\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.679\n",
      "Iteration: 1400, 0.003\n",
      "Accuracy: 0.677\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.676\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.674\n",
      "Lamb 0.1\n",
      "Iteration: 0, 8.181\n",
      "Accuracy: 0.481\n",
      "Iteration: 200, 0.730\n",
      "Accuracy: 0.662\n",
      "Iteration: 400, 0.204\n",
      "Accuracy: 0.620\n",
      "Iteration: 600, 0.750\n",
      "Accuracy: 0.620\n",
      "Iteration: 800, 0.520\n",
      "Accuracy: 0.597\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.594\n",
      "Iteration: 1200, 0.382\n",
      "Accuracy: 0.582\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.583\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.568\n",
      "Iteration: 1800, 1.456\n",
      "Accuracy: 0.580\n",
      "Lamb 1.0\n",
      "Iteration: 0, 22.233\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 15.083\n",
      "Accuracy: 0.548\n",
      "Iteration: 400, 5.803\n",
      "Accuracy: 0.555\n",
      "Iteration: 600, 3.594\n",
      "Accuracy: 0.563\n",
      "Iteration: 800, 1.509\n",
      "Accuracy: 0.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, 0.603\n",
      "Accuracy: 0.549\n",
      "Iteration: 1200, 1.443\n",
      "Accuracy: 0.530\n",
      "Iteration: 1400, 1.505\n",
      "Accuracy: 0.528\n",
      "Iteration: 1600, 4.662\n",
      "Accuracy: 0.529\n",
      "Iteration: 1800, 17.571\n",
      "Accuracy: 0.524\n",
      "#### no noise ####   iteration  0\n",
      "Lamb None\n",
      "Iteration: 0, 1.041\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.006\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.699\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.702\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.829\n",
      "Accuracy: 0.493\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.644\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.643\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.643\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.644\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.644\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.644\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.644\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.049\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.643\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.644\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.644\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.644\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.645\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.001\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.648\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.650\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.649\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.650\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.597\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.646\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.889\n",
      "Accuracy: 0.530\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.650\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.652\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.650\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.865\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.649\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.648\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.653\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.654\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.652\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.651\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.882\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.074\n",
      "Accuracy: 0.653\n",
      "Iteration: 400, 0.015\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.008\n",
      "Accuracy: 0.657\n",
      "Iteration: 800, 0.014\n",
      "Accuracy: 0.645\n",
      "Iteration: 1000, 0.006\n",
      "Accuracy: 0.646\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.005\n",
      "Accuracy: 0.632\n",
      "Iteration: 1600, 0.007\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.107\n",
      "Accuracy: 0.620\n",
      "#### struc #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.944\n",
      "Accuracy: 0.500\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.644\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.739\n",
      "Accuracy: 0.520\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.646\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.759\n",
      "Accuracy: 0.577\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.653\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.657\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.655\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.655\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.656\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.231\n",
      "Accuracy: 0.483\n",
      "Iteration: 200, 0.026\n",
      "Accuracy: 0.666\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.675\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.666\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.878\n",
      "Accuracy: 0.527\n",
      "Iteration: 200, 0.048\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 0.010\n",
      "Accuracy: 0.662\n",
      "Iteration: 600, 0.011\n",
      "Accuracy: 0.658\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.656\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.654\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.654\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.652\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.650\n",
      "Iteration: 1800, 0.002\n",
      "Accuracy: 0.652\n",
      "Lamb 0.1\n",
      "Iteration: 0, 8.715\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 2.204\n",
      "Accuracy: 0.613\n",
      "Iteration: 400, 0.339\n",
      "Accuracy: 0.604\n",
      "Iteration: 600, 0.178\n",
      "Accuracy: 0.575\n",
      "Iteration: 800, 0.037\n",
      "Accuracy: 0.571\n",
      "Iteration: 1000, 0.047\n",
      "Accuracy: 0.566\n",
      "Iteration: 1200, 0.258\n",
      "Accuracy: 0.564\n",
      "Iteration: 1400, 0.047\n",
      "Accuracy: 0.568\n",
      "Iteration: 1600, 2.230\n",
      "Accuracy: 0.554\n",
      "Iteration: 1800, 0.024\n",
      "Accuracy: 0.556\n",
      "Lamb 1.0\n",
      "Iteration: 0, 11.002\n",
      "Accuracy: 0.489\n",
      "Iteration: 200, 4.863\n",
      "Accuracy: 0.577\n",
      "Iteration: 400, 1.833\n",
      "Accuracy: 0.550\n",
      "Iteration: 600, 0.750\n",
      "Accuracy: 0.533\n",
      "Iteration: 800, 7.783\n",
      "Accuracy: 0.526\n",
      "Iteration: 1000, 5.862\n",
      "Accuracy: 0.526\n",
      "Iteration: 1200, 0.548\n",
      "Accuracy: 0.516\n",
      "Iteration: 1400, 4.301\n",
      "Accuracy: 0.513\n",
      "Iteration: 1600, 3.490\n",
      "Accuracy: 0.519\n",
      "Iteration: 1800, 3.874\n",
      "Accuracy: 0.517\n",
      "#### no noise ####   iteration  1\n",
      "Lamb None\n",
      "Iteration: 0, 0.791\n",
      "Accuracy: 0.514\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.645\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.001\n",
      "Accuracy: 0.504\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.698\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.916\n",
      "Accuracy: 0.583\n",
      "Iteration: 200, 0.003\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.699\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.432\n",
      "Accuracy: 0.485\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.694\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.699\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.996\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.696\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.519\n",
      "Accuracy: 0.470\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.685\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.687\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.691\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.691\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.692\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.778\n",
      "Accuracy: 0.568\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.698\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.702\n",
      "Lamb 1.0\n",
      "Iteration: 0, 1.547\n",
      "Accuracy: 0.568\n",
      "Iteration: 200, 0.111\n",
      "Accuracy: 0.690\n",
      "Iteration: 400, 0.020\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.053\n",
      "Accuracy: 0.692\n",
      "Iteration: 800, 0.010\n",
      "Accuracy: 0.680\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.688\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.685\n",
      "Iteration: 1400, 0.010\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.006\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.069\n",
      "Accuracy: 0.658\n",
      "#### struc #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.062\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.693\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.695\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.112\n",
      "Accuracy: 0.504\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.689\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.689\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.690\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.690\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.302\n",
      "Accuracy: 0.475\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.700\n",
      "Lamb 0.001\n",
      "Iteration: 0, 2.146\n",
      "Accuracy: 0.482\n",
      "Iteration: 200, 0.020\n",
      "Accuracy: 0.698\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.701\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.701\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.701\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.703\n",
      "Lamb 0.01\n",
      "Iteration: 0, 2.743\n",
      "Accuracy: 0.467\n",
      "Iteration: 200, 0.043\n",
      "Accuracy: 0.683\n",
      "Iteration: 400, 0.013\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.683\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.687\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.684\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.684\n",
      "Iteration: 1400, 0.004\n",
      "Accuracy: 0.682\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.682\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.679\n",
      "Lamb 0.1\n",
      "Iteration: 0, 5.714\n",
      "Accuracy: 0.400\n",
      "Iteration: 200, 0.824\n",
      "Accuracy: 0.653\n",
      "Iteration: 400, 0.243\n",
      "Accuracy: 0.622\n",
      "Iteration: 600, 0.007\n",
      "Accuracy: 0.611\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.593\n",
      "Iteration: 1000, 0.648\n",
      "Accuracy: 0.574\n",
      "Iteration: 1200, 0.028\n",
      "Accuracy: 0.588\n",
      "Iteration: 1400, 0.005\n",
      "Accuracy: 0.583\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.566\n",
      "Iteration: 1800, 0.058\n",
      "Accuracy: 0.563\n",
      "Lamb 1.0\n",
      "Iteration: 0, 24.696\n",
      "Accuracy: 0.557\n",
      "Iteration: 200, 8.698\n",
      "Accuracy: 0.549\n",
      "Iteration: 400, 4.059\n",
      "Accuracy: 0.576\n",
      "Iteration: 600, 5.707\n",
      "Accuracy: 0.547\n",
      "Iteration: 800, 3.187\n",
      "Accuracy: 0.550\n",
      "Iteration: 1000, 2.105\n",
      "Accuracy: 0.549\n",
      "Iteration: 1200, 2.074\n",
      "Accuracy: 0.545\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.532\n",
      "Iteration: 1600, 6.954\n",
      "Accuracy: 0.533\n",
      "Iteration: 1800, 0.749\n",
      "Accuracy: 0.531\n",
      "#### no noise ####   iteration  2\n",
      "Lamb None\n",
      "Iteration: 0, 0.584\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.696\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.697\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.698\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.153\n",
      "Accuracy: 0.500\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.606\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.607\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.608\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.608\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.607\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.607\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.607\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.607\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.608\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.121\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.620\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.621\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.620\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.619\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.620\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.620\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.619\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.620\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.619\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.232\n",
      "Accuracy: 0.545\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.617\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.618\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.616\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.615\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.615\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.614\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.614\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.615\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.616\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.178\n",
      "Accuracy: 0.480\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.613\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.612\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.613\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.613\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.614\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.613\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.614\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.613\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.613\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.997\n",
      "Accuracy: 0.482\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.599\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.600\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.603\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.604\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.604\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.604\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.604\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.605\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.605\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.907\n",
      "Accuracy: 0.529\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.621\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.622\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.621\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.620\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.621\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.619\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.618\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.620\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.618\n",
      "Lamb 1.0\n",
      "Iteration: 0, 1.907\n",
      "Accuracy: 0.487\n",
      "Iteration: 200, 0.085\n",
      "Accuracy: 0.627\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.622\n",
      "Iteration: 600, 0.098\n",
      "Accuracy: 0.611\n",
      "Iteration: 800, 0.032\n",
      "Accuracy: 0.609\n",
      "Iteration: 1000, 0.007\n",
      "Accuracy: 0.600\n",
      "Iteration: 1200, 0.031\n",
      "Accuracy: 0.609\n",
      "Iteration: 1400, 0.009\n",
      "Accuracy: 0.611\n",
      "Iteration: 1600, 0.052\n",
      "Accuracy: 0.596\n",
      "Iteration: 1800, 0.003\n",
      "Accuracy: 0.607\n",
      "#### struc #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.137\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.615\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.613\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.612\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.611\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.612\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.611\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.611\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.611\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.611\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.376\n",
      "Accuracy: 0.492\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.606\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.610\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.612\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.612\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.613\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.613\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.614\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.614\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lamb 0.0001\n",
      "Iteration: 0, 0.809\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.620\n",
      "Iteration: 400, 0.008\n",
      "Accuracy: 0.626\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.626\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.624\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.625\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.626\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.628\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.628\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.626\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.361\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.021\n",
      "Accuracy: 0.623\n",
      "Iteration: 400, 0.008\n",
      "Accuracy: 0.631\n",
      "Iteration: 600, 0.011\n",
      "Accuracy: 0.630\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.631\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.632\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.631\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.630\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.629\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.630\n",
      "Lamb 0.01\n",
      "Iteration: 0, 3.102\n",
      "Accuracy: 0.564\n",
      "Iteration: 200, 0.075\n",
      "Accuracy: 0.631\n",
      "Iteration: 400, 0.018\n",
      "Accuracy: 0.625\n",
      "Iteration: 600, 0.008\n",
      "Accuracy: 0.622\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.616\n",
      "Iteration: 1000, 0.004\n",
      "Accuracy: 0.618\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.615\n",
      "Iteration: 1400, 0.005\n",
      "Accuracy: 0.613\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.612\n",
      "Iteration: 1800, 0.006\n",
      "Accuracy: 0.610\n",
      "Lamb 0.1\n",
      "Iteration: 0, 11.949\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.661\n",
      "Accuracy: 0.600\n",
      "Iteration: 400, 1.534\n",
      "Accuracy: 0.569\n",
      "Iteration: 600, 0.215\n",
      "Accuracy: 0.570\n",
      "Iteration: 800, 1.476\n",
      "Accuracy: 0.592\n",
      "Iteration: 1000, 0.541\n",
      "Accuracy: 0.564\n",
      "Iteration: 1200, 0.046\n",
      "Accuracy: 0.554\n",
      "Iteration: 1400, 0.029\n",
      "Accuracy: 0.544\n",
      "Iteration: 1600, 0.018\n",
      "Accuracy: 0.547\n",
      "Iteration: 1800, 0.003\n",
      "Accuracy: 0.534\n",
      "Lamb 1.0\n",
      "Iteration: 0, 14.629\n",
      "Accuracy: 0.429\n",
      "Iteration: 200, 5.677\n",
      "Accuracy: 0.543\n",
      "Iteration: 400, 3.561\n",
      "Accuracy: 0.539\n",
      "Iteration: 600, 3.334\n",
      "Accuracy: 0.544\n",
      "Iteration: 800, 8.444\n",
      "Accuracy: 0.533\n",
      "Iteration: 1000, 4.693\n",
      "Accuracy: 0.532\n",
      "Iteration: 1200, 4.631\n",
      "Accuracy: 0.526\n",
      "Iteration: 1400, 2.221\n",
      "Accuracy: 0.516\n",
      "Iteration: 1600, 2.333\n",
      "Accuracy: 0.514\n",
      "Iteration: 1800, 0.628\n",
      "Accuracy: 0.519\n",
      "#### no noise ####   iteration  3\n",
      "Lamb None\n",
      "Iteration: 0, 1.087\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.615\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.616\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.616\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.617\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.617\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.617\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.617\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.616\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.617\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.956\n",
      "Accuracy: 0.532\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.635\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.637\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.637\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.638\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.638\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.956\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.009\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.637\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.639\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.638\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.639\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.786\n",
      "Accuracy: 0.534\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.640\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.638\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.639\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.640\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.904\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.642\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.641\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.641\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.641\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.642\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.641\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.169\n",
      "Accuracy: 0.511\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.638\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.638\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.640\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.994\n",
      "Accuracy: 0.535\n",
      "Iteration: 200, 0.030\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.650\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.653\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.650\n",
      "Lamb 1.0\n",
      "Iteration: 0, 1.029\n",
      "Accuracy: 0.462\n",
      "Iteration: 200, 0.110\n",
      "Accuracy: 0.651\n",
      "Iteration: 400, 0.077\n",
      "Accuracy: 0.633\n",
      "Iteration: 600, 0.034\n",
      "Accuracy: 0.627\n",
      "Iteration: 800, 0.121\n",
      "Accuracy: 0.637\n",
      "Iteration: 1000, 0.015\n",
      "Accuracy: 0.632\n",
      "Iteration: 1200, 0.016\n",
      "Accuracy: 0.633\n",
      "Iteration: 1400, 0.070\n",
      "Accuracy: 0.629\n",
      "Iteration: 1600, 0.058\n",
      "Accuracy: 0.636\n",
      "Iteration: 1800, 0.031\n",
      "Accuracy: 0.616\n",
      "#### struc #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.294\n",
      "Accuracy: 0.550\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.636\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.635\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.634\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.633\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.634\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.634\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.635\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.127\n",
      "Accuracy: 0.518\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.639\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.642\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.642\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.643\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.063\n",
      "Accuracy: 0.485\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.643\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.644\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.784\n",
      "Accuracy: 0.503\n",
      "Iteration: 200, 0.019\n",
      "Accuracy: 0.657\n",
      "Iteration: 400, 0.008\n",
      "Accuracy: 0.658\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.654\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.654\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.653\n",
      "Lamb 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d1d89d81e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#### struc #### iteration '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0macc_struc_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'struc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0macc_struc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macc_struc_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#### no noise ####   iteration '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4d1d89d81e98>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(seqlambda, mode, max_iters, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0miters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=100, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 1000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65832, 0.016279975429956867)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.67628, 0.013198393841676362)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68212, 0.013086389876509098)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 2.114\n",
      "Accuracy: 0.563\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.654\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.655\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.656\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.656\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.657\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.657\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.658\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.658\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 2.290\n",
      "Accuracy: 0.565\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.665\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.665\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 2.150\n",
      "Accuracy: 0.499\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.652\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.651\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.896\n",
      "Accuracy: 0.599\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.661\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.663\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.665\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.667\n",
      "Lamb 0.01\n",
      "Iteration: 0, 3.255\n",
      "Accuracy: 0.526\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.659\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.659\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.660\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.660\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.660\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.661\n",
      "Lamb 0.1\n",
      "Iteration: 0, 3.254\n",
      "Accuracy: 0.566\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.660\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.665\n",
      "Iteration: 1000, 0.165\n",
      "Accuracy: 0.655\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.650\n",
      "Lamb 1.0\n",
      "Iteration: 0, 2.303\n",
      "Accuracy: 0.512\n",
      "Iteration: 200, 0.032\n",
      "Accuracy: 0.672\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.668\n",
      "Iteration: 800, 0.369\n",
      "Accuracy: 0.665\n",
      "Iteration: 1000, 0.048\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.424\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.396\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.107\n",
      "Accuracy: 0.665\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.666\n",
      "Lamb 10.0\n",
      "Iteration: 0, 6.126\n",
      "Accuracy: 0.534\n",
      "Iteration: 200, 3.265\n",
      "Accuracy: 0.681\n",
      "Iteration: 400, 4.263\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 6.626\n",
      "Accuracy: 0.689\n",
      "Iteration: 800, 2.613\n",
      "Accuracy: 0.693\n",
      "Iteration: 1000, 1.626\n",
      "Accuracy: 0.693\n",
      "Iteration: 1200, 5.209\n",
      "Accuracy: 0.680\n",
      "Iteration: 1400, 7.072\n",
      "Accuracy: 0.680\n",
      "Iteration: 1600, 0.873\n",
      "Accuracy: 0.684\n",
      "Iteration: 1800, 9.388\n",
      "Accuracy: 0.679\n",
      "#### struc #### iteration  0\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.923\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.662\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.662\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.662\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.661\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.660\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 2.847\n",
      "Accuracy: 0.500\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.656\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.658\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.657\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.655\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.655\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.655\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.656\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 2.092\n",
      "Accuracy: 0.503\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.064\n",
      "Accuracy: 0.637\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.655\n",
      "Iteration: 800, 0.013\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.028\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.665\n",
      "Iteration: 1600, 0.211\n",
      "Accuracy: 0.668\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.662\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.508\n",
      "Accuracy: 0.575\n",
      "Iteration: 200, 0.205\n",
      "Accuracy: 0.660\n",
      "Iteration: 400, 0.841\n",
      "Accuracy: 0.665\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 800, 0.290\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.438\n",
      "Accuracy: 0.681\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.669\n",
      "Iteration: 1400, 0.004\n",
      "Accuracy: 0.672\n",
      "Iteration: 1600, 0.607\n",
      "Accuracy: 0.670\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.665\n",
      "Lamb 0.01\n",
      "Iteration: 0, 7.854\n",
      "Accuracy: 0.493\n",
      "Iteration: 200, 1.227\n",
      "Accuracy: 0.681\n",
      "Iteration: 400, 1.416\n",
      "Accuracy: 0.685\n",
      "Iteration: 600, 2.854\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 1.612\n",
      "Accuracy: 0.681\n",
      "Iteration: 1000, 1.003\n",
      "Accuracy: 0.681\n",
      "Iteration: 1200, 2.184\n",
      "Accuracy: 0.684\n",
      "Iteration: 1400, 0.697\n",
      "Accuracy: 0.685\n",
      "Iteration: 1600, 2.702\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 2.648\n",
      "Accuracy: 0.681\n",
      "Lamb 0.1\n",
      "Iteration: 0, 21.957\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 15.819\n",
      "Accuracy: 0.662\n",
      "Iteration: 400, 26.357\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 6.627\n",
      "Accuracy: 0.681\n",
      "Iteration: 800, 10.917\n",
      "Accuracy: 0.686\n",
      "Iteration: 1000, 23.220\n",
      "Accuracy: 0.693\n",
      "Iteration: 1200, 20.900\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 21.493\n",
      "Accuracy: 0.694\n",
      "Iteration: 1600, 25.054\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 35.035\n",
      "Accuracy: 0.686\n",
      "Lamb 1.0\n",
      "Iteration: 0, 67.590\n",
      "Accuracy: 0.507\n",
      "Iteration: 200, 62.577\n",
      "Accuracy: 0.563\n",
      "Iteration: 400, 81.586\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 68.954\n",
      "Accuracy: 0.652\n",
      "Iteration: 800, 78.468\n",
      "Accuracy: 0.631\n",
      "Iteration: 1000, 64.106\n",
      "Accuracy: 0.679\n",
      "Iteration: 1200, 76.737\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 14.946\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 50.659\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 139.760\n",
      "Accuracy: 0.669\n",
      "Lamb 10.0\n",
      "Iteration: 0, 255.729\n",
      "Accuracy: 0.478\n",
      "Iteration: 200, 378.795\n",
      "Accuracy: 0.559\n",
      "Iteration: 400, 130.123\n",
      "Accuracy: 0.582\n",
      "Iteration: 600, 155.848\n",
      "Accuracy: 0.590\n",
      "Iteration: 800, 368.925\n",
      "Accuracy: 0.571\n",
      "Iteration: 1000, 340.211\n",
      "Accuracy: 0.554\n",
      "Iteration: 1200, 261.809\n",
      "Accuracy: 0.570\n",
      "Iteration: 1400, 437.152\n",
      "Accuracy: 0.537\n",
      "Iteration: 1600, 108.157\n",
      "Accuracy: 0.515\n",
      "Iteration: 1800, 221.917\n",
      "Accuracy: 0.591\n",
      "#### no noise ####   iteration  0\n",
      "Lamb None\n",
      "Iteration: 0, 2.630\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.679\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 2.852\n",
      "Accuracy: 0.564\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 2.205\n",
      "Accuracy: 0.508\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.662\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.668\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.668\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.669\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 2.953\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.682\n",
      "Lamb 0.001\n",
      "Iteration: 0, 2.924\n",
      "Accuracy: 0.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.667\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.674\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.809\n",
      "Accuracy: 0.575\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.671\n",
      "Lamb 0.1\n",
      "Iteration: 0, 2.674\n",
      "Accuracy: 0.554\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.654\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.675\n",
      "Lamb 1.0\n",
      "Iteration: 0, 3.795\n",
      "Accuracy: 0.554\n",
      "Iteration: 200, 0.322\n",
      "Accuracy: 0.672\n",
      "Iteration: 400, 0.831\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.537\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.401\n",
      "Accuracy: 0.674\n",
      "Iteration: 1000, 0.191\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 1.027\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 0.046\n",
      "Accuracy: 0.679\n",
      "Iteration: 1600, 0.564\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.491\n",
      "Accuracy: 0.673\n",
      "Lamb 10.0\n",
      "Iteration: 0, 8.046\n",
      "Accuracy: 0.512\n",
      "Iteration: 200, 2.349\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 2.872\n",
      "Accuracy: 0.668\n",
      "Iteration: 600, 5.756\n",
      "Accuracy: 0.663\n",
      "Iteration: 800, 1.510\n",
      "Accuracy: 0.664\n",
      "Iteration: 1000, 6.782\n",
      "Accuracy: 0.668\n",
      "Iteration: 1200, 8.623\n",
      "Accuracy: 0.657\n",
      "Iteration: 1400, 5.065\n",
      "Accuracy: 0.674\n",
      "Iteration: 1600, 5.509\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 5.004\n",
      "Accuracy: 0.673\n",
      "#### struc #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.794\n",
      "Accuracy: 0.526\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.676\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 2.965\n",
      "Accuracy: 0.485\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.674\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.677\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 2.010\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.042\n",
      "Accuracy: 0.666\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.662\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.589\n",
      "Accuracy: 0.532\n",
      "Iteration: 200, 0.002\n",
      "Accuracy: 0.666\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.677\n",
      "Iteration: 600, 0.999\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.675\n",
      "Lamb 0.01\n",
      "Iteration: 0, 3.562\n",
      "Accuracy: 0.512\n",
      "Iteration: 200, 4.368\n",
      "Accuracy: 0.659\n",
      "Iteration: 400, 2.553\n",
      "Accuracy: 0.668\n",
      "Iteration: 600, 4.317\n",
      "Accuracy: 0.669\n",
      "Iteration: 800, 0.903\n",
      "Accuracy: 0.683\n",
      "Iteration: 1000, 1.191\n",
      "Accuracy: 0.679\n",
      "Iteration: 1200, 6.176\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 7.161\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 11.327\n",
      "Accuracy: 0.673\n",
      "Iteration: 1800, 11.733\n",
      "Accuracy: 0.671\n",
      "Lamb 0.1\n",
      "Iteration: 0, 21.910\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 22.518\n",
      "Accuracy: 0.656\n",
      "Iteration: 400, 31.682\n",
      "Accuracy: 0.662\n",
      "Iteration: 600, 21.861\n",
      "Accuracy: 0.656\n",
      "Iteration: 800, 24.967\n",
      "Accuracy: 0.658\n",
      "Iteration: 1000, 18.629\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 21.007\n",
      "Accuracy: 0.668\n",
      "Iteration: 1400, 13.516\n",
      "Accuracy: 0.668\n",
      "Iteration: 1600, 12.858\n",
      "Accuracy: 0.673\n",
      "Iteration: 1800, 12.759\n",
      "Accuracy: 0.669\n",
      "Lamb 1.0\n",
      "Iteration: 0, 33.337\n",
      "Accuracy: 0.455\n",
      "Iteration: 200, 90.214\n",
      "Accuracy: 0.607\n",
      "Iteration: 400, 116.673\n",
      "Accuracy: 0.609\n",
      "Iteration: 600, 104.603\n",
      "Accuracy: 0.649\n",
      "Iteration: 800, 90.089\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 35.436\n",
      "Accuracy: 0.629\n",
      "Iteration: 1200, 18.181\n",
      "Accuracy: 0.635\n",
      "Iteration: 1400, 77.311\n",
      "Accuracy: 0.642\n",
      "Iteration: 1600, 67.204\n",
      "Accuracy: 0.641\n",
      "Iteration: 1800, 34.715\n",
      "Accuracy: 0.636\n",
      "Lamb 10.0\n",
      "Iteration: 0, 303.634\n",
      "Accuracy: 0.561\n",
      "Iteration: 200, 170.381\n",
      "Accuracy: 0.522\n",
      "Iteration: 400, 402.976\n",
      "Accuracy: 0.597\n",
      "Iteration: 600, 136.308\n",
      "Accuracy: 0.587\n",
      "Iteration: 800, 259.306\n",
      "Accuracy: 0.561\n",
      "Iteration: 1000, 126.835\n",
      "Accuracy: 0.594\n",
      "Iteration: 1200, 258.709\n",
      "Accuracy: 0.597\n",
      "Iteration: 1400, 297.903\n",
      "Accuracy: 0.593\n",
      "Iteration: 1600, 215.302\n",
      "Accuracy: 0.592\n",
      "Iteration: 1800, 162.366\n",
      "Accuracy: 0.588\n",
      "#### no noise ####   iteration  1\n",
      "Lamb None\n",
      "Iteration: 0, 3.079\n",
      "Accuracy: 0.564\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.684\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.678\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 4.406\n",
      "Accuracy: 0.473\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.677\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.677\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.678\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.678\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.725\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.683\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.683\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.682\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 2.436\n",
      "Accuracy: 0.556\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.671\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.937\n",
      "Accuracy: 0.545\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.680\n",
      "Lamb 0.01\n",
      "Iteration: 0, 2.675\n",
      "Accuracy: 0.490\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.670\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.674\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.675\n",
      "Lamb 0.1\n",
      "Iteration: 0, 2.606\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.677\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.668\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.668\n",
      "Lamb 1.0\n",
      "Iteration: 0, 2.337\n",
      "Accuracy: 0.527\n",
      "Iteration: 200, 0.346\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.058\n",
      "Accuracy: 0.677\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.675\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, 0.434\n",
      "Accuracy: 0.680\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.151\n",
      "Accuracy: 0.676\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.678\n",
      "Iteration: 1800, 1.980\n",
      "Accuracy: 0.670\n",
      "Lamb 10.0\n",
      "Iteration: 0, 6.254\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 3.851\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 4.129\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 2.550\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 9.088\n",
      "Accuracy: 0.694\n",
      "Iteration: 1000, 3.545\n",
      "Accuracy: 0.683\n",
      "Iteration: 1200, 6.355\n",
      "Accuracy: 0.685\n",
      "Iteration: 1400, 8.451\n",
      "Accuracy: 0.691\n",
      "Iteration: 1600, 4.203\n",
      "Accuracy: 0.689\n",
      "Iteration: 1800, 5.532\n",
      "Accuracy: 0.694\n",
      "#### struc #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.798\n",
      "Accuracy: 0.554\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.671\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.677\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.678\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.679\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 2.530\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.688\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.687\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.687\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.686\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 2.615\n",
      "Accuracy: 0.529\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.682\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.680\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.679\n",
      "Lamb 0.001\n",
      "Iteration: 0, 3.590\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.028\n",
      "Accuracy: 0.671\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.029\n",
      "Accuracy: 0.679\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.039\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.669\n",
      "Lamb 0.01\n",
      "Iteration: 0, 5.811\n",
      "Accuracy: 0.545\n",
      "Iteration: 200, 1.899\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 1.853\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 6.491\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.321\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 1.242\n",
      "Accuracy: 0.687\n",
      "Iteration: 1200, 1.244\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 1.054\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 1.167\n",
      "Accuracy: 0.692\n",
      "Iteration: 1800, 1.516\n",
      "Accuracy: 0.690\n",
      "Lamb 0.1\n",
      "Iteration: 0, 12.756\n",
      "Accuracy: 0.531\n",
      "Iteration: 200, 11.788\n",
      "Accuracy: 0.660\n",
      "Iteration: 400, 17.341\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 13.796\n",
      "Accuracy: 0.685\n",
      "Iteration: 800, 24.276\n",
      "Accuracy: 0.704\n",
      "Iteration: 1000, 20.712\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 16.043\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 32.176\n",
      "Accuracy: 0.689\n",
      "Iteration: 1600, 7.964\n",
      "Accuracy: 0.689\n",
      "Iteration: 1800, 30.721\n",
      "Accuracy: 0.700\n",
      "Lamb 1.0\n",
      "Iteration: 0, 44.885\n",
      "Accuracy: 0.516\n",
      "Iteration: 200, 120.481\n",
      "Accuracy: 0.590\n",
      "Iteration: 400, 63.664\n",
      "Accuracy: 0.612\n",
      "Iteration: 600, 79.965\n",
      "Accuracy: 0.648\n",
      "Iteration: 800, 72.423\n",
      "Accuracy: 0.601\n",
      "Iteration: 1000, 131.539\n",
      "Accuracy: 0.679\n",
      "Iteration: 1200, 51.131\n",
      "Accuracy: 0.655\n",
      "Iteration: 1400, 44.736\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 93.662\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 44.149\n",
      "Accuracy: 0.676\n",
      "Lamb 10.0\n",
      "Iteration: 0, 225.799\n",
      "Accuracy: 0.471\n",
      "Iteration: 200, 412.263\n",
      "Accuracy: 0.559\n",
      "Iteration: 400, 229.505\n",
      "Accuracy: 0.500\n",
      "Iteration: 600, 170.702\n",
      "Accuracy: 0.579\n",
      "Iteration: 800, 477.904\n",
      "Accuracy: 0.585\n",
      "Iteration: 1000, 276.735\n",
      "Accuracy: 0.603\n",
      "Iteration: 1200, 252.724\n",
      "Accuracy: 0.559\n",
      "Iteration: 1400, 528.476\n",
      "Accuracy: 0.568\n",
      "Iteration: 1600, 295.988\n",
      "Accuracy: 0.592\n",
      "Iteration: 1800, 294.486\n",
      "Accuracy: 0.603\n",
      "#### no noise ####   iteration  2\n",
      "Lamb None\n",
      "Iteration: 0, 2.307\n",
      "Accuracy: 0.555\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.675\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.676\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.676\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 2.362\n",
      "Accuracy: 0.530\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.698\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.659\n",
      "Accuracy: 0.573\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.684\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.684\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.684\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.684\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.685\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.686\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.687\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.688\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 3.665\n",
      "Accuracy: 0.471\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "Lamb 0.001\n",
      "Iteration: 0, 2.169\n",
      "Accuracy: 0.578\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.692\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.693\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.693\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.693\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.693\n",
      "Lamb 0.01\n",
      "Iteration: 0, 2.277\n",
      "Accuracy: 0.597\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.698\n",
      "Lamb 0.1\n",
      "Iteration: 0, 1.969\n",
      "Accuracy: 0.559\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.700\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.702\n",
      "Lamb 1.0\n",
      "Iteration: 0, 3.752\n",
      "Accuracy: 0.577\n",
      "Iteration: 200, 0.886\n",
      "Accuracy: 0.707\n",
      "Iteration: 400, 0.144\n",
      "Accuracy: 0.714\n",
      "Iteration: 600, 1.242\n",
      "Accuracy: 0.688\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.110\n",
      "Accuracy: 0.693\n",
      "Iteration: 1200, 0.280\n",
      "Accuracy: 0.699\n",
      "Iteration: 1400, 0.071\n",
      "Accuracy: 0.705\n",
      "Iteration: 1600, 0.320\n",
      "Accuracy: 0.705\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.708\n",
      "Lamb 10.0\n",
      "Iteration: 0, 11.675\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 2.338\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 2.802\n",
      "Accuracy: 0.728\n",
      "Iteration: 600, 2.966\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 5.373\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 4.280\n",
      "Accuracy: 0.728\n",
      "Iteration: 1200, 6.828\n",
      "Accuracy: 0.711\n",
      "Iteration: 1400, 1.748\n",
      "Accuracy: 0.717\n",
      "Iteration: 1600, 2.775\n",
      "Accuracy: 0.712\n",
      "Iteration: 1800, 1.936\n",
      "Accuracy: 0.707\n",
      "#### struc #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 2.463\n",
      "Accuracy: 0.562\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.706\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.706\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.706\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 3.044\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 2.316\n",
      "Accuracy: 0.572\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.706\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.708\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.713\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.716\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.715\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.715\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.714\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.707\n",
      "Lamb 0.001\n",
      "Iteration: 0, 3.686\n",
      "Accuracy: 0.573\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.707\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 800, 0.074\n",
      "Accuracy: 0.707\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1800, 0.687\n",
      "Accuracy: 0.697\n",
      "Lamb 0.01\n",
      "Iteration: 0, 9.151\n",
      "Accuracy: 0.552\n",
      "Iteration: 200, 2.754\n",
      "Accuracy: 0.714\n",
      "Iteration: 400, 2.350\n",
      "Accuracy: 0.718\n",
      "Iteration: 600, 4.711\n",
      "Accuracy: 0.716\n",
      "Iteration: 800, 1.141\n",
      "Accuracy: 0.724\n",
      "Iteration: 1000, 1.731\n",
      "Accuracy: 0.717\n",
      "Iteration: 1200, 0.391\n",
      "Accuracy: 0.712\n",
      "Iteration: 1400, 1.734\n",
      "Accuracy: 0.708\n",
      "Iteration: 1600, 0.935\n",
      "Accuracy: 0.717\n",
      "Iteration: 1800, 1.759\n",
      "Accuracy: 0.709\n",
      "Lamb 0.1\n",
      "Iteration: 0, 41.980\n",
      "Accuracy: 0.473\n",
      "Iteration: 200, 36.269\n",
      "Accuracy: 0.706\n",
      "Iteration: 400, 63.695\n",
      "Accuracy: 0.699\n",
      "Iteration: 600, 31.961\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 20.161\n",
      "Accuracy: 0.720\n",
      "Iteration: 1000, 28.596\n",
      "Accuracy: 0.718\n",
      "Iteration: 1200, 2.419\n",
      "Accuracy: 0.724\n",
      "Iteration: 1400, 14.918\n",
      "Accuracy: 0.723\n",
      "Iteration: 1600, 3.308\n",
      "Accuracy: 0.729\n",
      "Iteration: 1800, 16.269\n",
      "Accuracy: 0.725\n",
      "Lamb 1.0\n",
      "Iteration: 0, 50.552\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 149.529\n",
      "Accuracy: 0.656\n",
      "Iteration: 400, 207.724\n",
      "Accuracy: 0.654\n",
      "Iteration: 600, 105.339\n",
      "Accuracy: 0.685\n",
      "Iteration: 800, 119.213\n",
      "Accuracy: 0.702\n",
      "Iteration: 1000, 49.701\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 59.082\n",
      "Accuracy: 0.692\n",
      "Iteration: 1400, 135.965\n",
      "Accuracy: 0.712\n",
      "Iteration: 1600, 106.486\n",
      "Accuracy: 0.707\n",
      "Iteration: 1800, 56.019\n",
      "Accuracy: 0.730\n",
      "Lamb 10.0\n",
      "Iteration: 0, 150.967\n",
      "Accuracy: 0.535\n",
      "Iteration: 200, 120.522\n",
      "Accuracy: 0.555\n",
      "Iteration: 400, 358.572\n",
      "Accuracy: 0.649\n",
      "Iteration: 600, 242.109\n",
      "Accuracy: 0.609\n",
      "Iteration: 800, 163.423\n",
      "Accuracy: 0.634\n",
      "Iteration: 1000, 332.246\n",
      "Accuracy: 0.628\n",
      "Iteration: 1200, 293.856\n",
      "Accuracy: 0.677\n",
      "Iteration: 1400, 217.854\n",
      "Accuracy: 0.675\n",
      "Iteration: 1600, 171.928\n",
      "Accuracy: 0.663\n",
      "Iteration: 1800, 188.748\n",
      "Accuracy: 0.668\n",
      "#### no noise ####   iteration  3\n",
      "Lamb None\n",
      "Iteration: 0, 3.614\n",
      "Accuracy: 0.563\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.702\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 2.996\n",
      "Accuracy: 0.587\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.631\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.633\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.634\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.635\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.635\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.635\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.635\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.635\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 2.402\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.649\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.650\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.488\n",
      "Accuracy: 0.510\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.640\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.640\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.641\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.641\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.639\n",
      "Lamb 0.001\n",
      "Iteration: 0, 2.631\n",
      "Accuracy: 0.579\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.631\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.631\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.631\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.631\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.472\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.634\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.636\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.637\n",
      "Lamb 0.1\n",
      "Iteration: 0, 3.027\n",
      "Accuracy: 0.588\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.652\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.621\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.622\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.624\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.642\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.649\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.648\n",
      "Lamb 1.0\n",
      "Iteration: 0, 3.387\n",
      "Accuracy: 0.492\n",
      "Iteration: 200, 0.193\n",
      "Accuracy: 0.654\n",
      "Iteration: 400, 0.022\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.412\n",
      "Accuracy: 0.634\n",
      "Iteration: 800, 0.034\n",
      "Accuracy: 0.650\n",
      "Iteration: 1000, 0.316\n",
      "Accuracy: 0.641\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 0.426\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.026\n",
      "Accuracy: 0.642\n",
      "Lamb 10.0\n",
      "Iteration: 0, 7.641\n",
      "Accuracy: 0.484\n",
      "Iteration: 200, 7.673\n",
      "Accuracy: 0.648\n",
      "Iteration: 400, 2.956\n",
      "Accuracy: 0.662\n",
      "Iteration: 600, 3.413\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 3.908\n",
      "Accuracy: 0.637\n",
      "Iteration: 1000, 1.486\n",
      "Accuracy: 0.643\n",
      "Iteration: 1200, 3.113\n",
      "Accuracy: 0.662\n",
      "Iteration: 1400, 3.690\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 3.072\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 5.116\n",
      "Accuracy: 0.652\n",
      "#### struc #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 3.092\n",
      "Accuracy: 0.595\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.613\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.614\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.615\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.616\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.617\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.617\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.619\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.621\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.621\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.901\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.631\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.632\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.633\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.634\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.635\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.635\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 2.372\n",
      "Accuracy: 0.512\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.634\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.024\n",
      "Accuracy: 0.643\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.653\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.642\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.640\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.635\n",
      "Lamb 0.001\n",
      "Iteration: 0, 3.210\n",
      "Accuracy: 0.583\n",
      "Iteration: 200, 0.109\n",
      "Accuracy: 0.638\n",
      "Iteration: 400, 0.195\n",
      "Accuracy: 0.639\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.638\n",
      "Iteration: 800, 0.603\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1200, 0.080\n",
      "Accuracy: 0.644\n",
      "Iteration: 1400, 0.610\n",
      "Accuracy: 0.636\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.644\n",
      "Lamb 0.01\n",
      "Iteration: 0, 5.620\n",
      "Accuracy: 0.543\n",
      "Iteration: 200, 3.041\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 7.795\n",
      "Accuracy: 0.656\n",
      "Iteration: 600, 1.285\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.780\n",
      "Accuracy: 0.649\n",
      "Iteration: 1000, 1.500\n",
      "Accuracy: 0.644\n",
      "Iteration: 1200, 0.369\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.041\n",
      "Accuracy: 0.645\n",
      "Iteration: 1600, 2.472\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 2.876\n",
      "Accuracy: 0.646\n",
      "Lamb 0.1\n",
      "Iteration: 0, 36.068\n",
      "Accuracy: 0.517\n",
      "Iteration: 200, 34.440\n",
      "Accuracy: 0.640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 400, 18.260\n",
      "Accuracy: 0.659\n",
      "Iteration: 600, 16.441\n",
      "Accuracy: 0.644\n",
      "Iteration: 800, 29.872\n",
      "Accuracy: 0.656\n",
      "Iteration: 1000, 14.208\n",
      "Accuracy: 0.653\n",
      "Iteration: 1200, 38.082\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 17.657\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 7.945\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 28.334\n",
      "Accuracy: 0.648\n",
      "Lamb 1.0\n",
      "Iteration: 0, 35.525\n",
      "Accuracy: 0.523\n",
      "Iteration: 200, 31.753\n",
      "Accuracy: 0.625\n",
      "Iteration: 400, 74.542\n",
      "Accuracy: 0.623\n",
      "Iteration: 600, 101.606\n",
      "Accuracy: 0.617\n",
      "Iteration: 800, 19.416\n",
      "Accuracy: 0.635\n",
      "Iteration: 1000, 69.731\n",
      "Accuracy: 0.600\n",
      "Iteration: 1200, 56.408\n",
      "Accuracy: 0.616\n",
      "Iteration: 1400, 42.757\n",
      "Accuracy: 0.617\n",
      "Iteration: 1600, 49.563\n",
      "Accuracy: 0.638\n",
      "Iteration: 1800, 48.209\n",
      "Accuracy: 0.622\n",
      "Lamb 10.0\n",
      "Iteration: 0, 189.104\n",
      "Accuracy: 0.507\n",
      "Iteration: 200, 231.332\n",
      "Accuracy: 0.573\n",
      "Iteration: 400, 463.693\n",
      "Accuracy: 0.594\n",
      "Iteration: 600, 584.205\n",
      "Accuracy: 0.553\n",
      "Iteration: 800, 640.043\n",
      "Accuracy: 0.602\n",
      "Iteration: 1000, 167.913\n",
      "Accuracy: 0.561\n",
      "Iteration: 1200, 278.926\n",
      "Accuracy: 0.566\n",
      "Iteration: 1400, 102.213\n",
      "Accuracy: 0.595\n",
      "Iteration: 1600, 272.854\n",
      "Accuracy: 0.587\n",
      "Iteration: 1800, 218.249\n",
      "Accuracy: 0.613\n",
      "#### no noise ####   iteration  4\n",
      "Lamb None\n",
      "Iteration: 0, 1.807\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.000\n",
      "Accuracy: 0.624\n",
      "Iteration: 400, 0.000\n",
      "Accuracy: 0.625\n",
      "Iteration: 600, 0.000\n",
      "Accuracy: 0.625\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.624\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.624\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.624\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.624\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.624\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0,1e+1]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=800, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 1000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
