{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In odrer to compare structured dropout and iid dropout in a linear model regime, we use the simulations embedded in sklearn (which make use of the Madelon synthetic dataset, see references in http://archive.ics.uci.edu/ml/datasets/madelon )\n",
    "we vary: \n",
    "- the number of variables of redundant variables\n",
    "- the number of overall variables \n",
    "\n",
    "we assess classification accuracy on a test set drawn from the same simulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "\n",
    "x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "x_train=x_all[range(100),]\n",
    "y_train=y_all[range(100),]\n",
    "x_test=x_all[101:,]\n",
    "y_test=y_all[101:]\n",
    "\n",
    "\n",
    "dim = 1000 \n",
    "nb_train = x_train.shape[0]\n",
    "nb_test = x_test.shape[0]\n",
    "nb_classes=1\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(nb_train, 'train samples')\n",
    "print(nb_test, 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = to_categorical(y_train, nb_classes)\n",
    "#y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "y_train=y_train.reshape(nb_train,1)\n",
    "y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.distributions import MultivariateNormalFullCovariance as mvnfc\n",
    "\n",
    "\n",
    "def dropout_layer(x, mode, l, dim):\n",
    "\n",
    "    if mode == 'struc':\n",
    "        xm = tf.reduce_mean(x, 0)\n",
    "        cov = tf.matmul(tf.transpose(x-xm), x-xm) / batch_size\n",
    "        cov += 1e-2 * tf.eye(dim, dtype='float32')\n",
    "       # dia=tf.sqrt(tf.diag(1/tf.diag_part(cov)))\n",
    "       # corr= tf.matmul(tf.matmul(dia,cov),dia)\n",
    "        sample = mvnfc(tf.zeros(shape=[dim]), cov).sample()\n",
    "        return tf.multiply(x, np.sqrt(l)* sample + tf.ones(shape=[dim]))\n",
    "\n",
    "    elif mode == 'iid':\n",
    "      # mu = tf.Variable(lambda : tf.ones(shape=[dim]))\n",
    "        cov =  tf.eye(dim, dtype='float32')\n",
    "        sample = mvnfc(tf.zeros(shape=[dim]), cov).sample()\n",
    "        return tf.multiply(x, np.sqrt(l)* sample + tf.ones(shape=[dim]))\n",
    "\n",
    "    else:  # no dropout\n",
    "        return x\n",
    "\n",
    "\n",
    "class Linear_Model:\n",
    "\n",
    "    def __init__(self, dim, nb_classes, batch_size, l, mode=None):\n",
    "\n",
    "        self.X = tf.placeholder(tf.float32, [None, dim])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "        self.train = tf.placeholder(tf.bool)\n",
    "\n",
    "        W = tf.Variable(tf.random_uniform([dim, nb_classes], -0.01, 0.01))  # model weights\n",
    "        b = tf.Variable(tf.zeros(shape=[nb_classes]))                       # model biases\n",
    "\n",
    "        self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n",
    "        x = tf.matmul(self.dl, W) + b\n",
    "\n",
    "        # Minimize error using cross entropy\n",
    "        self.probs = tf.nn.sigmoid(x)\n",
    "        log_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=x, labels=self.Y)\n",
    "        self.mean_log_loss = tf.reduce_mean(log_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred, dl = sess.run([model.probs, model.dl],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    cor_norms.append(np.linalg.norm(np.corrcoef((dl + 1e-10 * np.random.rand(*dl.shape)).T)))\n",
    "                    print(cor_norms[-1])\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "\n",
    "            all_accuracies.append(accs)\n",
    "            all_cor_norms.append(cor_norms)\n",
    "\n",
    "    return all_accuracies, all_cor_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5525, 0.512]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.max(accs) for accs in acc_struc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[np.max(accs) for accs in acc_iid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training of the linear model, we simulate on 10 runs a set of 100 points with parameters listed in the paper, the model is either regularised using iid Gaussian dropout, Structured dropout (ASNI), or without regularisation. We test the model on each run, and for all regularisation parameters on one test dataset with 10,000 points, then average the accuracy on the 10 runs (and compute the standard deviation).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n",
      "WARNING:tensorflow:From <ipython-input-4-5317bbadfddf>:18: MultivariateNormalFullCovariance.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_full_covariance) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py:194: MultivariateNormalTriL.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_tril) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_tril.py:221: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.315\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.345\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.219\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.187\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.146\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.109\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.214\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.115\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.089\n",
      "Accuracy: 0.657\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.689\n",
      "Accuracy: 0.547\n",
      "Iteration: 200, 0.341\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.291\n",
      "Accuracy: 0.681\n",
      "Iteration: 600, 0.225\n",
      "Accuracy: 0.676\n",
      "Iteration: 800, 0.161\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.185\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.265\n",
      "Accuracy: 0.665\n",
      "Iteration: 1400, 0.129\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.087\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.114\n",
      "Accuracy: 0.658\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.364\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.260\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.189\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.202\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.160\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.198\n",
      "Accuracy: 0.662\n",
      "Iteration: 1400, 0.146\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.125\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.102\n",
      "Accuracy: 0.657\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.311\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.310\n",
      "Accuracy: 0.679\n",
      "Iteration: 600, 0.224\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.188\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.159\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.204\n",
      "Accuracy: 0.665\n",
      "Iteration: 1400, 0.158\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.095\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.095\n",
      "Accuracy: 0.657\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.481\n",
      "Iteration: 200, 0.366\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.310\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.271\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.175\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.233\n",
      "Accuracy: 0.666\n",
      "Iteration: 1200, 0.133\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.088\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.122\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.095\n",
      "Accuracy: 0.655\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.458\n",
      "Iteration: 200, 0.362\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.364\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.236\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.258\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.117\n",
      "Accuracy: 0.665\n",
      "Iteration: 1200, 0.174\n",
      "Accuracy: 0.662\n",
      "Iteration: 1400, 0.189\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.209\n",
      "Accuracy: 0.658\n",
      "Iteration: 1800, 0.167\n",
      "Accuracy: 0.654\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.579\n",
      "Iteration: 200, 0.469\n",
      "Accuracy: 0.670\n",
      "Iteration: 400, 0.384\n",
      "Accuracy: 0.663\n",
      "Iteration: 600, 0.446\n",
      "Accuracy: 0.657\n",
      "Iteration: 800, 0.646\n",
      "Accuracy: 0.656\n",
      "Iteration: 1000, 0.479\n",
      "Accuracy: 0.654\n",
      "Iteration: 1200, 0.400\n",
      "Accuracy: 0.655\n",
      "Iteration: 1400, 0.263\n",
      "Accuracy: 0.656\n",
      "Iteration: 1600, 0.191\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 0.256\n",
      "Accuracy: 0.653\n",
      "#### struc #### iteration  0\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.688\n",
      "Accuracy: 0.568\n",
      "Iteration: 200, 0.439\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.310\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.298\n",
      "Accuracy: 0.675\n",
      "Iteration: 800, 0.170\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.159\n",
      "Accuracy: 0.668\n",
      "Iteration: 1200, 0.145\n",
      "Accuracy: 0.664\n",
      "Iteration: 1400, 0.158\n",
      "Accuracy: 0.663\n",
      "Iteration: 1600, 0.094\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.092\n",
      "Accuracy: 0.658\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.297\n",
      "Accuracy: 0.678\n",
      "Iteration: 400, 0.253\n",
      "Accuracy: 0.679\n",
      "Iteration: 600, 0.221\n",
      "Accuracy: 0.675\n",
      "Iteration: 800, 0.143\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.156\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.145\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.138\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.137\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.101\n",
      "Accuracy: 0.658\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.435\n",
      "Iteration: 200, 0.411\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.336\n",
      "Accuracy: 0.675\n",
      "Iteration: 600, 0.243\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.217\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.190\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.223\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.111\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.116\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.085\n",
      "Accuracy: 0.658\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.689\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.350\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.277\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.230\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.141\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.172\n",
      "Accuracy: 0.665\n",
      "Iteration: 1200, 0.175\n",
      "Accuracy: 0.664\n",
      "Iteration: 1400, 0.174\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.100\n",
      "Accuracy: 0.661\n",
      "Iteration: 1800, 0.123\n",
      "Accuracy: 0.657\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.324\n",
      "Accuracy: 0.679\n",
      "Iteration: 400, 0.243\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.248\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.186\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.140\n",
      "Accuracy: 0.661\n",
      "Iteration: 1200, 0.129\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.145\n",
      "Accuracy: 0.654\n",
      "Iteration: 1600, 0.162\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.102\n",
      "Accuracy: 0.651\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.389\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 0.219\n",
      "Accuracy: 0.649\n",
      "Iteration: 600, 0.323\n",
      "Accuracy: 0.645\n",
      "Iteration: 800, 0.256\n",
      "Accuracy: 0.637\n",
      "Iteration: 1000, 0.288\n",
      "Accuracy: 0.634\n",
      "Iteration: 1200, 0.237\n",
      "Accuracy: 0.625\n",
      "Iteration: 1400, 0.381\n",
      "Accuracy: 0.617\n",
      "Iteration: 1600, 0.302\n",
      "Accuracy: 0.615\n",
      "Iteration: 1800, 0.215\n",
      "Accuracy: 0.611\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.528\n",
      "Accuracy: 0.605\n",
      "Iteration: 400, 0.526\n",
      "Accuracy: 0.588\n",
      "Iteration: 600, 0.687\n",
      "Accuracy: 0.565\n",
      "Iteration: 800, 0.327\n",
      "Accuracy: 0.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, 0.534\n",
      "Accuracy: 0.564\n",
      "Iteration: 1200, 0.293\n",
      "Accuracy: 0.569\n",
      "Iteration: 1400, 0.354\n",
      "Accuracy: 0.558\n",
      "Iteration: 1600, 0.532\n",
      "Accuracy: 0.551\n",
      "Iteration: 1800, 0.415\n",
      "Accuracy: 0.556\n",
      "#### no noise ####   iteration  0\n",
      "Lamb None\n",
      "Iteration: 0, 0.671\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.384\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.283\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.247\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.174\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.134\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.138\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.104\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.148\n",
      "Accuracy: 0.658\n",
      "Iteration: 1800, 0.124\n",
      "Accuracy: 0.658\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.547\n",
      "Iteration: 200, 0.379\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.322\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.270\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.181\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.139\n",
      "Accuracy: 0.661\n",
      "Iteration: 1200, 0.110\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.076\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.073\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.068\n",
      "Accuracy: 0.657\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.408\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.247\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.201\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.163\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.102\n",
      "Accuracy: 0.662\n",
      "Iteration: 1200, 0.128\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.097\n",
      "Accuracy: 0.659\n",
      "Iteration: 1600, 0.067\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.067\n",
      "Accuracy: 0.654\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.672\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.318\n",
      "Accuracy: 0.676\n",
      "Iteration: 400, 0.225\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.161\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.172\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.125\n",
      "Accuracy: 0.658\n",
      "Iteration: 1200, 0.168\n",
      "Accuracy: 0.658\n",
      "Iteration: 1400, 0.118\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.083\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.055\n",
      "Accuracy: 0.655\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.311\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.261\n",
      "Accuracy: 0.671\n",
      "Iteration: 600, 0.180\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.168\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.119\n",
      "Accuracy: 0.663\n",
      "Iteration: 1200, 0.108\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.087\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.086\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.067\n",
      "Accuracy: 0.655\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.311\n",
      "Accuracy: 0.686\n",
      "Iteration: 400, 0.294\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.205\n",
      "Accuracy: 0.663\n",
      "Iteration: 800, 0.149\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.109\n",
      "Accuracy: 0.659\n",
      "Iteration: 1200, 0.128\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.073\n",
      "Accuracy: 0.656\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.688\n",
      "Accuracy: 0.571\n",
      "Iteration: 200, 0.382\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.301\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.216\n",
      "Accuracy: 0.668\n",
      "Iteration: 800, 0.202\n",
      "Accuracy: 0.663\n",
      "Iteration: 1000, 0.229\n",
      "Accuracy: 0.657\n",
      "Iteration: 1200, 0.154\n",
      "Accuracy: 0.658\n",
      "Iteration: 1400, 0.121\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.145\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 0.069\n",
      "Accuracy: 0.654\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.699\n",
      "Accuracy: 0.569\n",
      "Iteration: 200, 0.527\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.415\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.275\n",
      "Accuracy: 0.663\n",
      "Iteration: 800, 0.246\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.287\n",
      "Accuracy: 0.655\n",
      "Iteration: 1200, 0.234\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.314\n",
      "Accuracy: 0.653\n",
      "Iteration: 1600, 0.749\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 0.238\n",
      "Accuracy: 0.646\n",
      "#### struc #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.329\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.260\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.172\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.145\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.169\n",
      "Accuracy: 0.660\n",
      "Iteration: 1200, 0.110\n",
      "Accuracy: 0.659\n",
      "Iteration: 1400, 0.115\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.078\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.060\n",
      "Accuracy: 0.655\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.580\n",
      "Iteration: 200, 0.370\n",
      "Accuracy: 0.684\n",
      "Iteration: 400, 0.254\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.217\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.165\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.162\n",
      "Accuracy: 0.661\n",
      "Iteration: 1200, 0.104\n",
      "Accuracy: 0.659\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.101\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.056\n",
      "Accuracy: 0.655\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.592\n",
      "Iteration: 200, 0.293\n",
      "Accuracy: 0.681\n",
      "Iteration: 400, 0.260\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.227\n",
      "Accuracy: 0.665\n",
      "Iteration: 800, 0.182\n",
      "Accuracy: 0.659\n",
      "Iteration: 1000, 0.154\n",
      "Accuracy: 0.657\n",
      "Iteration: 1200, 0.111\n",
      "Accuracy: 0.657\n",
      "Iteration: 1400, 0.090\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.088\n",
      "Accuracy: 0.655\n",
      "Iteration: 1800, 0.067\n",
      "Accuracy: 0.654\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.330\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.241\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.231\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.221\n",
      "Accuracy: 0.663\n",
      "Iteration: 1000, 0.147\n",
      "Accuracy: 0.662\n",
      "Iteration: 1200, 0.110\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.655\n",
      "Iteration: 1600, 0.080\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.060\n",
      "Accuracy: 0.653\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.554\n",
      "Iteration: 200, 0.329\n",
      "Accuracy: 0.684\n",
      "Iteration: 400, 0.221\n",
      "Accuracy: 0.668\n",
      "Iteration: 600, 0.235\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.146\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.123\n",
      "Accuracy: 0.659\n",
      "Iteration: 1200, 0.120\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.110\n",
      "Accuracy: 0.654\n",
      "Iteration: 1600, 0.089\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.075\n",
      "Accuracy: 0.650\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.485\n",
      "Accuracy: 0.670\n",
      "Iteration: 400, 0.356\n",
      "Accuracy: 0.655\n",
      "Iteration: 600, 0.313\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.265\n",
      "Accuracy: 0.644\n",
      "Iteration: 1000, 0.235\n",
      "Accuracy: 0.641\n",
      "Iteration: 1200, 0.171\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.151\n",
      "Accuracy: 0.631\n",
      "Iteration: 1600, 0.121\n",
      "Accuracy: 0.628\n",
      "Iteration: 1800, 0.161\n",
      "Accuracy: 0.626\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.660\n",
      "Accuracy: 0.583\n",
      "Iteration: 200, 0.541\n",
      "Accuracy: 0.614\n",
      "Iteration: 400, 0.380\n",
      "Accuracy: 0.598\n",
      "Iteration: 600, 0.516\n",
      "Accuracy: 0.594\n",
      "Iteration: 800, 0.312\n",
      "Accuracy: 0.583\n",
      "Iteration: 1000, 0.459\n",
      "Accuracy: 0.577\n",
      "Iteration: 1200, 0.659\n",
      "Accuracy: 0.576\n",
      "Iteration: 1400, 0.373\n",
      "Accuracy: 0.578\n",
      "Iteration: 1600, 0.466\n",
      "Accuracy: 0.577\n",
      "Iteration: 1800, 0.407\n",
      "Accuracy: 0.573\n",
      "#### no noise ####   iteration  1\n",
      "Lamb None\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.523\n",
      "Iteration: 200, 0.333\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.251\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.196\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.199\n",
      "Accuracy: 0.660\n",
      "Iteration: 1000, 0.137\n",
      "Accuracy: 0.659\n",
      "Iteration: 1200, 0.116\n",
      "Accuracy: 0.659\n",
      "Iteration: 1400, 0.074\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.094\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.050\n",
      "Accuracy: 0.655\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.334\n",
      "Accuracy: 0.641\n",
      "Iteration: 400, 0.272\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.157\n",
      "Accuracy: 0.642\n",
      "Iteration: 800, 0.138\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.131\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.090\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.057\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.052\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.034\n",
      "Accuracy: 0.632\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.676\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.351\n",
      "Accuracy: 0.641\n",
      "Iteration: 400, 0.236\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.172\n",
      "Accuracy: 0.641\n",
      "Iteration: 800, 0.124\n",
      "Accuracy: 0.640\n",
      "Iteration: 1000, 0.119\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.075\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.063\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.063\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.047\n",
      "Accuracy: 0.632\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.687\n",
      "Accuracy: 0.584\n",
      "Iteration: 200, 0.406\n",
      "Accuracy: 0.638\n",
      "Iteration: 400, 0.285\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.155\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.135\n",
      "Accuracy: 0.640\n",
      "Iteration: 1000, 0.107\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.093\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.057\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.076\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.047\n",
      "Accuracy: 0.632\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.699\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.369\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.256\n",
      "Accuracy: 0.644\n",
      "Iteration: 600, 0.186\n",
      "Accuracy: 0.643\n",
      "Iteration: 800, 0.123\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.122\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.069\n",
      "Accuracy: 0.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1400, 0.075\n",
      "Accuracy: 0.637\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.635\n",
      "Iteration: 1800, 0.040\n",
      "Accuracy: 0.632\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.670\n",
      "Accuracy: 0.565\n",
      "Iteration: 200, 0.367\n",
      "Accuracy: 0.645\n",
      "Iteration: 400, 0.235\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.155\n",
      "Accuracy: 0.642\n",
      "Iteration: 800, 0.159\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.113\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.096\n",
      "Accuracy: 0.635\n",
      "Iteration: 1400, 0.098\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.059\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.064\n",
      "Accuracy: 0.631\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.489\n",
      "Iteration: 200, 0.373\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.281\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.214\n",
      "Accuracy: 0.642\n",
      "Iteration: 800, 0.286\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.143\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.104\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.229\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.634\n",
      "Iteration: 1800, 0.110\n",
      "Accuracy: 0.634\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.432\n",
      "Iteration: 200, 0.625\n",
      "Accuracy: 0.634\n",
      "Iteration: 400, 0.441\n",
      "Accuracy: 0.633\n",
      "Iteration: 600, 0.462\n",
      "Accuracy: 0.634\n",
      "Iteration: 800, 0.446\n",
      "Accuracy: 0.633\n",
      "Iteration: 1000, 0.356\n",
      "Accuracy: 0.632\n",
      "Iteration: 1200, 0.319\n",
      "Accuracy: 0.634\n",
      "Iteration: 1400, 0.326\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.330\n",
      "Accuracy: 0.634\n",
      "Iteration: 1800, 0.432\n",
      "Accuracy: 0.637\n",
      "#### struc #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.520\n",
      "Iteration: 200, 0.401\n",
      "Accuracy: 0.642\n",
      "Iteration: 400, 0.238\n",
      "Accuracy: 0.642\n",
      "Iteration: 600, 0.155\n",
      "Accuracy: 0.638\n",
      "Iteration: 800, 0.165\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.128\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.105\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.086\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.059\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.052\n",
      "Accuracy: 0.631\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.687\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.377\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.194\n",
      "Accuracy: 0.639\n",
      "Iteration: 600, 0.145\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.141\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.117\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.103\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.078\n",
      "Accuracy: 0.631\n",
      "Iteration: 1800, 0.047\n",
      "Accuracy: 0.630\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.583\n",
      "Iteration: 200, 0.370\n",
      "Accuracy: 0.635\n",
      "Iteration: 400, 0.242\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.177\n",
      "Accuracy: 0.639\n",
      "Iteration: 800, 0.140\n",
      "Accuracy: 0.636\n",
      "Iteration: 1000, 0.118\n",
      "Accuracy: 0.635\n",
      "Iteration: 1200, 0.103\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.066\n",
      "Accuracy: 0.633\n",
      "Iteration: 1600, 0.066\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.044\n",
      "Accuracy: 0.632\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.317\n",
      "Accuracy: 0.638\n",
      "Iteration: 400, 0.188\n",
      "Accuracy: 0.642\n",
      "Iteration: 600, 0.209\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.152\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.087\n",
      "Accuracy: 0.636\n",
      "Iteration: 1200, 0.085\n",
      "Accuracy: 0.635\n",
      "Iteration: 1400, 0.080\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.066\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.048\n",
      "Accuracy: 0.631\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.402\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.256\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.197\n",
      "Accuracy: 0.637\n",
      "Iteration: 800, 0.178\n",
      "Accuracy: 0.635\n",
      "Iteration: 1000, 0.136\n",
      "Accuracy: 0.634\n",
      "Iteration: 1200, 0.103\n",
      "Accuracy: 0.628\n",
      "Iteration: 1400, 0.051\n",
      "Accuracy: 0.626\n",
      "Iteration: 1600, 0.079\n",
      "Accuracy: 0.625\n",
      "Iteration: 1800, 0.085\n",
      "Accuracy: 0.624\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.482\n",
      "Iteration: 200, 0.427\n",
      "Accuracy: 0.624\n",
      "Iteration: 400, 0.297\n",
      "Accuracy: 0.614\n",
      "Iteration: 600, 0.179\n",
      "Accuracy: 0.610\n",
      "Iteration: 800, 0.200\n",
      "Accuracy: 0.607\n",
      "Iteration: 1000, 0.196\n",
      "Accuracy: 0.605\n",
      "Iteration: 1200, 0.157\n",
      "Accuracy: 0.600\n",
      "Iteration: 1400, 0.139\n",
      "Accuracy: 0.598\n",
      "Iteration: 1600, 0.107\n",
      "Accuracy: 0.592\n",
      "Iteration: 1800, 0.117\n",
      "Accuracy: 0.592\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.709\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.377\n",
      "Accuracy: 0.584\n",
      "Iteration: 400, 0.376\n",
      "Accuracy: 0.564\n",
      "Iteration: 600, 0.360\n",
      "Accuracy: 0.559\n",
      "Iteration: 800, 0.569\n",
      "Accuracy: 0.559\n",
      "Iteration: 1000, 0.336\n",
      "Accuracy: 0.555\n",
      "Iteration: 1200, 0.496\n",
      "Accuracy: 0.553\n",
      "Iteration: 1400, 0.342\n",
      "Accuracy: 0.546\n",
      "Iteration: 1600, 0.361\n",
      "Accuracy: 0.545\n",
      "Iteration: 1800, 0.337\n",
      "Accuracy: 0.538\n",
      "#### no noise ####   iteration  2\n",
      "Lamb None\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.375\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.265\n",
      "Accuracy: 0.642\n",
      "Iteration: 600, 0.168\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.144\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.139\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.090\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.083\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.049\n",
      "Accuracy: 0.631\n",
      "Iteration: 1800, 0.046\n",
      "Accuracy: 0.631\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.625\n",
      "Iteration: 200, 0.339\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.207\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.192\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.132\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.100\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.079\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 0.077\n",
      "Accuracy: 0.688\n",
      "Iteration: 1600, 0.041\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.045\n",
      "Accuracy: 0.686\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.497\n",
      "Iteration: 200, 0.329\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.247\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.181\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.126\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.120\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.084\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.046\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.058\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.049\n",
      "Accuracy: 0.684\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.686\n",
      "Accuracy: 0.542\n",
      "Iteration: 200, 0.343\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.244\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.226\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.101\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.074\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.059\n",
      "Accuracy: 0.690\n",
      "Iteration: 1400, 0.078\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.058\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.042\n",
      "Accuracy: 0.685\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.703\n",
      "Accuracy: 0.466\n",
      "Iteration: 200, 0.297\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.250\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.166\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.094\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.099\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.068\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.069\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.054\n",
      "Accuracy: 0.685\n",
      "Iteration: 1800, 0.040\n",
      "Accuracy: 0.685\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.572\n",
      "Iteration: 200, 0.310\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.167\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.198\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.149\n",
      "Accuracy: 0.690\n",
      "Iteration: 1000, 0.081\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.075\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.050\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.049\n",
      "Accuracy: 0.684\n",
      "Iteration: 1800, 0.052\n",
      "Accuracy: 0.685\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.281\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.227\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.210\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.098\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.163\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.094\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.086\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.684\n",
      "Iteration: 1800, 0.087\n",
      "Accuracy: 0.684\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.437\n",
      "Iteration: 200, 0.519\n",
      "Accuracy: 0.678\n",
      "Iteration: 400, 0.295\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.297\n",
      "Accuracy: 0.676\n",
      "Iteration: 800, 0.251\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.357\n",
      "Accuracy: 0.675\n",
      "Iteration: 1200, 0.458\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.435\n",
      "Accuracy: 0.670\n",
      "Iteration: 1600, 0.303\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.284\n",
      "Accuracy: 0.666\n",
      "#### struc #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.543\n",
      "Iteration: 200, 0.326\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.169\n",
      "Accuracy: 0.690\n",
      "Iteration: 600, 0.173\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.153\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.087\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.109\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.039\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.049\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.054\n",
      "Accuracy: 0.685\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.712\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.327\n",
      "Accuracy: 0.690\n",
      "Iteration: 400, 0.222\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.176\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.126\n",
      "Accuracy: 0.694\n",
      "Iteration: 1000, 0.089\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.092\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 0.089\n",
      "Accuracy: 0.689\n",
      "Iteration: 1600, 0.054\n",
      "Accuracy: 0.688\n",
      "Iteration: 1800, 0.037\n",
      "Accuracy: 0.687\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.538\n",
      "Iteration: 200, 0.342\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.214\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.148\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.187\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.096\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.042\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 0.066\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.064\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.030\n",
      "Accuracy: 0.686\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.575\n",
      "Iteration: 200, 0.371\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.203\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.124\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.145\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.137\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.077\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.058\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.059\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.042\n",
      "Accuracy: 0.684\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.604\n",
      "Iteration: 200, 0.369\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.185\n",
      "Accuracy: 0.689\n",
      "Iteration: 600, 0.139\n",
      "Accuracy: 0.689\n",
      "Iteration: 800, 0.148\n",
      "Accuracy: 0.688\n",
      "Iteration: 1000, 0.096\n",
      "Accuracy: 0.686\n",
      "Iteration: 1200, 0.127\n",
      "Accuracy: 0.683\n",
      "Iteration: 1400, 0.053\n",
      "Accuracy: 0.681\n",
      "Iteration: 1600, 0.062\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.063\n",
      "Accuracy: 0.679\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.503\n",
      "Iteration: 200, 0.422\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.175\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.259\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.133\n",
      "Accuracy: 0.659\n",
      "Iteration: 1000, 0.176\n",
      "Accuracy: 0.653\n",
      "Iteration: 1200, 0.106\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.195\n",
      "Accuracy: 0.644\n",
      "Iteration: 1600, 0.097\n",
      "Accuracy: 0.642\n",
      "Iteration: 1800, 0.061\n",
      "Accuracy: 0.637\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.712\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.599\n",
      "Accuracy: 0.612\n",
      "Iteration: 400, 0.540\n",
      "Accuracy: 0.591\n",
      "Iteration: 600, 0.469\n",
      "Accuracy: 0.586\n",
      "Iteration: 800, 0.220\n",
      "Accuracy: 0.571\n",
      "Iteration: 1000, 0.241\n",
      "Accuracy: 0.575\n",
      "Iteration: 1200, 0.609\n",
      "Accuracy: 0.576\n",
      "Iteration: 1400, 0.384\n",
      "Accuracy: 0.570\n",
      "Iteration: 1600, 0.683\n",
      "Accuracy: 0.568\n",
      "Iteration: 1800, 0.379\n",
      "Accuracy: 0.565\n",
      "#### no noise ####   iteration  3\n",
      "Lamb None\n",
      "Iteration: 0, 0.688\n",
      "Accuracy: 0.457\n",
      "Iteration: 200, 0.352\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.217\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.192\n",
      "Accuracy: 0.691\n",
      "Iteration: 800, 0.132\n",
      "Accuracy: 0.689\n",
      "Iteration: 1000, 0.109\n",
      "Accuracy: 0.688\n",
      "Iteration: 1200, 0.059\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.057\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.032\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.082\n",
      "Accuracy: 0.685\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.516\n",
      "Iteration: 200, 0.326\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.185\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.107\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.119\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.062\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.058\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.036\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.031\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.033\n",
      "Accuracy: 0.697\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.451\n",
      "Iteration: 200, 0.278\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.180\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.124\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.094\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.088\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.051\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.033\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.037\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.027\n",
      "Accuracy: 0.695\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.320\n",
      "Accuracy: 0.695\n",
      "Iteration: 400, 0.186\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.143\n",
      "Accuracy: 0.700\n",
      "Iteration: 800, 0.094\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.052\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.073\n",
      "Accuracy: 0.699\n",
      "Iteration: 1400, 0.042\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.035\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.028\n",
      "Accuracy: 0.697\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.439\n",
      "Iteration: 200, 0.309\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.167\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.099\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.081\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.062\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.052\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.046\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.026\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.034\n",
      "Accuracy: 0.697\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.294\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.205\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.142\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.080\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.086\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.055\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.047\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.035\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.030\n",
      "Accuracy: 0.698\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.450\n",
      "Iteration: 200, 0.257\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.172\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.195\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.182\n",
      "Accuracy: 0.699\n",
      "Iteration: 1000, 0.107\n",
      "Accuracy: 0.701\n",
      "Iteration: 1200, 0.045\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.090\n",
      "Accuracy: 0.700\n",
      "Iteration: 1600, 0.045\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.075\n",
      "Accuracy: 0.702\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.577\n",
      "Iteration: 200, 0.424\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.346\n",
      "Accuracy: 0.704\n",
      "Iteration: 600, 0.368\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.226\n",
      "Accuracy: 0.704\n",
      "Iteration: 1000, 0.493\n",
      "Accuracy: 0.699\n",
      "Iteration: 1200, 0.478\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.436\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.201\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.184\n",
      "Accuracy: 0.704\n",
      "#### struc #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.689\n",
      "Accuracy: 0.469\n",
      "Iteration: 200, 0.262\n",
      "Accuracy: 0.686\n",
      "Iteration: 400, 0.168\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.119\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.077\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.075\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.053\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.041\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.034\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.029\n",
      "Accuracy: 0.696\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.558\n",
      "Iteration: 200, 0.353\n",
      "Accuracy: 0.694\n",
      "Iteration: 400, 0.216\n",
      "Accuracy: 0.699\n",
      "Iteration: 600, 0.134\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.097\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.062\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.069\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.053\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.037\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.020\n",
      "Accuracy: 0.696\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.503\n",
      "Iteration: 200, 0.266\n",
      "Accuracy: 0.696\n",
      "Iteration: 400, 0.168\n",
      "Accuracy: 0.697\n",
      "Iteration: 600, 0.115\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.053\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.080\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.066\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.049\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.033\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.030\n",
      "Accuracy: 0.697\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.534\n",
      "Iteration: 200, 0.318\n",
      "Accuracy: 0.690\n",
      "Iteration: 400, 0.176\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.117\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.083\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.057\n",
      "Accuracy: 0.694\n",
      "Iteration: 1200, 0.054\n",
      "Accuracy: 0.694\n",
      "Iteration: 1400, 0.044\n",
      "Accuracy: 0.695\n",
      "Iteration: 1600, 0.040\n",
      "Accuracy: 0.695\n",
      "Iteration: 1800, 0.027\n",
      "Accuracy: 0.696\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.432\n",
      "Iteration: 200, 0.290\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.222\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.134\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.118\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.061\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.090\n",
      "Accuracy: 0.695\n",
      "Iteration: 1400, 0.068\n",
      "Accuracy: 0.694\n",
      "Iteration: 1600, 0.048\n",
      "Accuracy: 0.693\n",
      "Iteration: 1800, 0.048\n",
      "Accuracy: 0.693\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.509\n",
      "Iteration: 200, 0.465\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.193\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.193\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.108\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.122\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.202\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 0.109\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.042\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.089\n",
      "Accuracy: 0.655\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.713\n",
      "Accuracy: 0.456\n",
      "Iteration: 200, 0.410\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.449\n",
      "Accuracy: 0.612\n",
      "Iteration: 600, 0.699\n",
      "Accuracy: 0.593\n",
      "Iteration: 800, 0.282\n",
      "Accuracy: 0.595\n",
      "Iteration: 1000, 0.369\n",
      "Accuracy: 0.600\n",
      "Iteration: 1200, 0.385\n",
      "Accuracy: 0.594\n",
      "Iteration: 1400, 0.486\n",
      "Accuracy: 0.584\n",
      "Iteration: 1600, 0.519\n",
      "Accuracy: 0.584\n",
      "Iteration: 1800, 0.281\n",
      "Accuracy: 0.579\n",
      "#### no noise ####   iteration  4\n",
      "Lamb None\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.477\n",
      "Iteration: 200, 0.292\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.190\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.102\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.101\n",
      "Accuracy: 0.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, 0.072\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.060\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.048\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.034\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.029\n",
      "Accuracy: 0.698\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000 \n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=100, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 100\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 200 \n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=100, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 100\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6655, 0.0235405182610749)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6834800000000001, 0.02014580849705467)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6803999999999999, 0.01981706335459418)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 0)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.558\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.712\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.712\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.711\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.712\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.711\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.521\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.709\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.709\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.708\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.708\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.715\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.712\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.711\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.710\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.708\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.710\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.708\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.485\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.713\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.713\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.713\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.712\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.712\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.712\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.738\n",
      "Accuracy: 0.471\n",
      "Iteration: 200, 0.009\n",
      "Accuracy: 0.708\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.709\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.708\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.707\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.706\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.782\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.027\n",
      "Accuracy: 0.694\n",
      "Iteration: 400, 0.018\n",
      "Accuracy: 0.677\n",
      "Iteration: 600, 0.007\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.044\n",
      "Accuracy: 0.657\n",
      "Iteration: 1000, 0.007\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.007\n",
      "Accuracy: 0.642\n",
      "Iteration: 1400, 0.009\n",
      "Accuracy: 0.641\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.643\n",
      "Iteration: 1800, 0.039\n",
      "Accuracy: 0.635\n",
      "('#### struc #### iteration ', 0)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.740\n",
      "Accuracy: 0.490\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.704\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.703\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.703\n",
      "Accuracy: 0.549\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.715\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.716\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.716\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.715\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.715\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.671\n",
      "Accuracy: 0.565\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.716\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.715\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.714\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.715\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.714\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.714\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.714\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.779\n",
      "Accuracy: 0.478\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.707\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.708\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.708\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.708\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.707\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.707\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.766\n",
      "Accuracy: 0.552\n",
      "Iteration: 200, 0.029\n",
      "Accuracy: 0.703\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.690\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.688\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.685\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.682\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.681\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.839\n",
      "Accuracy: 0.523\n",
      "Iteration: 200, 0.034\n",
      "Accuracy: 0.596\n",
      "Iteration: 400, 0.017\n",
      "Accuracy: 0.574\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.566\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.556\n",
      "Iteration: 1000, 0.004\n",
      "Accuracy: 0.554\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.552\n",
      "Iteration: 1400, 0.004\n",
      "Accuracy: 0.551\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.550\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.546\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.789\n",
      "Accuracy: 0.551\n",
      "Iteration: 200, 0.093\n",
      "Accuracy: 0.516\n",
      "Iteration: 400, 0.040\n",
      "Accuracy: 0.516\n",
      "Iteration: 600, 0.052\n",
      "Accuracy: 0.516\n",
      "Iteration: 800, 0.022\n",
      "Accuracy: 0.512\n",
      "Iteration: 1000, 0.006\n",
      "Accuracy: 0.506\n",
      "Iteration: 1200, 0.023\n",
      "Accuracy: 0.508\n",
      "Iteration: 1400, 0.026\n",
      "Accuracy: 0.503\n",
      "Iteration: 1600, 0.074\n",
      "Accuracy: 0.512\n",
      "Iteration: 1800, 0.018\n",
      "Accuracy: 0.505\n",
      "('#### no noise ####   iteration ', 0)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.707\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.708\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.709\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 1)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.747\n",
      "Accuracy: 0.468\n",
      "Iteration: 200, 0.016\n",
      "Accuracy: 0.673\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.671\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.750\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.018\n",
      "Accuracy: 0.672\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.706\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.707\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.679\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.678\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.711\n",
      "Accuracy: 0.483\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.666\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.668\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.740\n",
      "Accuracy: 0.538\n",
      "Iteration: 200, 0.020\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.007\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.670\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.721\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.056\n",
      "Accuracy: 0.652\n",
      "Iteration: 400, 0.025\n",
      "Accuracy: 0.635\n",
      "Iteration: 600, 0.048\n",
      "Accuracy: 0.630\n",
      "Iteration: 800, 0.018\n",
      "Accuracy: 0.633\n",
      "Iteration: 1000, 0.005\n",
      "Accuracy: 0.626\n",
      "Iteration: 1200, 0.035\n",
      "Accuracy: 0.616\n",
      "Iteration: 1400, 0.034\n",
      "Accuracy: 0.606\n",
      "Iteration: 1600, 0.028\n",
      "Accuracy: 0.603\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.605\n",
      "('#### struc #### iteration ', 1)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.781\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.680\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.680\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.680\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.680\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.681\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.770\n",
      "Accuracy: 0.471\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.674\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.674\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.674\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.727\n",
      "Accuracy: 0.442\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.673\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.673\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.674\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.746\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.664\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.669\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.707\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.030\n",
      "Accuracy: 0.662\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.657\n",
      "Iteration: 600, 0.008\n",
      "Accuracy: 0.653\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.649\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.644\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.630\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.040\n",
      "Accuracy: 0.574\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.557\n",
      "Iteration: 600, 0.009\n",
      "Accuracy: 0.551\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.546\n",
      "Iteration: 1000, 0.004\n",
      "Accuracy: 0.543\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.539\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.538\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.536\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.536\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.908\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.093\n",
      "Accuracy: 0.514\n",
      "Iteration: 400, 0.062\n",
      "Accuracy: 0.511\n",
      "Iteration: 600, 0.026\n",
      "Accuracy: 0.517\n",
      "Iteration: 800, 0.026\n",
      "Accuracy: 0.510\n",
      "Iteration: 1000, 0.025\n",
      "Accuracy: 0.510\n",
      "Iteration: 1200, 0.021\n",
      "Accuracy: 0.509\n",
      "Iteration: 1400, 0.022\n",
      "Accuracy: 0.510\n",
      "Iteration: 1600, 0.072\n",
      "Accuracy: 0.505\n",
      "Iteration: 1800, 0.062\n",
      "Accuracy: 0.510\n",
      "('#### no noise ####   iteration ', 1)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.659\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.016\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.671\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 2)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.697\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.747\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.696\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.699\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.700\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.747\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.700\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.701\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.700\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.712\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.704\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.705\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.657\n",
      "Accuracy: 0.504\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.699\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.702\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.717\n",
      "Accuracy: 0.538\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.702\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.702\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.701\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.701\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.819\n",
      "Accuracy: 0.487\n",
      "Iteration: 200, 0.111\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.061\n",
      "Accuracy: 0.659\n",
      "Iteration: 600, 0.013\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.009\n",
      "Accuracy: 0.649\n",
      "Iteration: 1000, 0.009\n",
      "Accuracy: 0.633\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.633\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.004\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.626\n",
      "('#### struc #### iteration ', 2)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.674\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.700\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.703\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.749\n",
      "Accuracy: 0.518\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.692\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.692\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.694\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.695\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.694\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.677\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.704\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.704\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.705\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.768\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.699\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.699\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.699\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.738\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.679\n",
      "Iteration: 400, 0.007\n",
      "Accuracy: 0.675\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.668\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.666\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.666\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.664\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.662\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.869\n",
      "Accuracy: 0.479\n",
      "Iteration: 200, 0.032\n",
      "Accuracy: 0.567\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.550\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.542\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.537\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.532\n",
      "Iteration: 1200, 0.004\n",
      "Accuracy: 0.529\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.529\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.527\n",
      "Iteration: 1800, 0.002\n",
      "Accuracy: 0.524\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 1.134\n",
      "Accuracy: 0.537\n",
      "Iteration: 200, 0.193\n",
      "Accuracy: 0.508\n",
      "Iteration: 400, 0.062\n",
      "Accuracy: 0.500\n",
      "Iteration: 600, 0.045\n",
      "Accuracy: 0.494\n",
      "Iteration: 800, 0.046\n",
      "Accuracy: 0.493\n",
      "Iteration: 1000, 0.047\n",
      "Accuracy: 0.493\n",
      "Iteration: 1200, 0.012\n",
      "Accuracy: 0.491\n",
      "Iteration: 1400, 0.006\n",
      "Accuracy: 0.494\n",
      "Iteration: 1600, 0.024\n",
      "Accuracy: 0.493\n",
      "Iteration: 1800, 0.006\n",
      "Accuracy: 0.486\n",
      "('#### no noise ####   iteration ', 2)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.681\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.702\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 3)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.652\n",
      "Accuracy: 0.489\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.668\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.669\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.670\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.715\n",
      "Accuracy: 0.549\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.676\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.678\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.678\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.640\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.666\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.572\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.677\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.679\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.710\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.679\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.679\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.680\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.529\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.676\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.677\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.675\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.676\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.675\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.675\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.675\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.596\n",
      "Accuracy: 0.563\n",
      "Iteration: 200, 0.066\n",
      "Accuracy: 0.653\n",
      "Iteration: 400, 0.024\n",
      "Accuracy: 0.632\n",
      "Iteration: 600, 0.023\n",
      "Accuracy: 0.623\n",
      "Iteration: 800, 0.020\n",
      "Accuracy: 0.616\n",
      "Iteration: 1000, 0.037\n",
      "Accuracy: 0.617\n",
      "Iteration: 1200, 0.011\n",
      "Accuracy: 0.614\n",
      "Iteration: 1400, 0.005\n",
      "Accuracy: 0.603\n",
      "Iteration: 1600, 0.011\n",
      "Accuracy: 0.605\n",
      "Iteration: 1800, 0.010\n",
      "Accuracy: 0.600\n",
      "('#### struc #### iteration ', 3)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.755\n",
      "Accuracy: 0.512\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.667\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.670\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.795\n",
      "Accuracy: 0.494\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.667\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.672\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.714\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.683\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.684\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.684\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.683\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.683\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.682\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.681\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.723\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.672\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.673\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.674\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.752\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 0.016\n",
      "Accuracy: 0.659\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.657\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.655\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.654\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.652\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.647\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.704\n",
      "Accuracy: 0.499\n",
      "Iteration: 200, 0.044\n",
      "Accuracy: 0.577\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.555\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.544\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.544\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.539\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.535\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.533\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.531\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.531\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.750\n",
      "Accuracy: 0.550\n",
      "Iteration: 200, 0.051\n",
      "Accuracy: 0.511\n",
      "Iteration: 400, 0.098\n",
      "Accuracy: 0.507\n",
      "Iteration: 600, 0.022\n",
      "Accuracy: 0.505\n",
      "Iteration: 800, 0.049\n",
      "Accuracy: 0.502\n",
      "Iteration: 1000, 0.028\n",
      "Accuracy: 0.509\n",
      "Iteration: 1200, 0.039\n",
      "Accuracy: 0.504\n",
      "Iteration: 1400, 0.003\n",
      "Accuracy: 0.504\n",
      "Iteration: 1600, 0.005\n",
      "Accuracy: 0.504\n",
      "Iteration: 1800, 0.004\n",
      "Accuracy: 0.506\n",
      "('#### no noise ####   iteration ', 3)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.679\n",
      "Accuracy: 0.494\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.668\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.672\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 4)\n",
      "('Lamb', 1e-06)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, 0.744\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.645\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.647\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.649\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.717\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.654\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.652\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.650\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.687\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.648\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.541\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.645\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.645\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.743\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.652\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.651\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.651\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.474\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.641\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.641\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.641\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.056\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.020\n",
      "Accuracy: 0.624\n",
      "Iteration: 600, 0.033\n",
      "Accuracy: 0.616\n",
      "Iteration: 800, 0.021\n",
      "Accuracy: 0.617\n",
      "Iteration: 1000, 0.026\n",
      "Accuracy: 0.607\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.609\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.610\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.607\n",
      "Iteration: 1800, 0.007\n",
      "Accuracy: 0.595\n",
      "('#### struc #### iteration ', 4)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.746\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.649\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.650\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.649\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.649\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.746\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.728\n",
      "Accuracy: 0.510\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.647\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.646\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.706\n",
      "Accuracy: 0.535\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.648\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.649\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.648\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.648\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.674\n",
      "Accuracy: 0.511\n",
      "Iteration: 200, 0.021\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.007\n",
      "Accuracy: 0.635\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.633\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.633\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.633\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.633\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.631\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.630\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.770\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.053\n",
      "Accuracy: 0.566\n",
      "Iteration: 400, 0.018\n",
      "Accuracy: 0.551\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.542\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.538\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.538\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.537\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.535\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.534\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.533\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 1.135\n",
      "Accuracy: 0.551\n",
      "Iteration: 200, 0.118\n",
      "Accuracy: 0.516\n",
      "Iteration: 400, 0.046\n",
      "Accuracy: 0.514\n",
      "Iteration: 600, 0.024\n",
      "Accuracy: 0.509\n",
      "Iteration: 800, 0.016\n",
      "Accuracy: 0.503\n",
      "Iteration: 1000, 0.015\n",
      "Accuracy: 0.511\n",
      "Iteration: 1200, 0.009\n",
      "Accuracy: 0.512\n",
      "Iteration: 1400, 0.039\n",
      "Accuracy: 0.506\n",
      "Iteration: 1600, 0.046\n",
      "Accuracy: 0.502\n",
      "Iteration: 1800, 0.036\n",
      "Accuracy: 0.509\n",
      "('#### no noise ####   iteration ', 4)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.648\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.648\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.648\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 1000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68056, 0.02296654958847756)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6864600000000001, 0.020661229392269956)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68758, 0.022539955634384)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=10000, n_informative=1000, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 10000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=100, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 1000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65832, 0.016279975429956867)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.67628, 0.013198393841676362)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68212, 0.013086389876509098)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "\n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0,1e+1]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=800, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 1000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
