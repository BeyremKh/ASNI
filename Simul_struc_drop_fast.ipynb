{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In odrer to compare structured dropout and iid dropout in a linear model regime, we use the simulations embedded in sklearn (which make use of the Madelon synthetic dataset, see references in http://archive.ics.uci.edu/ml/datasets/madelon )\n",
    "we vary: \n",
    "- the number of variables of redundant variables\n",
    "- the number of overall variables \n",
    "\n",
    "we assess classification accuracy on a test set drawn from the same simulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "\n",
    "x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "x_train=x_all[range(100),]\n",
    "y_train=y_all[range(100),]\n",
    "x_test=x_all[101:,]\n",
    "y_test=y_all[101:]\n",
    "\n",
    "\n",
    "dim = 1000 \n",
    "nb_train = x_train.shape[0]\n",
    "nb_test = x_test.shape[0]\n",
    "nb_classes=1\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(nb_train, 'train samples')\n",
    "print(nb_test, 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = to_categorical(y_train, nb_classes)\n",
    "#y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "y_train=y_train.reshape(nb_train,1)\n",
    "y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.distributions import MultivariateNormalFullCovariance as mvnfc\n",
    "\n",
    "\n",
    "def dropout_layer(x, mode, l, dim):\n",
    "\n",
    "    if mode == 'struc':\n",
    "        xm = tf.reduce_mean(x, 0)\n",
    "        cov = tf.matmul(tf.transpose(x-xm), x-xm) / batch_size\n",
    "        cov += 1e-2 * tf.eye(dim, dtype='float32')\n",
    "       # dia=tf.sqrt(tf.diag(1/tf.diag_part(cov)))\n",
    "       # corr= tf.matmul(tf.matmul(dia,cov),dia)\n",
    "        sample = mvnfc(tf.zeros(shape=[dim]), cov).sample()\n",
    "        return tf.multiply(x, np.sqrt(l)* sample + tf.ones(shape=[dim]))\n",
    "\n",
    "    elif mode == 'iid':\n",
    "      # mu = tf.Variable(lambda : tf.ones(shape=[dim]))\n",
    "        cov =  tf.eye(dim, dtype='float32')\n",
    "        sample = mvnfc(tf.zeros(shape=[dim]), cov).sample()\n",
    "        return tf.multiply(x, np.sqrt(l)* sample + tf.ones(shape=[dim]))\n",
    "\n",
    "    else:  # no dropout\n",
    "        return x\n",
    "\n",
    "\n",
    "class Linear_Model:\n",
    "\n",
    "    def __init__(self, dim, nb_classes, batch_size, l, mode=None):\n",
    "\n",
    "        self.X = tf.placeholder(tf.float32, [None, dim])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "        self.train = tf.placeholder(tf.bool)\n",
    "\n",
    "        W = tf.Variable(tf.random_uniform([dim, nb_classes], -0.01, 0.01))  # model weights\n",
    "        b = tf.Variable(tf.zeros(shape=[nb_classes]))                       # model biases\n",
    "\n",
    "        self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n",
    "        x = tf.matmul(self.dl, W) + b\n",
    "\n",
    "        # Minimize error using cross entropy\n",
    "        self.probs = tf.nn.sigmoid(x)\n",
    "        log_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=x, labels=self.Y)\n",
    "        self.mean_log_loss = tf.reduce_mean(log_loss)\n",
    "\n",
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "                 \n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training of the linear model, we simulate on 10 runs a set of 100 points with parameters listed in the paper, the model is either regularised using iid Gaussian dropout, Structured dropout (ASNI), or without regularisation. We test the model on each run, and for all regularisation parameters on one test dataset with 10,000 points, then average the accuracy on the 10 runs (and compute the standard deviation).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n",
      "WARNING:tensorflow:From <ipython-input-4-5317bbadfddf>:18: MultivariateNormalFullCovariance.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_full_covariance) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py:194: MultivariateNormalTriL.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_tril) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_tril.py:221: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.315\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.345\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.219\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.187\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.146\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.109\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.214\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.115\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.089\n",
      "Accuracy: 0.657\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.689\n",
      "Accuracy: 0.547\n",
      "Iteration: 200, 0.341\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.291\n",
      "Accuracy: 0.681\n",
      "Iteration: 600, 0.225\n",
      "Accuracy: 0.676\n",
      "Iteration: 800, 0.161\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.185\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.265\n",
      "Accuracy: 0.665\n",
      "Iteration: 1400, 0.129\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.087\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.114\n",
      "Accuracy: 0.658\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.364\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.260\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.189\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.202\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.160\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.198\n",
      "Accuracy: 0.662\n",
      "Iteration: 1400, 0.146\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.125\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.102\n",
      "Accuracy: 0.657\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.311\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.310\n",
      "Accuracy: 0.679\n",
      "Iteration: 600, 0.224\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.188\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.159\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.204\n",
      "Accuracy: 0.665\n",
      "Iteration: 1400, 0.158\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.095\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.095\n",
      "Accuracy: 0.657\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.481\n",
      "Iteration: 200, 0.366\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.310\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.271\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.175\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.233\n",
      "Accuracy: 0.666\n",
      "Iteration: 1200, 0.133\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.088\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.122\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.095\n",
      "Accuracy: 0.655\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.458\n",
      "Iteration: 200, 0.362\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.364\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.236\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.258\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.117\n",
      "Accuracy: 0.665\n",
      "Iteration: 1200, 0.174\n",
      "Accuracy: 0.662\n",
      "Iteration: 1400, 0.189\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.209\n",
      "Accuracy: 0.658\n",
      "Iteration: 1800, 0.167\n",
      "Accuracy: 0.654\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.579\n",
      "Iteration: 200, 0.469\n",
      "Accuracy: 0.670\n",
      "Iteration: 400, 0.384\n",
      "Accuracy: 0.663\n",
      "Iteration: 600, 0.446\n",
      "Accuracy: 0.657\n",
      "Iteration: 800, 0.646\n",
      "Accuracy: 0.656\n",
      "Iteration: 1000, 0.479\n",
      "Accuracy: 0.654\n",
      "Iteration: 1200, 0.400\n",
      "Accuracy: 0.655\n",
      "Iteration: 1400, 0.263\n",
      "Accuracy: 0.656\n",
      "Iteration: 1600, 0.191\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 0.256\n",
      "Accuracy: 0.653\n",
      "#### struc #### iteration  0\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.688\n",
      "Accuracy: 0.568\n",
      "Iteration: 200, 0.439\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.310\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.298\n",
      "Accuracy: 0.675\n",
      "Iteration: 800, 0.170\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.159\n",
      "Accuracy: 0.668\n",
      "Iteration: 1200, 0.145\n",
      "Accuracy: 0.664\n",
      "Iteration: 1400, 0.158\n",
      "Accuracy: 0.663\n",
      "Iteration: 1600, 0.094\n",
      "Accuracy: 0.660\n",
      "Iteration: 1800, 0.092\n",
      "Accuracy: 0.658\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.297\n",
      "Accuracy: 0.678\n",
      "Iteration: 400, 0.253\n",
      "Accuracy: 0.679\n",
      "Iteration: 600, 0.221\n",
      "Accuracy: 0.675\n",
      "Iteration: 800, 0.143\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.156\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.145\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.138\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.137\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.101\n",
      "Accuracy: 0.658\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.435\n",
      "Iteration: 200, 0.411\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.336\n",
      "Accuracy: 0.675\n",
      "Iteration: 600, 0.243\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.217\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.190\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.223\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.111\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.116\n",
      "Accuracy: 0.659\n",
      "Iteration: 1800, 0.085\n",
      "Accuracy: 0.658\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.689\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.350\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.277\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.230\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.141\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.172\n",
      "Accuracy: 0.665\n",
      "Iteration: 1200, 0.175\n",
      "Accuracy: 0.664\n",
      "Iteration: 1400, 0.174\n",
      "Accuracy: 0.661\n",
      "Iteration: 1600, 0.100\n",
      "Accuracy: 0.661\n",
      "Iteration: 1800, 0.123\n",
      "Accuracy: 0.657\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.324\n",
      "Accuracy: 0.679\n",
      "Iteration: 400, 0.243\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.248\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.186\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.140\n",
      "Accuracy: 0.661\n",
      "Iteration: 1200, 0.129\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.145\n",
      "Accuracy: 0.654\n",
      "Iteration: 1600, 0.162\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.102\n",
      "Accuracy: 0.651\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.389\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 0.219\n",
      "Accuracy: 0.649\n",
      "Iteration: 600, 0.323\n",
      "Accuracy: 0.645\n",
      "Iteration: 800, 0.256\n",
      "Accuracy: 0.637\n",
      "Iteration: 1000, 0.288\n",
      "Accuracy: 0.634\n",
      "Iteration: 1200, 0.237\n",
      "Accuracy: 0.625\n",
      "Iteration: 1400, 0.381\n",
      "Accuracy: 0.617\n",
      "Iteration: 1600, 0.302\n",
      "Accuracy: 0.615\n",
      "Iteration: 1800, 0.215\n",
      "Accuracy: 0.611\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.528\n",
      "Accuracy: 0.605\n",
      "Iteration: 400, 0.526\n",
      "Accuracy: 0.588\n",
      "Iteration: 600, 0.687\n",
      "Accuracy: 0.565\n",
      "Iteration: 800, 0.327\n",
      "Accuracy: 0.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, 0.534\n",
      "Accuracy: 0.564\n",
      "Iteration: 1200, 0.293\n",
      "Accuracy: 0.569\n",
      "Iteration: 1400, 0.354\n",
      "Accuracy: 0.558\n",
      "Iteration: 1600, 0.532\n",
      "Accuracy: 0.551\n",
      "Iteration: 1800, 0.415\n",
      "Accuracy: 0.556\n",
      "#### no noise ####   iteration  0\n",
      "Lamb None\n",
      "Iteration: 0, 0.671\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.384\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.283\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.247\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.174\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.134\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.138\n",
      "Accuracy: 0.663\n",
      "Iteration: 1400, 0.104\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.148\n",
      "Accuracy: 0.658\n",
      "Iteration: 1800, 0.124\n",
      "Accuracy: 0.658\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.547\n",
      "Iteration: 200, 0.379\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.322\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.270\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.181\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.139\n",
      "Accuracy: 0.661\n",
      "Iteration: 1200, 0.110\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.076\n",
      "Accuracy: 0.660\n",
      "Iteration: 1600, 0.073\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.068\n",
      "Accuracy: 0.657\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.408\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.247\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.201\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.163\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.102\n",
      "Accuracy: 0.662\n",
      "Iteration: 1200, 0.128\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.097\n",
      "Accuracy: 0.659\n",
      "Iteration: 1600, 0.067\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.067\n",
      "Accuracy: 0.654\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.672\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.318\n",
      "Accuracy: 0.676\n",
      "Iteration: 400, 0.225\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.161\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.172\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.125\n",
      "Accuracy: 0.658\n",
      "Iteration: 1200, 0.168\n",
      "Accuracy: 0.658\n",
      "Iteration: 1400, 0.118\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.083\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.055\n",
      "Accuracy: 0.655\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.311\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.261\n",
      "Accuracy: 0.671\n",
      "Iteration: 600, 0.180\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.168\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.119\n",
      "Accuracy: 0.663\n",
      "Iteration: 1200, 0.108\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.087\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.086\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.067\n",
      "Accuracy: 0.655\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.311\n",
      "Accuracy: 0.686\n",
      "Iteration: 400, 0.294\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.205\n",
      "Accuracy: 0.663\n",
      "Iteration: 800, 0.149\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.109\n",
      "Accuracy: 0.659\n",
      "Iteration: 1200, 0.128\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.073\n",
      "Accuracy: 0.656\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.688\n",
      "Accuracy: 0.571\n",
      "Iteration: 200, 0.382\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.301\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.216\n",
      "Accuracy: 0.668\n",
      "Iteration: 800, 0.202\n",
      "Accuracy: 0.663\n",
      "Iteration: 1000, 0.229\n",
      "Accuracy: 0.657\n",
      "Iteration: 1200, 0.154\n",
      "Accuracy: 0.658\n",
      "Iteration: 1400, 0.121\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.145\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 0.069\n",
      "Accuracy: 0.654\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.699\n",
      "Accuracy: 0.569\n",
      "Iteration: 200, 0.527\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.415\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.275\n",
      "Accuracy: 0.663\n",
      "Iteration: 800, 0.246\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.287\n",
      "Accuracy: 0.655\n",
      "Iteration: 1200, 0.234\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.314\n",
      "Accuracy: 0.653\n",
      "Iteration: 1600, 0.749\n",
      "Accuracy: 0.654\n",
      "Iteration: 1800, 0.238\n",
      "Accuracy: 0.646\n",
      "#### struc #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.329\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.260\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.172\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.145\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.169\n",
      "Accuracy: 0.660\n",
      "Iteration: 1200, 0.110\n",
      "Accuracy: 0.659\n",
      "Iteration: 1400, 0.115\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.078\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.060\n",
      "Accuracy: 0.655\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.580\n",
      "Iteration: 200, 0.370\n",
      "Accuracy: 0.684\n",
      "Iteration: 400, 0.254\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.217\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.165\n",
      "Accuracy: 0.662\n",
      "Iteration: 1000, 0.162\n",
      "Accuracy: 0.661\n",
      "Iteration: 1200, 0.104\n",
      "Accuracy: 0.659\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.101\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.056\n",
      "Accuracy: 0.655\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.592\n",
      "Iteration: 200, 0.293\n",
      "Accuracy: 0.681\n",
      "Iteration: 400, 0.260\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.227\n",
      "Accuracy: 0.665\n",
      "Iteration: 800, 0.182\n",
      "Accuracy: 0.659\n",
      "Iteration: 1000, 0.154\n",
      "Accuracy: 0.657\n",
      "Iteration: 1200, 0.111\n",
      "Accuracy: 0.657\n",
      "Iteration: 1400, 0.090\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.088\n",
      "Accuracy: 0.655\n",
      "Iteration: 1800, 0.067\n",
      "Accuracy: 0.654\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.330\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.241\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.231\n",
      "Accuracy: 0.666\n",
      "Iteration: 800, 0.221\n",
      "Accuracy: 0.663\n",
      "Iteration: 1000, 0.147\n",
      "Accuracy: 0.662\n",
      "Iteration: 1200, 0.110\n",
      "Accuracy: 0.660\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.655\n",
      "Iteration: 1600, 0.080\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.060\n",
      "Accuracy: 0.653\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.554\n",
      "Iteration: 200, 0.329\n",
      "Accuracy: 0.684\n",
      "Iteration: 400, 0.221\n",
      "Accuracy: 0.668\n",
      "Iteration: 600, 0.235\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.146\n",
      "Accuracy: 0.661\n",
      "Iteration: 1000, 0.123\n",
      "Accuracy: 0.659\n",
      "Iteration: 1200, 0.120\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.110\n",
      "Accuracy: 0.654\n",
      "Iteration: 1600, 0.089\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.075\n",
      "Accuracy: 0.650\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.485\n",
      "Accuracy: 0.670\n",
      "Iteration: 400, 0.356\n",
      "Accuracy: 0.655\n",
      "Iteration: 600, 0.313\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.265\n",
      "Accuracy: 0.644\n",
      "Iteration: 1000, 0.235\n",
      "Accuracy: 0.641\n",
      "Iteration: 1200, 0.171\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.151\n",
      "Accuracy: 0.631\n",
      "Iteration: 1600, 0.121\n",
      "Accuracy: 0.628\n",
      "Iteration: 1800, 0.161\n",
      "Accuracy: 0.626\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.660\n",
      "Accuracy: 0.583\n",
      "Iteration: 200, 0.541\n",
      "Accuracy: 0.614\n",
      "Iteration: 400, 0.380\n",
      "Accuracy: 0.598\n",
      "Iteration: 600, 0.516\n",
      "Accuracy: 0.594\n",
      "Iteration: 800, 0.312\n",
      "Accuracy: 0.583\n",
      "Iteration: 1000, 0.459\n",
      "Accuracy: 0.577\n",
      "Iteration: 1200, 0.659\n",
      "Accuracy: 0.576\n",
      "Iteration: 1400, 0.373\n",
      "Accuracy: 0.578\n",
      "Iteration: 1600, 0.466\n",
      "Accuracy: 0.577\n",
      "Iteration: 1800, 0.407\n",
      "Accuracy: 0.573\n",
      "#### no noise ####   iteration  1\n",
      "Lamb None\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.523\n",
      "Iteration: 200, 0.333\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.251\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.196\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.199\n",
      "Accuracy: 0.660\n",
      "Iteration: 1000, 0.137\n",
      "Accuracy: 0.659\n",
      "Iteration: 1200, 0.116\n",
      "Accuracy: 0.659\n",
      "Iteration: 1400, 0.074\n",
      "Accuracy: 0.658\n",
      "Iteration: 1600, 0.094\n",
      "Accuracy: 0.656\n",
      "Iteration: 1800, 0.050\n",
      "Accuracy: 0.655\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.334\n",
      "Accuracy: 0.641\n",
      "Iteration: 400, 0.272\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.157\n",
      "Accuracy: 0.642\n",
      "Iteration: 800, 0.138\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.131\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.090\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.057\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.052\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.034\n",
      "Accuracy: 0.632\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.676\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.351\n",
      "Accuracy: 0.641\n",
      "Iteration: 400, 0.236\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.172\n",
      "Accuracy: 0.641\n",
      "Iteration: 800, 0.124\n",
      "Accuracy: 0.640\n",
      "Iteration: 1000, 0.119\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.075\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.063\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.063\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.047\n",
      "Accuracy: 0.632\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.687\n",
      "Accuracy: 0.584\n",
      "Iteration: 200, 0.406\n",
      "Accuracy: 0.638\n",
      "Iteration: 400, 0.285\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.155\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.135\n",
      "Accuracy: 0.640\n",
      "Iteration: 1000, 0.107\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.093\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.057\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.076\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.047\n",
      "Accuracy: 0.632\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.699\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.369\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.256\n",
      "Accuracy: 0.644\n",
      "Iteration: 600, 0.186\n",
      "Accuracy: 0.643\n",
      "Iteration: 800, 0.123\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.122\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.069\n",
      "Accuracy: 0.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1400, 0.075\n",
      "Accuracy: 0.637\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.635\n",
      "Iteration: 1800, 0.040\n",
      "Accuracy: 0.632\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.670\n",
      "Accuracy: 0.565\n",
      "Iteration: 200, 0.367\n",
      "Accuracy: 0.645\n",
      "Iteration: 400, 0.235\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.155\n",
      "Accuracy: 0.642\n",
      "Iteration: 800, 0.159\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.113\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.096\n",
      "Accuracy: 0.635\n",
      "Iteration: 1400, 0.098\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.059\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.064\n",
      "Accuracy: 0.631\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.489\n",
      "Iteration: 200, 0.373\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.281\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.214\n",
      "Accuracy: 0.642\n",
      "Iteration: 800, 0.286\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.143\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.104\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.229\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.634\n",
      "Iteration: 1800, 0.110\n",
      "Accuracy: 0.634\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.432\n",
      "Iteration: 200, 0.625\n",
      "Accuracy: 0.634\n",
      "Iteration: 400, 0.441\n",
      "Accuracy: 0.633\n",
      "Iteration: 600, 0.462\n",
      "Accuracy: 0.634\n",
      "Iteration: 800, 0.446\n",
      "Accuracy: 0.633\n",
      "Iteration: 1000, 0.356\n",
      "Accuracy: 0.632\n",
      "Iteration: 1200, 0.319\n",
      "Accuracy: 0.634\n",
      "Iteration: 1400, 0.326\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.330\n",
      "Accuracy: 0.634\n",
      "Iteration: 1800, 0.432\n",
      "Accuracy: 0.637\n",
      "#### struc #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.520\n",
      "Iteration: 200, 0.401\n",
      "Accuracy: 0.642\n",
      "Iteration: 400, 0.238\n",
      "Accuracy: 0.642\n",
      "Iteration: 600, 0.155\n",
      "Accuracy: 0.638\n",
      "Iteration: 800, 0.165\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.128\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.105\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.086\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.059\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.052\n",
      "Accuracy: 0.631\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.687\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.377\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.194\n",
      "Accuracy: 0.639\n",
      "Iteration: 600, 0.145\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.141\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.117\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.103\n",
      "Accuracy: 0.636\n",
      "Iteration: 1400, 0.084\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.078\n",
      "Accuracy: 0.631\n",
      "Iteration: 1800, 0.047\n",
      "Accuracy: 0.630\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.583\n",
      "Iteration: 200, 0.370\n",
      "Accuracy: 0.635\n",
      "Iteration: 400, 0.242\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.177\n",
      "Accuracy: 0.639\n",
      "Iteration: 800, 0.140\n",
      "Accuracy: 0.636\n",
      "Iteration: 1000, 0.118\n",
      "Accuracy: 0.635\n",
      "Iteration: 1200, 0.103\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.066\n",
      "Accuracy: 0.633\n",
      "Iteration: 1600, 0.066\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.044\n",
      "Accuracy: 0.632\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.317\n",
      "Accuracy: 0.638\n",
      "Iteration: 400, 0.188\n",
      "Accuracy: 0.642\n",
      "Iteration: 600, 0.209\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.152\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.087\n",
      "Accuracy: 0.636\n",
      "Iteration: 1200, 0.085\n",
      "Accuracy: 0.635\n",
      "Iteration: 1400, 0.080\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.066\n",
      "Accuracy: 0.633\n",
      "Iteration: 1800, 0.048\n",
      "Accuracy: 0.631\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.402\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.256\n",
      "Accuracy: 0.643\n",
      "Iteration: 600, 0.197\n",
      "Accuracy: 0.637\n",
      "Iteration: 800, 0.178\n",
      "Accuracy: 0.635\n",
      "Iteration: 1000, 0.136\n",
      "Accuracy: 0.634\n",
      "Iteration: 1200, 0.103\n",
      "Accuracy: 0.628\n",
      "Iteration: 1400, 0.051\n",
      "Accuracy: 0.626\n",
      "Iteration: 1600, 0.079\n",
      "Accuracy: 0.625\n",
      "Iteration: 1800, 0.085\n",
      "Accuracy: 0.624\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.482\n",
      "Iteration: 200, 0.427\n",
      "Accuracy: 0.624\n",
      "Iteration: 400, 0.297\n",
      "Accuracy: 0.614\n",
      "Iteration: 600, 0.179\n",
      "Accuracy: 0.610\n",
      "Iteration: 800, 0.200\n",
      "Accuracy: 0.607\n",
      "Iteration: 1000, 0.196\n",
      "Accuracy: 0.605\n",
      "Iteration: 1200, 0.157\n",
      "Accuracy: 0.600\n",
      "Iteration: 1400, 0.139\n",
      "Accuracy: 0.598\n",
      "Iteration: 1600, 0.107\n",
      "Accuracy: 0.592\n",
      "Iteration: 1800, 0.117\n",
      "Accuracy: 0.592\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.709\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.377\n",
      "Accuracy: 0.584\n",
      "Iteration: 400, 0.376\n",
      "Accuracy: 0.564\n",
      "Iteration: 600, 0.360\n",
      "Accuracy: 0.559\n",
      "Iteration: 800, 0.569\n",
      "Accuracy: 0.559\n",
      "Iteration: 1000, 0.336\n",
      "Accuracy: 0.555\n",
      "Iteration: 1200, 0.496\n",
      "Accuracy: 0.553\n",
      "Iteration: 1400, 0.342\n",
      "Accuracy: 0.546\n",
      "Iteration: 1600, 0.361\n",
      "Accuracy: 0.545\n",
      "Iteration: 1800, 0.337\n",
      "Accuracy: 0.538\n",
      "#### no noise ####   iteration  2\n",
      "Lamb None\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.375\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.265\n",
      "Accuracy: 0.642\n",
      "Iteration: 600, 0.168\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.144\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.139\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.090\n",
      "Accuracy: 0.637\n",
      "Iteration: 1400, 0.083\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.049\n",
      "Accuracy: 0.631\n",
      "Iteration: 1800, 0.046\n",
      "Accuracy: 0.631\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.625\n",
      "Iteration: 200, 0.339\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.207\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.192\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.132\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.100\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.079\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 0.077\n",
      "Accuracy: 0.688\n",
      "Iteration: 1600, 0.041\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.045\n",
      "Accuracy: 0.686\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.497\n",
      "Iteration: 200, 0.329\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.247\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.181\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.126\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.120\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.084\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.046\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.058\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.049\n",
      "Accuracy: 0.684\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.686\n",
      "Accuracy: 0.542\n",
      "Iteration: 200, 0.343\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.244\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.226\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.101\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.074\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.059\n",
      "Accuracy: 0.690\n",
      "Iteration: 1400, 0.078\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.058\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.042\n",
      "Accuracy: 0.685\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.703\n",
      "Accuracy: 0.466\n",
      "Iteration: 200, 0.297\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.250\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.166\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.094\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.099\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.068\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.069\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.054\n",
      "Accuracy: 0.685\n",
      "Iteration: 1800, 0.040\n",
      "Accuracy: 0.685\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.572\n",
      "Iteration: 200, 0.310\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.167\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.198\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.149\n",
      "Accuracy: 0.690\n",
      "Iteration: 1000, 0.081\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.075\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.050\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.049\n",
      "Accuracy: 0.684\n",
      "Iteration: 1800, 0.052\n",
      "Accuracy: 0.685\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.702\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.281\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.227\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.210\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.098\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.163\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.094\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.086\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.069\n",
      "Accuracy: 0.684\n",
      "Iteration: 1800, 0.087\n",
      "Accuracy: 0.684\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.437\n",
      "Iteration: 200, 0.519\n",
      "Accuracy: 0.678\n",
      "Iteration: 400, 0.295\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.297\n",
      "Accuracy: 0.676\n",
      "Iteration: 800, 0.251\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.357\n",
      "Accuracy: 0.675\n",
      "Iteration: 1200, 0.458\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.435\n",
      "Accuracy: 0.670\n",
      "Iteration: 1600, 0.303\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.284\n",
      "Accuracy: 0.666\n",
      "#### struc #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.543\n",
      "Iteration: 200, 0.326\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.169\n",
      "Accuracy: 0.690\n",
      "Iteration: 600, 0.173\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.153\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.087\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.109\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.039\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.049\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.054\n",
      "Accuracy: 0.685\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.712\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.327\n",
      "Accuracy: 0.690\n",
      "Iteration: 400, 0.222\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.176\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.126\n",
      "Accuracy: 0.694\n",
      "Iteration: 1000, 0.089\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.092\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 0.089\n",
      "Accuracy: 0.689\n",
      "Iteration: 1600, 0.054\n",
      "Accuracy: 0.688\n",
      "Iteration: 1800, 0.037\n",
      "Accuracy: 0.687\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.538\n",
      "Iteration: 200, 0.342\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.214\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.148\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.187\n",
      "Accuracy: 0.692\n",
      "Iteration: 1000, 0.096\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.042\n",
      "Accuracy: 0.689\n",
      "Iteration: 1400, 0.066\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.064\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.030\n",
      "Accuracy: 0.686\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.575\n",
      "Iteration: 200, 0.371\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.203\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.124\n",
      "Accuracy: 0.693\n",
      "Iteration: 800, 0.145\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.137\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.077\n",
      "Accuracy: 0.688\n",
      "Iteration: 1400, 0.058\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.059\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.042\n",
      "Accuracy: 0.684\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.604\n",
      "Iteration: 200, 0.369\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.185\n",
      "Accuracy: 0.689\n",
      "Iteration: 600, 0.139\n",
      "Accuracy: 0.689\n",
      "Iteration: 800, 0.148\n",
      "Accuracy: 0.688\n",
      "Iteration: 1000, 0.096\n",
      "Accuracy: 0.686\n",
      "Iteration: 1200, 0.127\n",
      "Accuracy: 0.683\n",
      "Iteration: 1400, 0.053\n",
      "Accuracy: 0.681\n",
      "Iteration: 1600, 0.062\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.063\n",
      "Accuracy: 0.679\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.503\n",
      "Iteration: 200, 0.422\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.175\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.259\n",
      "Accuracy: 0.664\n",
      "Iteration: 800, 0.133\n",
      "Accuracy: 0.659\n",
      "Iteration: 1000, 0.176\n",
      "Accuracy: 0.653\n",
      "Iteration: 1200, 0.106\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.195\n",
      "Accuracy: 0.644\n",
      "Iteration: 1600, 0.097\n",
      "Accuracy: 0.642\n",
      "Iteration: 1800, 0.061\n",
      "Accuracy: 0.637\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.712\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.599\n",
      "Accuracy: 0.612\n",
      "Iteration: 400, 0.540\n",
      "Accuracy: 0.591\n",
      "Iteration: 600, 0.469\n",
      "Accuracy: 0.586\n",
      "Iteration: 800, 0.220\n",
      "Accuracy: 0.571\n",
      "Iteration: 1000, 0.241\n",
      "Accuracy: 0.575\n",
      "Iteration: 1200, 0.609\n",
      "Accuracy: 0.576\n",
      "Iteration: 1400, 0.384\n",
      "Accuracy: 0.570\n",
      "Iteration: 1600, 0.683\n",
      "Accuracy: 0.568\n",
      "Iteration: 1800, 0.379\n",
      "Accuracy: 0.565\n",
      "#### no noise ####   iteration  3\n",
      "Lamb None\n",
      "Iteration: 0, 0.688\n",
      "Accuracy: 0.457\n",
      "Iteration: 200, 0.352\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.217\n",
      "Accuracy: 0.691\n",
      "Iteration: 600, 0.192\n",
      "Accuracy: 0.691\n",
      "Iteration: 800, 0.132\n",
      "Accuracy: 0.689\n",
      "Iteration: 1000, 0.109\n",
      "Accuracy: 0.688\n",
      "Iteration: 1200, 0.059\n",
      "Accuracy: 0.687\n",
      "Iteration: 1400, 0.057\n",
      "Accuracy: 0.686\n",
      "Iteration: 1600, 0.032\n",
      "Accuracy: 0.686\n",
      "Iteration: 1800, 0.082\n",
      "Accuracy: 0.685\n",
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.516\n",
      "Iteration: 200, 0.326\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.185\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.107\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.119\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.062\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.058\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.036\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.031\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.033\n",
      "Accuracy: 0.697\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.451\n",
      "Iteration: 200, 0.278\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.180\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.124\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.094\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.088\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.051\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.033\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.037\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.027\n",
      "Accuracy: 0.695\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.320\n",
      "Accuracy: 0.695\n",
      "Iteration: 400, 0.186\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.143\n",
      "Accuracy: 0.700\n",
      "Iteration: 800, 0.094\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.052\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.073\n",
      "Accuracy: 0.699\n",
      "Iteration: 1400, 0.042\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.035\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.028\n",
      "Accuracy: 0.697\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.439\n",
      "Iteration: 200, 0.309\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.167\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.099\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.081\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.062\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.052\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.046\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.026\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.034\n",
      "Accuracy: 0.697\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.294\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.205\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.142\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.080\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.086\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.055\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.047\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.035\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.030\n",
      "Accuracy: 0.698\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.450\n",
      "Iteration: 200, 0.257\n",
      "Accuracy: 0.689\n",
      "Iteration: 400, 0.172\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.195\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.182\n",
      "Accuracy: 0.699\n",
      "Iteration: 1000, 0.107\n",
      "Accuracy: 0.701\n",
      "Iteration: 1200, 0.045\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.090\n",
      "Accuracy: 0.700\n",
      "Iteration: 1600, 0.045\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.075\n",
      "Accuracy: 0.702\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.577\n",
      "Iteration: 200, 0.424\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.346\n",
      "Accuracy: 0.704\n",
      "Iteration: 600, 0.368\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.226\n",
      "Accuracy: 0.704\n",
      "Iteration: 1000, 0.493\n",
      "Accuracy: 0.699\n",
      "Iteration: 1200, 0.478\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.436\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.201\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.184\n",
      "Accuracy: 0.704\n",
      "#### struc #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.689\n",
      "Accuracy: 0.469\n",
      "Iteration: 200, 0.262\n",
      "Accuracy: 0.686\n",
      "Iteration: 400, 0.168\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.119\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.077\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.075\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.053\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.041\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.034\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.029\n",
      "Accuracy: 0.696\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.694\n",
      "Accuracy: 0.558\n",
      "Iteration: 200, 0.353\n",
      "Accuracy: 0.694\n",
      "Iteration: 400, 0.216\n",
      "Accuracy: 0.699\n",
      "Iteration: 600, 0.134\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.097\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.062\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.069\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.053\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.037\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.020\n",
      "Accuracy: 0.696\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.698\n",
      "Accuracy: 0.503\n",
      "Iteration: 200, 0.266\n",
      "Accuracy: 0.696\n",
      "Iteration: 400, 0.168\n",
      "Accuracy: 0.697\n",
      "Iteration: 600, 0.115\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.053\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.080\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.066\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.049\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.033\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.030\n",
      "Accuracy: 0.697\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.534\n",
      "Iteration: 200, 0.318\n",
      "Accuracy: 0.690\n",
      "Iteration: 400, 0.176\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.117\n",
      "Accuracy: 0.695\n",
      "Iteration: 800, 0.083\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.057\n",
      "Accuracy: 0.694\n",
      "Iteration: 1200, 0.054\n",
      "Accuracy: 0.694\n",
      "Iteration: 1400, 0.044\n",
      "Accuracy: 0.695\n",
      "Iteration: 1600, 0.040\n",
      "Accuracy: 0.695\n",
      "Iteration: 1800, 0.027\n",
      "Accuracy: 0.696\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.432\n",
      "Iteration: 200, 0.290\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.222\n",
      "Accuracy: 0.695\n",
      "Iteration: 600, 0.134\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.118\n",
      "Accuracy: 0.696\n",
      "Iteration: 1000, 0.061\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.090\n",
      "Accuracy: 0.695\n",
      "Iteration: 1400, 0.068\n",
      "Accuracy: 0.694\n",
      "Iteration: 1600, 0.048\n",
      "Accuracy: 0.693\n",
      "Iteration: 1800, 0.048\n",
      "Accuracy: 0.693\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.509\n",
      "Iteration: 200, 0.465\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.193\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.193\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.108\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.122\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.202\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 0.109\n",
      "Accuracy: 0.662\n",
      "Iteration: 1600, 0.042\n",
      "Accuracy: 0.657\n",
      "Iteration: 1800, 0.089\n",
      "Accuracy: 0.655\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.713\n",
      "Accuracy: 0.456\n",
      "Iteration: 200, 0.410\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.449\n",
      "Accuracy: 0.612\n",
      "Iteration: 600, 0.699\n",
      "Accuracy: 0.593\n",
      "Iteration: 800, 0.282\n",
      "Accuracy: 0.595\n",
      "Iteration: 1000, 0.369\n",
      "Accuracy: 0.600\n",
      "Iteration: 1200, 0.385\n",
      "Accuracy: 0.594\n",
      "Iteration: 1400, 0.486\n",
      "Accuracy: 0.584\n",
      "Iteration: 1600, 0.519\n",
      "Accuracy: 0.584\n",
      "Iteration: 1800, 0.281\n",
      "Accuracy: 0.579\n",
      "#### no noise ####   iteration  4\n",
      "Lamb None\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.477\n",
      "Iteration: 200, 0.292\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.190\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.102\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.101\n",
      "Accuracy: 0.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, 0.072\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.060\n",
      "Accuracy: 0.697\n",
      "Iteration: 1400, 0.048\n",
      "Accuracy: 0.697\n",
      "Iteration: 1600, 0.034\n",
      "Accuracy: 0.697\n",
      "Iteration: 1800, 0.029\n",
      "Accuracy: 0.698\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "max_iters = 2000 \n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=100, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 100\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 100)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n",
      "WARNING:tensorflow:From <ipython-input-2-5317bbadfddf>:18: MultivariateNormalFullCovariance.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_full_covariance) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py:194: MultivariateNormalTriL.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_tril) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_tril.py:221: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.571\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.479\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.480\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.699\n",
      "Accuracy: 0.500\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.696\n",
      "Accuracy: 0.487\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.490\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.685\n",
      "Accuracy: 0.537\n",
      "#### struc #### iteration  0\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.704\n",
      "Accuracy: 0.491\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.680\n",
      "Accuracy: 0.589\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.514\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.693\n",
      "Accuracy: 0.495\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.700\n",
      "Accuracy: 0.574\n",
      "Lamb 0.1\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "                 \n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 200 \n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=100, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 100\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6655, 0.0235405182610749)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6834800000000001, 0.02014580849705467)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6803999999999999, 0.01981706335459418)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 0)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.558\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.712\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.712\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.711\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.712\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.711\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.521\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.709\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.709\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.708\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.708\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.708\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.715\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.712\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.711\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.711\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.710\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.695\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.708\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.710\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.708\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.705\n",
      "Accuracy: 0.485\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.713\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.713\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.713\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.712\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.712\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.712\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.738\n",
      "Accuracy: 0.471\n",
      "Iteration: 200, 0.009\n",
      "Accuracy: 0.708\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.709\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.708\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.707\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.706\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.782\n",
      "Accuracy: 0.539\n",
      "Iteration: 200, 0.027\n",
      "Accuracy: 0.694\n",
      "Iteration: 400, 0.018\n",
      "Accuracy: 0.677\n",
      "Iteration: 600, 0.007\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.044\n",
      "Accuracy: 0.657\n",
      "Iteration: 1000, 0.007\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.007\n",
      "Accuracy: 0.642\n",
      "Iteration: 1400, 0.009\n",
      "Accuracy: 0.641\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.643\n",
      "Iteration: 1800, 0.039\n",
      "Accuracy: 0.635\n",
      "('#### struc #### iteration ', 0)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.740\n",
      "Accuracy: 0.490\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.704\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.703\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.703\n",
      "Accuracy: 0.549\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.715\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.716\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.716\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.716\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.715\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.715\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.671\n",
      "Accuracy: 0.565\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.716\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.715\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.714\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.715\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.714\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.714\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.713\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.714\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.779\n",
      "Accuracy: 0.478\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.707\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.708\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.708\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.708\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.707\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.707\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.766\n",
      "Accuracy: 0.552\n",
      "Iteration: 200, 0.029\n",
      "Accuracy: 0.703\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.690\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.688\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.685\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.682\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.681\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.839\n",
      "Accuracy: 0.523\n",
      "Iteration: 200, 0.034\n",
      "Accuracy: 0.596\n",
      "Iteration: 400, 0.017\n",
      "Accuracy: 0.574\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.566\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.556\n",
      "Iteration: 1000, 0.004\n",
      "Accuracy: 0.554\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.552\n",
      "Iteration: 1400, 0.004\n",
      "Accuracy: 0.551\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.550\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.546\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.789\n",
      "Accuracy: 0.551\n",
      "Iteration: 200, 0.093\n",
      "Accuracy: 0.516\n",
      "Iteration: 400, 0.040\n",
      "Accuracy: 0.516\n",
      "Iteration: 600, 0.052\n",
      "Accuracy: 0.516\n",
      "Iteration: 800, 0.022\n",
      "Accuracy: 0.512\n",
      "Iteration: 1000, 0.006\n",
      "Accuracy: 0.506\n",
      "Iteration: 1200, 0.023\n",
      "Accuracy: 0.508\n",
      "Iteration: 1400, 0.026\n",
      "Accuracy: 0.503\n",
      "Iteration: 1600, 0.074\n",
      "Accuracy: 0.512\n",
      "Iteration: 1800, 0.018\n",
      "Accuracy: 0.505\n",
      "('#### no noise ####   iteration ', 0)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.707\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.708\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.709\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.709\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 1)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.747\n",
      "Accuracy: 0.468\n",
      "Iteration: 200, 0.016\n",
      "Accuracy: 0.673\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.671\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.750\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.018\n",
      "Accuracy: 0.672\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.706\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.707\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.679\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.678\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.711\n",
      "Accuracy: 0.483\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.666\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.668\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.740\n",
      "Accuracy: 0.538\n",
      "Iteration: 200, 0.020\n",
      "Accuracy: 0.674\n",
      "Iteration: 400, 0.007\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.670\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.721\n",
      "Accuracy: 0.536\n",
      "Iteration: 200, 0.056\n",
      "Accuracy: 0.652\n",
      "Iteration: 400, 0.025\n",
      "Accuracy: 0.635\n",
      "Iteration: 600, 0.048\n",
      "Accuracy: 0.630\n",
      "Iteration: 800, 0.018\n",
      "Accuracy: 0.633\n",
      "Iteration: 1000, 0.005\n",
      "Accuracy: 0.626\n",
      "Iteration: 1200, 0.035\n",
      "Accuracy: 0.616\n",
      "Iteration: 1400, 0.034\n",
      "Accuracy: 0.606\n",
      "Iteration: 1600, 0.028\n",
      "Accuracy: 0.603\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.605\n",
      "('#### struc #### iteration ', 1)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.781\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.680\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.680\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.680\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.680\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.681\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.770\n",
      "Accuracy: 0.471\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.675\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.674\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.674\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.674\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.674\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.727\n",
      "Accuracy: 0.442\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.673\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.673\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.674\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.746\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.664\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.669\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.707\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.030\n",
      "Accuracy: 0.662\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.657\n",
      "Iteration: 600, 0.008\n",
      "Accuracy: 0.653\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.649\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.644\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.630\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.040\n",
      "Accuracy: 0.574\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.557\n",
      "Iteration: 600, 0.009\n",
      "Accuracy: 0.551\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.546\n",
      "Iteration: 1000, 0.004\n",
      "Accuracy: 0.543\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.539\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.538\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.536\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.536\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.908\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.093\n",
      "Accuracy: 0.514\n",
      "Iteration: 400, 0.062\n",
      "Accuracy: 0.511\n",
      "Iteration: 600, 0.026\n",
      "Accuracy: 0.517\n",
      "Iteration: 800, 0.026\n",
      "Accuracy: 0.510\n",
      "Iteration: 1000, 0.025\n",
      "Accuracy: 0.510\n",
      "Iteration: 1200, 0.021\n",
      "Accuracy: 0.509\n",
      "Iteration: 1400, 0.022\n",
      "Accuracy: 0.510\n",
      "Iteration: 1600, 0.072\n",
      "Accuracy: 0.505\n",
      "Iteration: 1800, 0.062\n",
      "Accuracy: 0.510\n",
      "('#### no noise ####   iteration ', 1)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.659\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.016\n",
      "Accuracy: 0.669\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.671\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 2)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.690\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.697\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.747\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.696\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.699\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.700\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.747\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.700\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.701\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.700\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.712\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.704\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.705\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.657\n",
      "Accuracy: 0.504\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.699\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.702\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.717\n",
      "Accuracy: 0.538\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.702\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.702\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.701\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.701\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.819\n",
      "Accuracy: 0.487\n",
      "Iteration: 200, 0.111\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.061\n",
      "Accuracy: 0.659\n",
      "Iteration: 600, 0.013\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.009\n",
      "Accuracy: 0.649\n",
      "Iteration: 1000, 0.009\n",
      "Accuracy: 0.633\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.633\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.634\n",
      "Iteration: 1600, 0.004\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.626\n",
      "('#### struc #### iteration ', 2)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.674\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.700\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.703\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.703\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.749\n",
      "Accuracy: 0.518\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.692\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.692\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.694\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.695\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.694\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.677\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.704\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.704\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.705\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.768\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.699\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.699\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.699\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.738\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.679\n",
      "Iteration: 400, 0.007\n",
      "Accuracy: 0.675\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.668\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.666\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.666\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.664\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.662\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.869\n",
      "Accuracy: 0.479\n",
      "Iteration: 200, 0.032\n",
      "Accuracy: 0.567\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.550\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.542\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.537\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.532\n",
      "Iteration: 1200, 0.004\n",
      "Accuracy: 0.529\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.529\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.527\n",
      "Iteration: 1800, 0.002\n",
      "Accuracy: 0.524\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 1.134\n",
      "Accuracy: 0.537\n",
      "Iteration: 200, 0.193\n",
      "Accuracy: 0.508\n",
      "Iteration: 400, 0.062\n",
      "Accuracy: 0.500\n",
      "Iteration: 600, 0.045\n",
      "Accuracy: 0.494\n",
      "Iteration: 800, 0.046\n",
      "Accuracy: 0.493\n",
      "Iteration: 1000, 0.047\n",
      "Accuracy: 0.493\n",
      "Iteration: 1200, 0.012\n",
      "Accuracy: 0.491\n",
      "Iteration: 1400, 0.006\n",
      "Accuracy: 0.494\n",
      "Iteration: 1600, 0.024\n",
      "Accuracy: 0.493\n",
      "Iteration: 1800, 0.006\n",
      "Accuracy: 0.486\n",
      "('#### no noise ####   iteration ', 2)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.681\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.702\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 3)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.652\n",
      "Accuracy: 0.489\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.668\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.669\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.670\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.715\n",
      "Accuracy: 0.549\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.676\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.676\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.678\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.678\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.640\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.666\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.673\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.673\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.673\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.572\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.677\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.677\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.679\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.710\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.679\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.679\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.678\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.679\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.680\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.701\n",
      "Accuracy: 0.529\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.676\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.678\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.677\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.677\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.675\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.676\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.675\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.675\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.675\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.596\n",
      "Accuracy: 0.563\n",
      "Iteration: 200, 0.066\n",
      "Accuracy: 0.653\n",
      "Iteration: 400, 0.024\n",
      "Accuracy: 0.632\n",
      "Iteration: 600, 0.023\n",
      "Accuracy: 0.623\n",
      "Iteration: 800, 0.020\n",
      "Accuracy: 0.616\n",
      "Iteration: 1000, 0.037\n",
      "Accuracy: 0.617\n",
      "Iteration: 1200, 0.011\n",
      "Accuracy: 0.614\n",
      "Iteration: 1400, 0.005\n",
      "Accuracy: 0.603\n",
      "Iteration: 1600, 0.011\n",
      "Accuracy: 0.605\n",
      "Iteration: 1800, 0.010\n",
      "Accuracy: 0.600\n",
      "('#### struc #### iteration ', 3)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.755\n",
      "Accuracy: 0.512\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.667\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.667\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.670\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.795\n",
      "Accuracy: 0.494\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.667\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.671\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.672\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.672\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.714\n",
      "Accuracy: 0.553\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.683\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.684\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.684\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.683\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.683\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.682\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.681\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.681\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.681\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.723\n",
      "Accuracy: 0.519\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.672\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.673\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.673\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.673\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.674\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.674\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.752\n",
      "Accuracy: 0.522\n",
      "Iteration: 200, 0.016\n",
      "Accuracy: 0.659\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.657\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.655\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.654\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.652\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.647\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.704\n",
      "Accuracy: 0.499\n",
      "Iteration: 200, 0.044\n",
      "Accuracy: 0.577\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.555\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.544\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.544\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.539\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.535\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.533\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.531\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.531\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.750\n",
      "Accuracy: 0.550\n",
      "Iteration: 200, 0.051\n",
      "Accuracy: 0.511\n",
      "Iteration: 400, 0.098\n",
      "Accuracy: 0.507\n",
      "Iteration: 600, 0.022\n",
      "Accuracy: 0.505\n",
      "Iteration: 800, 0.049\n",
      "Accuracy: 0.502\n",
      "Iteration: 1000, 0.028\n",
      "Accuracy: 0.509\n",
      "Iteration: 1200, 0.039\n",
      "Accuracy: 0.504\n",
      "Iteration: 1400, 0.003\n",
      "Accuracy: 0.504\n",
      "Iteration: 1600, 0.005\n",
      "Accuracy: 0.504\n",
      "Iteration: 1800, 0.004\n",
      "Accuracy: 0.506\n",
      "('#### no noise ####   iteration ', 3)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.679\n",
      "Accuracy: 0.494\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.668\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.669\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.668\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.672\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.672\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.672\n",
      "('x_train shape:', (100, 1000))\n",
      "(100, 'train samples')\n",
      "(10000, 'test samples')\n",
      "('#### iid  #### iteration ', 4)\n",
      "('Lamb', 1e-06)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, 0.744\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.645\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.647\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.649\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.717\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.654\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.652\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.650\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.687\n",
      "Accuracy: 0.540\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.648\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.697\n",
      "Accuracy: 0.541\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.645\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.645\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.743\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.652\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.651\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.651\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.474\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.641\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.641\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.641\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 0.682\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.056\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.020\n",
      "Accuracy: 0.624\n",
      "Iteration: 600, 0.033\n",
      "Accuracy: 0.616\n",
      "Iteration: 800, 0.021\n",
      "Accuracy: 0.617\n",
      "Iteration: 1000, 0.026\n",
      "Accuracy: 0.607\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.609\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.610\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.607\n",
      "Iteration: 1800, 0.007\n",
      "Accuracy: 0.595\n",
      "('#### struc #### iteration ', 4)\n",
      "('Lamb', 1e-06)\n",
      "Iteration: 0, 0.746\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.649\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.650\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.649\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.649\n",
      "('Lamb', 1e-05)\n",
      "Iteration: 0, 0.746\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n",
      "('Lamb', 0.0001)\n",
      "Iteration: 0, 0.728\n",
      "Accuracy: 0.510\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.647\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.646\n",
      "('Lamb', 0.001)\n",
      "Iteration: 0, 0.706\n",
      "Accuracy: 0.535\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.648\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.649\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.648\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.648\n",
      "('Lamb', 0.01)\n",
      "Iteration: 0, 0.674\n",
      "Accuracy: 0.511\n",
      "Iteration: 200, 0.021\n",
      "Accuracy: 0.637\n",
      "Iteration: 400, 0.007\n",
      "Accuracy: 0.635\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.633\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.633\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.633\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.633\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.631\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.630\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.630\n",
      "('Lamb', 0.1)\n",
      "Iteration: 0, 0.770\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.053\n",
      "Accuracy: 0.566\n",
      "Iteration: 400, 0.018\n",
      "Accuracy: 0.551\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.542\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.538\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.538\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.537\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.535\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.534\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.533\n",
      "('Lamb', 1.0)\n",
      "Iteration: 0, 1.135\n",
      "Accuracy: 0.551\n",
      "Iteration: 200, 0.118\n",
      "Accuracy: 0.516\n",
      "Iteration: 400, 0.046\n",
      "Accuracy: 0.514\n",
      "Iteration: 600, 0.024\n",
      "Accuracy: 0.509\n",
      "Iteration: 800, 0.016\n",
      "Accuracy: 0.503\n",
      "Iteration: 1000, 0.015\n",
      "Accuracy: 0.511\n",
      "Iteration: 1200, 0.009\n",
      "Accuracy: 0.512\n",
      "Iteration: 1400, 0.039\n",
      "Accuracy: 0.506\n",
      "Iteration: 1600, 0.046\n",
      "Accuracy: 0.502\n",
      "Iteration: 1800, 0.036\n",
      "Accuracy: 0.509\n",
      "('#### no noise ####   iteration ', 4)\n",
      "('Lamb', None)\n",
      "Iteration: 0, 0.692\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.648\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.648\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.648\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "                 \n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 1000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68056, 0.02296654958847756)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6864600000000001, 0.020661229392269956)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68758, 0.022539955634384)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 10000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n",
      "WARNING:tensorflow:From <ipython-input-5-33aea1dcf6cd>:18: MultivariateNormalFullCovariance.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_full_covariance) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py:194: MultivariateNormalTriL.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_tril) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_tril.py:221: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'cond/eye/MatrixDiag', defined at:\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-cfb07ff18606>\", line 88, in <module>\n    acc_iid_i=training(lambdas, 'iid', max_iters)\n  File \"<ipython-input-6-cfb07ff18606>\", line 11, in training\n    model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n  File \"<ipython-input-5-33aea1dcf6cd>\", line 36, in __init__\n    self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2048, in cond\n    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1895, in BuildCondBranch\n    original_result = fn()\n  File \"<ipython-input-5-33aea1dcf6cd>\", line 36, in <lambda>\n    self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n  File \"<ipython-input-5-33aea1dcf6cd>\", line 17, in dropout_layer\n    cov =  tf.eye(dim, dtype='float32')\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/linalg_ops.py\", line 167, in eye\n    name=name)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/linalg_ops_impl.py\", line 68, in eye\n    return array_ops.matrix_diag(diag_ones)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3950, in matrix_diag\n    \"MatrixDiag\", diagonal=diagonal, name=name)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cfb07ff18606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#### iid  #### iteration '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0macc_iid_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0macc_iid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macc_iid_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-cfb07ff18606>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(seqlambda, mode, max_iters, learning_rate)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n\u001b[0;32m---> 26\u001b[0;31m                     model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                \u001b[0;31m# print(\"train_accuracy\",acc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'cond/eye/MatrixDiag', defined at:\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-cfb07ff18606>\", line 88, in <module>\n    acc_iid_i=training(lambdas, 'iid', max_iters)\n  File \"<ipython-input-6-cfb07ff18606>\", line 11, in training\n    model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n  File \"<ipython-input-5-33aea1dcf6cd>\", line 36, in __init__\n    self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2048, in cond\n    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1895, in BuildCondBranch\n    original_result = fn()\n  File \"<ipython-input-5-33aea1dcf6cd>\", line 36, in <lambda>\n    self.dl = tf.cond(self.train, lambda : dropout_layer(self.X, mode, l, dim), lambda : self.X)\n  File \"<ipython-input-5-33aea1dcf6cd>\", line 17, in dropout_layer\n    cov =  tf.eye(dim, dtype='float32')\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/linalg_ops.py\", line 167, in eye\n    name=name)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/linalg_ops_impl.py\", line 68, in eye\n    return array_ops.matrix_diag(diag_ones)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3950, in matrix_diag\n    \"MatrixDiag\", diagonal=diagonal, name=name)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,10000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: cond/eye/MatrixDiag = MatrixDiag[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cond/eye/ones)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "                 \n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    #print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=10000, n_informative=1000, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 10000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  0\n",
      "Lamb 1e-06\n",
      "WARNING:tensorflow:From <ipython-input-3-5317bbadfddf>:18: MultivariateNormalFullCovariance.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_full_covariance) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py:194: MultivariateNormalTriL.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_tril) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_tril.py:221: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "Iteration: 0, 1.130\n",
      "Accuracy: 0.448\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.700\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.701\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.214\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.006\n",
      "Accuracy: 0.695\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.697\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.702\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.076\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.700\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.700\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.701\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.210\n",
      "Accuracy: 0.566\n",
      "Iteration: 200, 0.006\n",
      "Accuracy: 0.699\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.824\n",
      "Accuracy: 0.530\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "Lamb 0.1\n",
      "Iteration: 0, 1.266\n",
      "Accuracy: 0.472\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.701\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.705\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.705\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.705\n",
      "Lamb 1.0\n",
      "Iteration: 0, 1.197\n",
      "Accuracy: 0.395\n",
      "Iteration: 200, 0.096\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.027\n",
      "Accuracy: 0.681\n",
      "Iteration: 600, 0.025\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 0.025\n",
      "Accuracy: 0.679\n",
      "Iteration: 1000, 0.087\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.067\n",
      "Accuracy: 0.664\n",
      "Iteration: 1400, 0.004\n",
      "Accuracy: 0.688\n",
      "Iteration: 1600, 0.023\n",
      "Accuracy: 0.671\n",
      "Iteration: 1800, 0.056\n",
      "Accuracy: 0.670\n",
      "#### struc #### iteration  0\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.981\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.702\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.704\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.706\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.706\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.707\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.707\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.707\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.194\n",
      "Accuracy: 0.581\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.708\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.710\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.710\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.709\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.709\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.708\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.891\n",
      "Accuracy: 0.550\n",
      "Iteration: 200, 0.066\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.700\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.702\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.703\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.608\n",
      "Accuracy: 0.472\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.702\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.708\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.703\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.709\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.707\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.706\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.704\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.704\n",
      "Lamb 0.01\n",
      "Iteration: 0, 4.496\n",
      "Accuracy: 0.567\n",
      "Iteration: 200, 0.041\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.684\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.680\n",
      "Iteration: 800, 0.017\n",
      "Accuracy: 0.683\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.682\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.679\n",
      "Iteration: 1400, 0.003\n",
      "Accuracy: 0.677\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.676\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.674\n",
      "Lamb 0.1\n",
      "Iteration: 0, 8.181\n",
      "Accuracy: 0.481\n",
      "Iteration: 200, 0.730\n",
      "Accuracy: 0.662\n",
      "Iteration: 400, 0.204\n",
      "Accuracy: 0.620\n",
      "Iteration: 600, 0.750\n",
      "Accuracy: 0.620\n",
      "Iteration: 800, 0.520\n",
      "Accuracy: 0.597\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.594\n",
      "Iteration: 1200, 0.382\n",
      "Accuracy: 0.582\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.583\n",
      "Iteration: 1600, 0.003\n",
      "Accuracy: 0.568\n",
      "Iteration: 1800, 1.456\n",
      "Accuracy: 0.580\n",
      "Lamb 1.0\n",
      "Iteration: 0, 22.233\n",
      "Accuracy: 0.496\n",
      "Iteration: 200, 15.083\n",
      "Accuracy: 0.548\n",
      "Iteration: 400, 5.803\n",
      "Accuracy: 0.555\n",
      "Iteration: 600, 3.594\n",
      "Accuracy: 0.563\n",
      "Iteration: 800, 1.509\n",
      "Accuracy: 0.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, 0.603\n",
      "Accuracy: 0.549\n",
      "Iteration: 1200, 1.443\n",
      "Accuracy: 0.530\n",
      "Iteration: 1400, 1.505\n",
      "Accuracy: 0.528\n",
      "Iteration: 1600, 4.662\n",
      "Accuracy: 0.529\n",
      "Iteration: 1800, 17.571\n",
      "Accuracy: 0.524\n",
      "#### no noise ####   iteration  0\n",
      "Lamb None\n",
      "Iteration: 0, 1.041\n",
      "Accuracy: 0.528\n",
      "Iteration: 200, 0.006\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.699\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.700\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.702\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.702\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.829\n",
      "Accuracy: 0.493\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.644\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.643\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.643\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.644\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.644\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.644\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.644\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.049\n",
      "Accuracy: 0.525\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.643\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.644\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.644\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.644\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.645\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.001\n",
      "Accuracy: 0.515\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.648\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.650\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.649\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.650\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.597\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.648\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.648\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.646\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.889\n",
      "Accuracy: 0.530\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.650\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.652\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.651\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.650\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.865\n",
      "Accuracy: 0.546\n",
      "Iteration: 200, 0.017\n",
      "Accuracy: 0.649\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.648\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.653\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.654\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.652\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.651\n",
      "Lamb 1.0\n",
      "Iteration: 0, 0.882\n",
      "Accuracy: 0.506\n",
      "Iteration: 200, 0.074\n",
      "Accuracy: 0.653\n",
      "Iteration: 400, 0.015\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.008\n",
      "Accuracy: 0.657\n",
      "Iteration: 800, 0.014\n",
      "Accuracy: 0.645\n",
      "Iteration: 1000, 0.006\n",
      "Accuracy: 0.646\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.005\n",
      "Accuracy: 0.632\n",
      "Iteration: 1600, 0.007\n",
      "Accuracy: 0.632\n",
      "Iteration: 1800, 0.107\n",
      "Accuracy: 0.620\n",
      "#### struc #### iteration  1\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.944\n",
      "Accuracy: 0.500\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.644\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.739\n",
      "Accuracy: 0.520\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.646\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.645\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.646\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.759\n",
      "Accuracy: 0.577\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.653\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.657\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.655\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.651\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.655\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.656\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.231\n",
      "Accuracy: 0.483\n",
      "Iteration: 200, 0.026\n",
      "Accuracy: 0.666\n",
      "Iteration: 400, 0.006\n",
      "Accuracy: 0.675\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.671\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.670\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.671\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.666\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.878\n",
      "Accuracy: 0.527\n",
      "Iteration: 200, 0.048\n",
      "Accuracy: 0.665\n",
      "Iteration: 400, 0.010\n",
      "Accuracy: 0.662\n",
      "Iteration: 600, 0.011\n",
      "Accuracy: 0.658\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.656\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.654\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.654\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.652\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.650\n",
      "Iteration: 1800, 0.002\n",
      "Accuracy: 0.652\n",
      "Lamb 0.1\n",
      "Iteration: 0, 8.715\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 2.204\n",
      "Accuracy: 0.613\n",
      "Iteration: 400, 0.339\n",
      "Accuracy: 0.604\n",
      "Iteration: 600, 0.178\n",
      "Accuracy: 0.575\n",
      "Iteration: 800, 0.037\n",
      "Accuracy: 0.571\n",
      "Iteration: 1000, 0.047\n",
      "Accuracy: 0.566\n",
      "Iteration: 1200, 0.258\n",
      "Accuracy: 0.564\n",
      "Iteration: 1400, 0.047\n",
      "Accuracy: 0.568\n",
      "Iteration: 1600, 2.230\n",
      "Accuracy: 0.554\n",
      "Iteration: 1800, 0.024\n",
      "Accuracy: 0.556\n",
      "Lamb 1.0\n",
      "Iteration: 0, 11.002\n",
      "Accuracy: 0.489\n",
      "Iteration: 200, 4.863\n",
      "Accuracy: 0.577\n",
      "Iteration: 400, 1.833\n",
      "Accuracy: 0.550\n",
      "Iteration: 600, 0.750\n",
      "Accuracy: 0.533\n",
      "Iteration: 800, 7.783\n",
      "Accuracy: 0.526\n",
      "Iteration: 1000, 5.862\n",
      "Accuracy: 0.526\n",
      "Iteration: 1200, 0.548\n",
      "Accuracy: 0.516\n",
      "Iteration: 1400, 4.301\n",
      "Accuracy: 0.513\n",
      "Iteration: 1600, 3.490\n",
      "Accuracy: 0.519\n",
      "Iteration: 1800, 3.874\n",
      "Accuracy: 0.517\n",
      "#### no noise ####   iteration  1\n",
      "Lamb None\n",
      "Iteration: 0, 0.791\n",
      "Accuracy: 0.514\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.645\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.645\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.647\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.001\n",
      "Accuracy: 0.504\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.692\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.696\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.698\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.916\n",
      "Accuracy: 0.583\n",
      "Iteration: 200, 0.003\n",
      "Accuracy: 0.697\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.697\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.699\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.432\n",
      "Accuracy: 0.485\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.694\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.696\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.697\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.699\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.699\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.996\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.694\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.696\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.696\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.519\n",
      "Accuracy: 0.470\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.685\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.687\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.691\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.691\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.692\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.778\n",
      "Accuracy: 0.568\n",
      "Iteration: 200, 0.015\n",
      "Accuracy: 0.698\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.700\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.701\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.704\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.702\n",
      "Lamb 1.0\n",
      "Iteration: 0, 1.547\n",
      "Accuracy: 0.568\n",
      "Iteration: 200, 0.111\n",
      "Accuracy: 0.690\n",
      "Iteration: 400, 0.020\n",
      "Accuracy: 0.701\n",
      "Iteration: 600, 0.053\n",
      "Accuracy: 0.692\n",
      "Iteration: 800, 0.010\n",
      "Accuracy: 0.680\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.688\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.685\n",
      "Iteration: 1400, 0.010\n",
      "Accuracy: 0.687\n",
      "Iteration: 1600, 0.006\n",
      "Accuracy: 0.679\n",
      "Iteration: 1800, 0.069\n",
      "Accuracy: 0.658\n",
      "#### struc #### iteration  2\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.062\n",
      "Accuracy: 0.513\n",
      "Iteration: 200, 0.004\n",
      "Accuracy: 0.691\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.693\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.694\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.695\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.112\n",
      "Accuracy: 0.504\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.685\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.689\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.689\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.691\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.691\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.690\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.690\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.690\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.302\n",
      "Accuracy: 0.475\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.682\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.693\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.694\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.695\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.699\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.701\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.700\n",
      "Lamb 0.001\n",
      "Iteration: 0, 2.146\n",
      "Accuracy: 0.482\n",
      "Iteration: 200, 0.020\n",
      "Accuracy: 0.698\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.698\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.701\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.701\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.701\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.702\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.703\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.703\n",
      "Lamb 0.01\n",
      "Iteration: 0, 2.743\n",
      "Accuracy: 0.467\n",
      "Iteration: 200, 0.043\n",
      "Accuracy: 0.683\n",
      "Iteration: 400, 0.013\n",
      "Accuracy: 0.680\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.683\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.687\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.684\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.684\n",
      "Iteration: 1400, 0.004\n",
      "Accuracy: 0.682\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.682\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.679\n",
      "Lamb 0.1\n",
      "Iteration: 0, 5.714\n",
      "Accuracy: 0.400\n",
      "Iteration: 200, 0.824\n",
      "Accuracy: 0.653\n",
      "Iteration: 400, 0.243\n",
      "Accuracy: 0.622\n",
      "Iteration: 600, 0.007\n",
      "Accuracy: 0.611\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.593\n",
      "Iteration: 1000, 0.648\n",
      "Accuracy: 0.574\n",
      "Iteration: 1200, 0.028\n",
      "Accuracy: 0.588\n",
      "Iteration: 1400, 0.005\n",
      "Accuracy: 0.583\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.566\n",
      "Iteration: 1800, 0.058\n",
      "Accuracy: 0.563\n",
      "Lamb 1.0\n",
      "Iteration: 0, 24.696\n",
      "Accuracy: 0.557\n",
      "Iteration: 200, 8.698\n",
      "Accuracy: 0.549\n",
      "Iteration: 400, 4.059\n",
      "Accuracy: 0.576\n",
      "Iteration: 600, 5.707\n",
      "Accuracy: 0.547\n",
      "Iteration: 800, 3.187\n",
      "Accuracy: 0.550\n",
      "Iteration: 1000, 2.105\n",
      "Accuracy: 0.549\n",
      "Iteration: 1200, 2.074\n",
      "Accuracy: 0.545\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.532\n",
      "Iteration: 1600, 6.954\n",
      "Accuracy: 0.533\n",
      "Iteration: 1800, 0.749\n",
      "Accuracy: 0.531\n",
      "#### no noise ####   iteration  2\n",
      "Lamb None\n",
      "Iteration: 0, 0.584\n",
      "Accuracy: 0.544\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.696\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.697\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.698\n",
      "Iteration: 1000, 0.000\n",
      "Accuracy: 0.697\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.698\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.698\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.153\n",
      "Accuracy: 0.500\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.606\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.607\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.608\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.608\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.607\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.607\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.607\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.607\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.608\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.121\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.620\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.621\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.620\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.619\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.620\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.620\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.619\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.620\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.619\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.232\n",
      "Accuracy: 0.545\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.617\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.618\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.616\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.615\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.615\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.614\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.614\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.615\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.616\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.178\n",
      "Accuracy: 0.480\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.613\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.612\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.613\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.613\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.614\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.613\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.614\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.613\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.613\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.997\n",
      "Accuracy: 0.482\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.599\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.600\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.603\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.604\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.604\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.604\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.604\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.605\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.605\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.907\n",
      "Accuracy: 0.529\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.621\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.622\n",
      "Iteration: 600, 0.005\n",
      "Accuracy: 0.621\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.620\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.621\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.619\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.618\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.620\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.618\n",
      "Lamb 1.0\n",
      "Iteration: 0, 1.907\n",
      "Accuracy: 0.487\n",
      "Iteration: 200, 0.085\n",
      "Accuracy: 0.627\n",
      "Iteration: 400, 0.012\n",
      "Accuracy: 0.622\n",
      "Iteration: 600, 0.098\n",
      "Accuracy: 0.611\n",
      "Iteration: 800, 0.032\n",
      "Accuracy: 0.609\n",
      "Iteration: 1000, 0.007\n",
      "Accuracy: 0.600\n",
      "Iteration: 1200, 0.031\n",
      "Accuracy: 0.609\n",
      "Iteration: 1400, 0.009\n",
      "Accuracy: 0.611\n",
      "Iteration: 1600, 0.052\n",
      "Accuracy: 0.596\n",
      "Iteration: 1800, 0.003\n",
      "Accuracy: 0.607\n",
      "#### struc #### iteration  3\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.137\n",
      "Accuracy: 0.502\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.615\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.613\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.612\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.611\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.612\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.611\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.611\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.611\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.611\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.376\n",
      "Accuracy: 0.492\n",
      "Iteration: 200, 0.013\n",
      "Accuracy: 0.606\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.610\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.612\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.612\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.613\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.613\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.614\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.614\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lamb 0.0001\n",
      "Iteration: 0, 0.809\n",
      "Accuracy: 0.548\n",
      "Iteration: 200, 0.014\n",
      "Accuracy: 0.620\n",
      "Iteration: 400, 0.008\n",
      "Accuracy: 0.626\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.626\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.624\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.625\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.626\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.628\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.628\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.626\n",
      "Lamb 0.001\n",
      "Iteration: 0, 1.361\n",
      "Accuracy: 0.524\n",
      "Iteration: 200, 0.021\n",
      "Accuracy: 0.623\n",
      "Iteration: 400, 0.008\n",
      "Accuracy: 0.631\n",
      "Iteration: 600, 0.011\n",
      "Accuracy: 0.630\n",
      "Iteration: 800, 0.003\n",
      "Accuracy: 0.631\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.632\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.631\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.630\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.629\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.630\n",
      "Lamb 0.01\n",
      "Iteration: 0, 3.102\n",
      "Accuracy: 0.564\n",
      "Iteration: 200, 0.075\n",
      "Accuracy: 0.631\n",
      "Iteration: 400, 0.018\n",
      "Accuracy: 0.625\n",
      "Iteration: 600, 0.008\n",
      "Accuracy: 0.622\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.616\n",
      "Iteration: 1000, 0.004\n",
      "Accuracy: 0.618\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.615\n",
      "Iteration: 1400, 0.005\n",
      "Accuracy: 0.613\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.612\n",
      "Iteration: 1800, 0.006\n",
      "Accuracy: 0.610\n",
      "Lamb 0.1\n",
      "Iteration: 0, 11.949\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.661\n",
      "Accuracy: 0.600\n",
      "Iteration: 400, 1.534\n",
      "Accuracy: 0.569\n",
      "Iteration: 600, 0.215\n",
      "Accuracy: 0.570\n",
      "Iteration: 800, 1.476\n",
      "Accuracy: 0.592\n",
      "Iteration: 1000, 0.541\n",
      "Accuracy: 0.564\n",
      "Iteration: 1200, 0.046\n",
      "Accuracy: 0.554\n",
      "Iteration: 1400, 0.029\n",
      "Accuracy: 0.544\n",
      "Iteration: 1600, 0.018\n",
      "Accuracy: 0.547\n",
      "Iteration: 1800, 0.003\n",
      "Accuracy: 0.534\n",
      "Lamb 1.0\n",
      "Iteration: 0, 14.629\n",
      "Accuracy: 0.429\n",
      "Iteration: 200, 5.677\n",
      "Accuracy: 0.543\n",
      "Iteration: 400, 3.561\n",
      "Accuracy: 0.539\n",
      "Iteration: 600, 3.334\n",
      "Accuracy: 0.544\n",
      "Iteration: 800, 8.444\n",
      "Accuracy: 0.533\n",
      "Iteration: 1000, 4.693\n",
      "Accuracy: 0.532\n",
      "Iteration: 1200, 4.631\n",
      "Accuracy: 0.526\n",
      "Iteration: 1400, 2.221\n",
      "Accuracy: 0.516\n",
      "Iteration: 1600, 2.333\n",
      "Accuracy: 0.514\n",
      "Iteration: 1800, 0.628\n",
      "Accuracy: 0.519\n",
      "#### no noise ####   iteration  3\n",
      "Lamb None\n",
      "Iteration: 0, 1.087\n",
      "Accuracy: 0.533\n",
      "Iteration: 200, 0.011\n",
      "Accuracy: 0.615\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.616\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.616\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.617\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.617\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.617\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.617\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.616\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.617\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### iid  #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 0.956\n",
      "Accuracy: 0.532\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.635\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.637\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.637\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.638\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.638\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.638\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 0.956\n",
      "Accuracy: 0.498\n",
      "Iteration: 200, 0.009\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.637\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.639\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.637\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.639\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.638\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.637\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.639\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 0.786\n",
      "Accuracy: 0.534\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.640\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.638\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.639\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.640\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.904\n",
      "Accuracy: 0.501\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.642\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.641\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.641\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.641\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.642\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.641\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.169\n",
      "Accuracy: 0.511\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.638\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.638\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.638\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.638\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.638\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.639\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.640\n",
      "Lamb 0.1\n",
      "Iteration: 0, 0.994\n",
      "Accuracy: 0.535\n",
      "Iteration: 200, 0.030\n",
      "Accuracy: 0.644\n",
      "Iteration: 400, 0.004\n",
      "Accuracy: 0.650\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.650\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.650\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.649\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.653\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.650\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.650\n",
      "Lamb 1.0\n",
      "Iteration: 0, 1.029\n",
      "Accuracy: 0.462\n",
      "Iteration: 200, 0.110\n",
      "Accuracy: 0.651\n",
      "Iteration: 400, 0.077\n",
      "Accuracy: 0.633\n",
      "Iteration: 600, 0.034\n",
      "Accuracy: 0.627\n",
      "Iteration: 800, 0.121\n",
      "Accuracy: 0.637\n",
      "Iteration: 1000, 0.015\n",
      "Accuracy: 0.632\n",
      "Iteration: 1200, 0.016\n",
      "Accuracy: 0.633\n",
      "Iteration: 1400, 0.070\n",
      "Accuracy: 0.629\n",
      "Iteration: 1600, 0.058\n",
      "Accuracy: 0.636\n",
      "Iteration: 1800, 0.031\n",
      "Accuracy: 0.616\n",
      "#### struc #### iteration  4\n",
      "Lamb 1e-06\n",
      "Iteration: 0, 1.294\n",
      "Accuracy: 0.550\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.639\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.636\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.635\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.634\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.633\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.634\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.635\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.634\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.635\n",
      "Lamb 1e-05\n",
      "Iteration: 0, 1.127\n",
      "Accuracy: 0.518\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.636\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.639\n",
      "Iteration: 600, 0.002\n",
      "Accuracy: 0.640\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.640\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.642\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.641\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.642\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.643\n",
      "Lamb 0.0001\n",
      "Iteration: 0, 1.063\n",
      "Accuracy: 0.485\n",
      "Iteration: 200, 0.012\n",
      "Accuracy: 0.643\n",
      "Iteration: 400, 0.005\n",
      "Accuracy: 0.646\n",
      "Iteration: 600, 0.003\n",
      "Accuracy: 0.644\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.648\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.647\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.646\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.647\n",
      "Lamb 0.001\n",
      "Iteration: 0, 0.784\n",
      "Accuracy: 0.503\n",
      "Iteration: 200, 0.019\n",
      "Accuracy: 0.657\n",
      "Iteration: 400, 0.008\n",
      "Accuracy: 0.658\n",
      "Iteration: 600, 0.004\n",
      "Accuracy: 0.654\n",
      "Iteration: 800, 0.002\n",
      "Accuracy: 0.654\n",
      "Iteration: 1000, 0.002\n",
      "Accuracy: 0.652\n",
      "Iteration: 1200, 0.002\n",
      "Accuracy: 0.656\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.657\n",
      "Iteration: 1600, 0.002\n",
      "Accuracy: 0.653\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.653\n",
      "Lamb 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d1d89d81e98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#### struc #### iteration '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0macc_struc_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'struc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0macc_struc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macc_struc_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#### no noise ####   iteration '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4d1d89d81e98>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(seqlambda, mode, max_iters, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0miters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def training(seqlambda, mode, max_iters=6000, learning_rate=1):\n",
    "\n",
    "    all_accuracies = []\n",
    "    all_cor_norms = []\n",
    "    acts1 = []\n",
    "    for lamb in seqlambda:\n",
    "\n",
    "        print('Lamb', lamb)\n",
    "        accs = [] ; cor_norms = [] \n",
    "        \n",
    "        model = Linear_Model(dim, nb_classes, batch_size, lamb, mode)\n",
    "        #model = MLP(dimension, nb_hidden1, nb_hidden2,nb_classes, batch_size, lamb, mode)\n",
    "\n",
    "        # training parameters\n",
    "        optimiser = tf.train.AdamOptimizer().minimize(model.mean_log_loss)\n",
    "        #optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(model.mean_log_loss)\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for iters in range(max_iters):\n",
    "\n",
    "                idx = np.random.randint(nb_train, size=batch_size)\n",
    "\n",
    "                _, loss,train_probs = sess.run([optimiser, model.mean_log_loss,model.probs], feed_dict={\n",
    "                    model.X : x_train[idx], model.Y : y_train[idx], model.train : True})\n",
    "                acc = np.sum(np.round(train_probs) == y_train[idx]) / float(128)\n",
    "               # print(\"train_accuracy\",acc)\n",
    "                #print(np.sum(err1))\n",
    "                #print(np.sum(err2))\n",
    "            \n",
    "\n",
    "                if iters % 200 == 0:\n",
    "                    print('Iteration: %d, %.03f' % (iters, loss))  \n",
    "                    pred= sess.run([model.probs],\n",
    "                                    feed_dict={model.X : x_test, model.train : False})\n",
    "                 \n",
    "                    acc = np.sum(np.round(pred) == y_test) / float(nb_test)\n",
    "                    accs.append(acc)\n",
    "                    print('Accuracy: %.03f' % acc)\n",
    "            \n",
    "            all_accuracies.append(accs)\n",
    "\n",
    "\n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "max_iters = 2000\n",
    "lambdas = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e-0]\n",
    "\n",
    "\n",
    "\n",
    "acc_linear=[]\n",
    "acc_iid=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=100, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 1000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    print('#### iid  #### iteration ',i)\n",
    "    acc_iid_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_iid.append([np.max([np.max(acc) for acc in acc_iid_i])])\n",
    "\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    print('#### no noise ####   iteration ',i)\n",
    "    acc_linear_i=training([None], None , max_iters)\n",
    "    acc_linear.append([accs[-1] for accs in acc_linear_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65832, 0.016279975429956867)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_linear), np.std(acc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.67628, 0.013198393841676362)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_iid), np.std(acc_iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68212, 0.013086389876509098)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compare fast structured dropout with structured dropout version : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.distributions import MultivariateNormalFullCovariance as mvnfc\n",
    "\n",
    "\n",
    "def dropout_layer(x, mode, l, dim):\n",
    "\n",
    "    if mode == 'struc':\n",
    "        xm = tf.reduce_mean(x, 0)\n",
    "        cov = tf.matmul(tf.transpose(x-xm), x-xm) / batch_size\n",
    "        cov += 1e-2 * tf.eye(dim, dtype='float32')\n",
    "       # dia=tf.sqrt(tf.diag(1/tf.diag_part(cov)))\n",
    "       # corr= tf.matmul(tf.matmul(dia,cov),dia)\n",
    "        sample = mvnfc(tf.zeros(shape=[dim]), cov).sample()\n",
    "        return tf.multiply(x, np.sqrt(l)* sample + tf.ones(shape=[dim]))\n",
    " \n",
    "    elif mode == 'struc_fast':\n",
    "       #mu = tf.Variable(lambda : tf.ones(shape=[dim]))\n",
    "        xm = tf.reduce_mean(x, 0)\n",
    "        sample = tf.distributions.Normal(loc=tf.zeros(shape=[dim]),scale= tf.ones(shape=[dim])).sample()\n",
    "        a= tf.expand_dims(sample,1)\n",
    "        sample =  tf.matmul((x-xm),a)/ np.sqrt(batch_size)\n",
    "        return tf.multiply(x, np.sqrt(l)* sample + tf.ones(shape=[dim]))\n",
    "\n",
    "    elif mode == 'iid':\n",
    "      # mu = tf.Variable(lambda : tf.ones(shape=[dim]))\n",
    "        cov =  tf.eye(dim, dtype='float32')\n",
    "        sample = mvnfc(tf.zeros(shape=[dim]), cov).sample()\n",
    "        return tf.multiply(x, np.sqrt(l)* sample + tf.ones(shape=[dim]))\n",
    "\n",
    "    else:  # no dropout\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### fast_struc  #### iteration  0\n",
      "Lamb 0.01\n",
      "WARNING:tensorflow:From <ipython-input-4-91bd14f1adb8>:18: MultivariateNormalFullCovariance.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_full_covariance) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_full_covariance.py:194: MultivariateNormalTriL.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_tril) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_tril.py:221: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:200: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "WARNING:tensorflow:From /cbio/donnees/bkhalfaoui/miniconda3/envs/tensor_gpu/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
      "Iteration: 0, 1.018\n",
      "Accuracy: 0.493\n",
      "Iteration: 200, 0.007\n",
      "Accuracy: 0.710\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.707\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.705\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.706\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.705\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.704\n",
      "#### struc #### iteration  0\n",
      "Lamb 0.01\n",
      "Iteration: 0, 2.471\n",
      "Accuracy: 0.505\n",
      "Iteration: 200, 0.024\n",
      "Accuracy: 0.693\n",
      "Iteration: 400, 0.010\n",
      "Accuracy: 0.689\n",
      "Iteration: 600, 0.013\n",
      "Accuracy: 0.689\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.689\n",
      "Iteration: 1000, 0.009\n",
      "Accuracy: 0.688\n",
      "Iteration: 1200, 0.024\n",
      "Accuracy: 0.683\n",
      "Iteration: 1400, 0.001\n",
      "Accuracy: 0.684\n",
      "Iteration: 1600, 0.461\n",
      "Accuracy: 0.693\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.683\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### fast_struc  #### iteration  1\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.929\n",
      "Accuracy: 0.535\n",
      "Iteration: 200, 0.008\n",
      "Accuracy: 0.629\n",
      "Iteration: 400, 0.003\n",
      "Accuracy: 0.628\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.628\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.627\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.627\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.627\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.627\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.628\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.628\n",
      "#### struc #### iteration  1\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.973\n",
      "Accuracy: 0.476\n",
      "Iteration: 200, 0.045\n",
      "Accuracy: 0.631\n",
      "Iteration: 400, 0.009\n",
      "Accuracy: 0.629\n",
      "Iteration: 600, 0.008\n",
      "Accuracy: 0.631\n",
      "Iteration: 800, 0.008\n",
      "Accuracy: 0.629\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.629\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.627\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.630\n",
      "Iteration: 1600, 0.004\n",
      "Accuracy: 0.626\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.627\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### fast_struc  #### iteration  2\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.796\n",
      "Accuracy: 0.520\n",
      "Iteration: 200, 0.005\n",
      "Accuracy: 0.667\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.670\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.667\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.667\n",
      "#### struc #### iteration  2\n",
      "Lamb 0.01\n",
      "Iteration: 0, 2.840\n",
      "Accuracy: 0.492\n",
      "Iteration: 200, 0.031\n",
      "Accuracy: 0.663\n",
      "Iteration: 400, 0.020\n",
      "Accuracy: 0.657\n",
      "Iteration: 600, 0.006\n",
      "Accuracy: 0.651\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.655\n",
      "Iteration: 1000, 0.003\n",
      "Accuracy: 0.648\n",
      "Iteration: 1200, 0.006\n",
      "Accuracy: 0.646\n",
      "Iteration: 1400, 0.003\n",
      "Accuracy: 0.647\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.645\n",
      "Iteration: 1800, 0.002\n",
      "Accuracy: 0.641\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### fast_struc  #### iteration  3\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.577\n",
      "Accuracy: 0.449\n",
      "Iteration: 200, 0.003\n",
      "Accuracy: 0.667\n",
      "Iteration: 400, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.669\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.668\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.669\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.668\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.669\n",
      "#### struc #### iteration  3\n",
      "Lamb 0.01\n",
      "Iteration: 0, 3.356\n",
      "Accuracy: 0.500\n",
      "Iteration: 200, 0.021\n",
      "Accuracy: 0.688\n",
      "Iteration: 400, 0.010\n",
      "Accuracy: 0.679\n",
      "Iteration: 600, 0.007\n",
      "Accuracy: 0.678\n",
      "Iteration: 800, 0.004\n",
      "Accuracy: 0.678\n",
      "Iteration: 1000, 0.004\n",
      "Accuracy: 0.674\n",
      "Iteration: 1200, 0.005\n",
      "Accuracy: 0.677\n",
      "Iteration: 1400, 0.187\n",
      "Accuracy: 0.683\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.687\n",
      "Iteration: 1800, 0.006\n",
      "Accuracy: 0.686\n",
      "x_train shape: (100, 1000)\n",
      "100 train samples\n",
      "10000 test samples\n",
      "#### fast_struc  #### iteration  4\n",
      "Lamb 0.01\n",
      "Iteration: 0, 0.891\n",
      "Accuracy: 0.490\n",
      "Iteration: 200, 0.010\n",
      "Accuracy: 0.663\n",
      "Iteration: 400, 0.002\n",
      "Accuracy: 0.665\n",
      "Iteration: 600, 0.001\n",
      "Accuracy: 0.665\n",
      "Iteration: 800, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1000, 0.001\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.000\n",
      "Accuracy: 0.668\n",
      "Iteration: 1400, 0.000\n",
      "Accuracy: 0.666\n",
      "Iteration: 1600, 0.000\n",
      "Accuracy: 0.665\n",
      "Iteration: 1800, 0.000\n",
      "Accuracy: 0.667\n",
      "#### struc #### iteration  4\n",
      "Lamb 0.01\n",
      "Iteration: 0, 1.363\n",
      "Accuracy: 0.494\n",
      "Iteration: 200, 0.029\n",
      "Accuracy: 0.680\n",
      "Iteration: 400, 0.013\n",
      "Accuracy: 0.672\n",
      "Iteration: 600, 0.014\n",
      "Accuracy: 0.672\n",
      "Iteration: 800, 0.005\n",
      "Accuracy: 0.668\n",
      "Iteration: 1000, 0.005\n",
      "Accuracy: 0.667\n",
      "Iteration: 1200, 0.003\n",
      "Accuracy: 0.666\n",
      "Iteration: 1400, 0.002\n",
      "Accuracy: 0.663\n",
      "Iteration: 1600, 0.001\n",
      "Accuracy: 0.664\n",
      "Iteration: 1800, 0.001\n",
      "Accuracy: 0.663\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "max_iters = 2000\n",
    "lambdas = [1e-2]\n",
    "\n",
    "\n",
    "acc_fstruc=[]\n",
    "acc_struc=[]\n",
    "\n",
    "for i in range(5):            \n",
    "    x_all, y_all= sklearn.datasets.make_classification(n_samples=10101, n_features=1000, n_informative=100, n_redundant=100, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    x_train=x_all[range(100),]\n",
    "    y_train=y_all[range(100),]\n",
    "    x_test=x_all[101:,]\n",
    "    y_test=y_all[101:]\n",
    "\n",
    "\n",
    "    dim = 1000\n",
    "    nb_train = x_train.shape[0]\n",
    "    nb_test = x_test.shape[0]\n",
    "    nb_classes=1\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(nb_train, 'train samples')\n",
    "    print(nb_test, 'test samples')\n",
    "\n",
    "    # Convert class vectors to binary class matrices.\n",
    "    #y_train = to_categorical(y_train, nb_classes)\n",
    "    #y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    y_train=y_train.reshape(nb_train,1)\n",
    "    y_test=y_test.reshape(nb_test,1)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    " \n",
    "    print('#### fast_struc  #### iteration ',i)\n",
    "    t0 = time()\n",
    "    acc_fstruc_i=training(lambdas, 'iid', max_iters)\n",
    "    acc_fstruc.append([np.max([np.max(acc) for acc in acc_fstruc_i])])\n",
    "    t1 = time()\n",
    "    print('#### struc #### iteration ',i)\n",
    "    acc_struc_i=training(lambdas, 'struc', max_iters)\n",
    "    acc_struc.append([np.max([np.max(acc) for acc in acc_struc_i])])\n",
    "    t2 = time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6711, 0.022516482851457947)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_struc), np.std(acc_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6693399999999998, 0.02531233691305489)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_fstruc), np.std(acc_fstruc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "line_styles = ['--o', '--*', '--.','--+',':']\n",
    "\n",
    "for i, series in enumerate(acc_struc_i):\n",
    "    ax.plot(np.arange(0, max_iters, 200), series,\n",
    "            line_styles[i], color='blue', linewidth=1,\n",
    "            label=r'struc. drop. $\\lambda=$%.0e' % lambdas[i])\n",
    "    \n",
    "for i, series in enumerate(acc_fstruc_i):\n",
    "    ax.plot(np.arange(0, max_iters, 200), series,\n",
    "            line_styles[i], color='purple', linewidth=1,\n",
    "            label=r'fast struc. drop. $\\lambda=$%.0e' % lambdas[i])\n",
    "\n",
    "\n",
    "ax.set_xlabel('iteration')\n",
    "ax.set_ylabel('Correlation F. norm')\n",
    "\n",
    "# ax.set_ylim([0.8, 1.0])\n",
    "\n",
    "plt.legend(ncol=2,prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average time for Fast structured dropout:  3.4186959266662598\n"
     ]
    }
   ],
   "source": [
    "print('average time for Fast structured dropout: ',t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average time for  structured dropout:  7.841660737991333\n"
     ]
    }
   ],
   "source": [
    "print('average time for  structured dropout: ',t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
